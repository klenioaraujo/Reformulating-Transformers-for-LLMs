# ğŸš€ Plano de ImplementaÃ§Ã£o: CorreÃ§Ã£o do Mapeamento de Pesos Espectrais

## ğŸ¯ Objetivo
Corrigir o gap entre conversÃ£o espectral e pipeline, garantindo que os pesos TREINADOS do GPT-2 sejam preservados no modelo Î¨QRH via transformaÃ§Ã£o fÃ­sica.

---

## ğŸ“‹ Tarefas

### âœ… FASE 1: DiagnÃ³stico (COMPLETO)
- [x] Analisar `SpectralModelConverter`
- [x] Identificar gap: pesos nÃ£o sÃ£o salvos/carregados
- [x] Documentar anÃ¡lise completa
- [x] Criar plano de correÃ§Ã£o

### ğŸ”„ FASE 2: ImplementaÃ§Ã£o do Mapeador de Pesos

#### Tarefa 2.1: Criar `spectral_weight_mapper.py`
**Arquivo:** `src/utils/spectral_weight_mapper.py`

**FunÃ§Ãµes a implementar:**

1. **`quaternion_from_phase(theta: float) -> torch.Tensor`**
   ```python
   """
   Cria quaternion de rotaÃ§Ã£o a partir de fase

   Args:
       theta: Fase em radianos [-Ï€, Ï€]

   Returns:
       q = [cos(Î¸/2), sin(Î¸/2), 0, 0] (rotaÃ§Ã£o no eixo i)
   """
   ```

2. **`apply_quaternion_rotation(weight: Tensor, q: Tensor, alpha: float) -> Tensor`**
   ```python
   """
   Aplica rotaÃ§Ã£o quaterniÃ´nica modulada por Î±

   Args:
       weight: Tensor de pesos (qualquer shape)
       q: Quaternion [w, x, y, z]
       alpha: ParÃ¢metro espectral

   Returns:
       Peso transformado com mesma shape
   """
   ```

3. **`leech_project(weight: Tensor, block_size: int = 24) -> Tensor`**
   ```python
   """
   Projeta pesos no reticulado de Leech Î›â‚‚â‚„

   Args:
       weight: Tensor de pesos
       block_size: Tamanho do bloco (24 para Leech)

   Returns:
       Peso projetado (mesma shape)
   """
   ```

4. **`map_layer_weights(source_weight: Tensor, alpha: float, theta: float) -> Tensor`**
   ```python
   """
   Mapeia peso de uma camada usando parÃ¢metros espectrais

   Pipeline:
       source_weight â†’ quaternion_rotation(Î¸) â†’
       modulate(Î±) â†’ leech_project â†’ psiqrh_weight

   Args:
       source_weight: Peso fonte (GPT-2)
       alpha: ParÃ¢metro Î± da anÃ¡lise espectral
       theta: Fase Î¸ da anÃ¡lise espectral

   Returns:
       Peso mapeado para Î¨QRH
   """
   ```

5. **`map_spectral_to_state_dict(source_state_dict: Dict, spectral_params: Dict) -> Dict`**
   ```python
   """
   Mapeia state_dict completo usando parÃ¢metros espectrais

   Args:
       source_state_dict: State dict do modelo fonte
       spectral_params: ParÃ¢metros espectrais por camada
           {
               'layer_0': {'alpha': 1.4, 'theta': -0.5},
               'layer_1': {'alpha': 1.6, 'theta': 0.2},
               ...
           }

   Returns:
       State dict Î¨QRH com pesos mapeados
   """
   ```

#### Tarefa 2.2: Atualizar `convert_model_spectral.py`
**Arquivo:** `scripts/convert_model_spectral.py`

**MudanÃ§as:**

```python
# Adicionar import
from src.utils.spectral_weight_mapper import map_spectral_to_state_dict

def save_converted_model(
    converted_params: dict,
    output_dir: Path,
    source_info: dict
):
    # ... cÃ³digo atual (salva JSON) ...

    # âœ… ADICIONAR: Mapear e salvar state_dict
    print("\nğŸ’¾ Mapeando pesos usando parÃ¢metros espectrais...")

    # Verificar se temos source_model
    if 'source_model' in source_info and hasattr(source_info['source_model'], 'state_dict'):
        source_state_dict = source_info['source_model'].state_dict()

        # Mapear pesos
        psiqrh_state_dict = map_spectral_to_state_dict(
            source_state_dict,
            converted_params['converted_params']
        )

        # Salvar state_dict
        state_dict_path = output_dir / "pytorch_model.bin"
        torch.save(psiqrh_state_dict, state_dict_path)
        print(f"âœ… State dict mapeado salvo: {state_dict_path}")
        print(f"   NÃºmero de tensores: {len(psiqrh_state_dict)}")

        # Calcular tamanho
        total_params = sum(t.numel() for t in psiqrh_state_dict.values())
        print(f"   Total de parÃ¢metros: {total_params:,}")

    else:
        print("âš ï¸  Source model nÃ£o disponÃ­vel - state_dict nÃ£o serÃ¡ salvo")
        print("   Apenas metadata espectral serÃ¡ salva")
```

**Atualizar funÃ§Ã£o main():**

```python
def main():
    # ... cÃ³digo atual ...

    # Executar conversÃ£o
    try:
        report = converter.convert_model(source_model, ...)

        # âœ… Passar source_model para save_converted_model
        source_info = {
            'model_type': source_model.__class__.__name__,
            'source': args.source,
            'source_model': source_model  # â† ADICIONAR
        }

        save_converted_model(report, output_path, source_info)

    except Exception as e:
        # ... tratamento de erro ...
```

#### Tarefa 2.3: Atualizar `complete_spectral_pipeline.py`
**Arquivo:** `examples/complete_spectral_pipeline.py`

**MudanÃ§as na funÃ§Ã£o `_load_psiqrh_model()`:**

```python
def _load_psiqrh_model(self):
    """Carrega modelo Î¨QRH convertido espectralmente"""

    print("\nğŸ—ï¸  Carregando PsiQRHTransformer nativo...")

    # Carregar metadata espectral
    metadata_path = self.model_dir / "spectral_metadata.json"
    if metadata_path.exists():
        with open(metadata_path) as f:
            metadata = json.load(f)
        print(f"âœ… Metadata espectral carregada")
        print(f"   D mÃ©dio: {metadata.get('avg_fractal_dim', 'N/A'):.4f}")
        print(f"   Î± mÃ©dio: {metadata.get('avg_alpha', 'N/A'):.4f}")
    else:
        print("âš ï¸  Metadata espectral nÃ£o encontrada")
        metadata = {}

    # Carregar configuraÃ§Ã£o
    config_path = self.model_dir / "config.json"
    if config_path.exists():
        with open(config_path) as f:
            config = json.load(f)
    else:
        # ConfiguraÃ§Ã£o padrÃ£o
        config = {
            'model': {
                'vocab_size': 50000,
                'd_model': 256,
                'n_layers': 6,
                'n_heads': 8,
                'dim_feedforward': 1024,
                'max_seq_length': 512
            }
        }

    # Criar modelo
    self.psiqrh_model = PsiQRHTransformer(
        vocab_size=config['model'].get('vocab_size', 50000),
        d_model=config['model'].get('d_model', 256),
        n_layers=config['model'].get('n_layers', 6),
        n_heads=config['model'].get('n_heads', 8),
        max_seq_length=config['model'].get('max_seq_length', 512)
    ).to(self.device)

    # âœ… ADICIONAR: Carregar pesos convertidos
    weights_path = self.model_dir / "pytorch_model.bin"
    if weights_path.exists():
        print(f"\nğŸ’¾ Carregando pesos convertidos...")
        state_dict = torch.load(weights_path, map_location=self.device)
        self.psiqrh_model.load_state_dict(state_dict, strict=False)
        print(f"âœ… Pesos convertidos carregados do GPT-2")
        print(f"   Total de parÃ¢metros: {sum(p.numel() for p in self.psiqrh_model.parameters()):,}")
    else:
        print("âš ï¸  pytorch_model.bin nÃ£o encontrado")
        print("   Usando inicializaÃ§Ã£o aleatÃ³ria (SEM conhecimento do GPT-2)")
        print("   Para usar conhecimento convertido, execute:")
        print(f"   make convert-model SOURCE=gpt2 OUTPUT={self.model_dir}")

    print(f"âœ… Modelo Î¨QRH carregado")
```

---

## ğŸ§ª Testes de ValidaÃ§Ã£o

### Teste 1: PreservaÃ§Ã£o de Conhecimento
**Arquivo:** `tests/test_spectral_weight_mapping.py`

```python
import torch
from transformers import AutoModel, AutoTokenizer
from src.utils.spectral_model_converter import SpectralModelConverter
from src.utils.spectral_weight_mapper import map_spectral_to_state_dict
from src.architecture.psiqrh_transformer import PsiQRHTransformer

def test_knowledge_preservation():
    """
    Testa se conhecimento Ã© preservado na conversÃ£o
    """
    # 1. Carregar GPT-2
    gpt2 = AutoModel.from_pretrained("gpt2")
    tokenizer = AutoTokenizer.from_pretrained("gpt2")

    # 2. Converter
    converter = SpectralModelConverter()
    report = converter.convert_model(gpt2)

    # 3. Mapear pesos
    psiqrh_state_dict = map_spectral_to_state_dict(
        gpt2.state_dict(),
        report['converted_params']
    )

    # 4. Criar modelo Î¨QRH
    psiqrh = PsiQRHTransformer(...)
    psiqrh.load_state_dict(psiqrh_state_dict, strict=False)

    # 5. Testar preservaÃ§Ã£o
    test_text = "Hello world"
    input_ids = tokenizer(test_text, return_tensors="pt")['input_ids']

    with torch.no_grad():
        gpt2_out = gpt2(input_ids)['last_hidden_state']
        psiqrh_out = psiqrh(input_ids)

    # 6. Calcular similaridade
    similarity = torch.nn.functional.cosine_similarity(
        gpt2_out.flatten(),
        psiqrh_out.flatten(),
        dim=0
    ).item()

    print(f"Similaridade de saÃ­da: {similarity:.4f}")
    assert similarity > 0.7, "Conhecimento nÃ£o foi preservado!"

    # 7. Validar energia
    gpt2_energy = torch.sum(gpt2_out ** 2).item()
    psiqrh_energy = torch.sum(psiqrh_out ** 2).item()
    energy_ratio = psiqrh_energy / (gpt2_energy + 1e-12)

    print(f"RazÃ£o de energia: {energy_ratio:.4f}")
    assert 0.9 <= energy_ratio <= 1.1, "ConservaÃ§Ã£o de energia violada!"

    print("âœ… Teste de preservaÃ§Ã£o de conhecimento passou!")
```

### Teste 2: Pipeline End-to-End
**Arquivo:** `tests/test_spectral_pipeline_e2e.py`

```python
def test_pipeline_end_to_end():
    """
    Testa pipeline completo: converter â†’ carregar â†’ gerar texto
    """
    # 1. Converter modelo
    os.system("make convert-model SOURCE=gpt2 OUTPUT=./temp_models/gpt2_test")

    # 2. Executar pipeline
    pipeline = SpectralPipelineComplete("./temp_models/gpt2_test")

    # 3. Processar texto
    result = pipeline.process("Hello world")

    # 4. Verificar saÃ­da
    assert result['generated_text'].strip() != "", "SaÃ­da vazia!"
    assert len(result['generated_text']) > 5, "SaÃ­da muito curta!"

    # 5. Verificar mÃ©tricas
    assert 'fci' in result['consciousness_metrics']
    assert 'alpha' in result

    print(f"âœ… Pipeline E2E passou!")
    print(f"   Input: Hello world")
    print(f"   Output: {result['generated_text'][:50]}...")
    print(f"   FCI: {result['consciousness_metrics']['fci']}")
```

---

## ğŸ“Š CritÃ©rios de Sucesso

### âœ… ImplementaÃ§Ã£o Completa
- [ ] `spectral_weight_mapper.py` criado e testado
- [ ] `convert_model_spectral.py` atualizado
- [ ] `complete_spectral_pipeline.py` atualizado
- [ ] Testes unitÃ¡rios passando

### âœ… ValidaÃ§Ã£o Funcional
- [ ] ConversÃ£o salva `pytorch_model.bin`
- [ ] Pipeline carrega pesos convertidos
- [ ] Similaridade GPT-2 â†” Î¨QRH > 0.7
- [ ] ConservaÃ§Ã£o de energia: 0.9 â‰¤ R â‰¤ 1.1

### âœ… GeraÃ§Ã£o de Texto
- [ ] Input: "Hello world" â†’ Output: texto coerente
- [ ] FCI > 0.0 (nÃ£o mais sempre 0.0)
- [ ] Texto gerado > 10 caracteres (nÃ£o apenas espaÃ§os)

---

## ğŸ”„ Workflow de Desenvolvimento

### 1. Implementar Mapeador
```bash
# Criar arquivo
vim src/utils/spectral_weight_mapper.py

# Implementar funÃ§Ãµes:
# - quaternion_from_phase()
# - apply_quaternion_rotation()
# - leech_project()
# - map_layer_weights()
# - map_spectral_to_state_dict()

# Testar isoladamente
python3 -c "
from src.utils.spectral_weight_mapper import *
import torch
w = torch.randn(100, 100)
q = quaternion_from_phase(0.5)
w_rot = apply_quaternion_rotation(w, q, 1.5)
print(f'Shape: {w_rot.shape}')
print(f'Norm ratio: {torch.norm(w_rot) / torch.norm(w):.4f}')
"
```

### 2. Atualizar ConversÃ£o
```bash
# Editar convert_model_spectral.py
vim scripts/convert_model_spectral.py

# Testar conversÃ£o
make convert-model SOURCE=gpt2 OUTPUT=./temp_models/gpt2_test

# Verificar saÃ­da
ls -lh ./temp_models/gpt2_test/
# Deve mostrar: pytorch_model.bin (novo!)
```

### 3. Atualizar Pipeline
```bash
# Editar pipeline
vim examples/complete_spectral_pipeline.py

# Testar pipeline
python3 examples/complete_spectral_pipeline.py ./temp_models/gpt2_test

# Verificar saÃ­da
# Input: "Hello world"
# Output: DEVE ter texto real (nÃ£o espaÃ§os)
```

### 4. Validar Completo
```bash
# Rodar testes
python3 tests/test_spectral_weight_mapping.py
python3 tests/test_spectral_pipeline_e2e.py

# Pipeline completo
make new-model SOURCE=gpt2 NAME=gpt2_validated

# Testar geraÃ§Ã£o
python3 chat_with_model.py --model gpt2_validated
```

---

## ğŸ“ Checklist Final

### Antes do Commit
- [ ] CÃ³digo documentado (docstrings)
- [ ] Testes unitÃ¡rios passando
- [ ] Pipeline E2E funcional
- [ ] GeraÃ§Ã£o de texto validada
- [ ] DocumentaÃ§Ã£o atualizada

### Antes do Deploy
- [ ] `make convert-model` salva `pytorch_model.bin`
- [ ] `complete_spectral_pipeline.py` carrega pesos
- [ ] Similaridade > 0.7
- [ ] Energia conservada (0.9-1.1)
- [ ] Texto gerado coerente

---

## ğŸ¯ Resultado Final Esperado

```bash
# 1. Converter GPT-2
$ make convert-model SOURCE=gpt2 OUTPUT=./models/gpt2_psiqrh

ğŸ“Š PASSO 1: AnÃ¡lise Espectral do Modelo Antigo
âœ… transformer.h.0.attn.c_attn.weight: Î²=1.234, D=0.883, RÂ²=0.956
âœ… transformer.h.1.attn.c_attn.weight: Î²=1.456, D=0.772, RÂ²=0.934
...
ğŸ’¾ Mapeando pesos usando parÃ¢metros espectrais...
âœ… State dict mapeado salvo: ./models/gpt2_psiqrh/pytorch_model.bin
   Total de parÃ¢metros: 124,439,808

# 2. Executar pipeline
$ python3 examples/complete_spectral_pipeline.py ./models/gpt2_psiqrh

ğŸ—ï¸  Carregando PsiQRHTransformer nativo...
âœ… Metadata espectral carregada
   D mÃ©dio: 0.8835
   Î± mÃ©dio: 1.4521
ğŸ’¾ Carregando pesos convertidos...
âœ… Pesos convertidos carregados do GPT-2
   Total de parÃ¢metros: 124,439,808

ğŸ§ª Testando com 3 entradas...

ğŸ“ Teste 1: "Hello world"
   âœ… Texto gerado: "Hello world! How can I help you today? I'm an AI..."
   ğŸ“Š FCI: 0.78 (Estado: MEDITAÃ‡ÃƒO)
   âš¡ Î±: 1.450
   ğŸŒŠ D: 0.883

ğŸ“ Teste 2: "Quantum physics is fascinating"
   âœ… Texto gerado: "Quantum physics is fascinating because it describes..."
   ğŸ“Š FCI: 0.92 (Estado: EMERGÃŠNCIA)
   âš¡ Î±: 1.523
   ğŸŒŠ D: 1.015

âœ… Pipeline completo validado!
   Conhecimento do GPT-2 preservado via conversÃ£o espectral Î¨QRH!
```

---

**PrÃ³ximo passo:** Implementar `spectral_weight_mapper.py` conforme especificaÃ§Ã£o acima.
