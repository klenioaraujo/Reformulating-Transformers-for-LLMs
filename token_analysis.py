#!/usr/bin/env python3
"""
Token Resonance Analysis - Œ®QRH Optical Probe Diagnostics
=========================================================

Analyzes the token resonance patterns from the Œ®QRH optical probe
to understand why certain tokens are selected and identify issues.
"""

import numpy as np
from typing import Dict, List, Tuple

def analyze_token_resonance_patterns():
    """
    Analyze the token resonance patterns from the provided pipeline outputs.
    """

    print("üî¨ TOKEN RESONANCE ANALYSIS - Œ®QRH OPTICAL PROBE")
    print("=" * 60)

    # Data from the user's provided outputs
    resonance_data = [
        {
            'iteration': 1,
            'resonance_spectrum': {
                1: 0.000217,
                3: 0.000193,
                21: 0.000191,
                23: 0.000182,
                19: 0.000174
            },
            'selected_token': 1,
            'max_resonance': 0.000217,
            'echo_quality': 1.0000,
            'vocab_size': 34
        },
        {
            'iteration': 2,
            'resonance_spectrum': {
                1: 0.000193,
                3: 0.000162,
                17: 0.000159,
                15: 0.000144,
                19: 0.000137
            },
            'selected_token': 1,
            'max_resonance': 0.000193,
            'echo_quality': 1.0000,
            'vocab_size': 34
        },
        {
            'iteration': 3,
            'resonance_spectrum': {
                8: 0.000152,
                1: 0.000146,
                17: 0.000124,
                15: 0.000123,
                10: 0.000113
            },
            'selected_token': 8,
            'max_resonance': 0.000152,
            'echo_quality': 1.0000,
            'vocab_size': 34
        }
    ]

    print("üìä ANALYZING RESONANCE PATTERNS ACROSS ITERATIONS")
    print("-" * 50)

    # Analyze resonance distribution
    all_resonances = []
    token_frequencies = {}
    max_resonances = []

    for data in resonance_data:
        spectrum = data['resonance_spectrum']
        all_resonances.extend(spectrum.values())
        max_resonances.append(data['max_resonance'])

        for token, resonance in spectrum.items():
            if token not in token_frequencies:
                token_frequencies[token] = []
            token_frequencies[token].append(resonance)

    # Statistical analysis
    resonance_array = np.array(all_resonances)
    print("\nüî¢ STATISTICAL ANALYSIS:")
    print(f"   ‚Ä¢ Total resonance measurements: {len(resonance_array)}")
    print(f"   ‚Ä¢ Mean resonance: {resonance_array.mean():.6f}")
    print(f"   ‚Ä¢ Max resonance: {resonance_array.max():.6f}")
    print(f"   ‚Ä¢ Min resonance: {resonance_array.min():.6f}")
    print(f"   ‚Ä¢ Standard deviation: {resonance_array.std():.6f}")
    print(f"   ‚Ä¢ Range: {resonance_array.max() - resonance_array.min():.6f}")

    # Identify concerning patterns
    print("\n‚ö†Ô∏è  CRITICAL ISSUES IDENTIFIED:")
    print(f"   ‚Ä¢ Very low resonance values (< 0.001) indicate weak optical coupling")
    print(f"   ‚Ä¢ Resonance range is only {resonance_array.max() - resonance_array.min():.6f}")
    print(f"   ‚Ä¢ This suggests the optical probe is not effectively measuring the quaternion state")

    # Token selection analysis
    print("\nüéØ TOKEN SELECTION ANALYSIS:")
    selected_tokens = [data['selected_token'] for data in resonance_data]
    print(f"   ‚Ä¢ Selected tokens: {selected_tokens}")
    print(f"   ‚Ä¢ Token diversity: {len(set(selected_tokens))} unique tokens out of {len(selected_tokens)} selections")

    # Character mapping (assuming ASCII mapping)
    print("\nüî§ CHARACTER MAPPING (ASCII):")
    for token in sorted(set(selected_tokens)):
        char = chr(32 + token) if 32 + token < 127 else f"INVALID({32 + token})"
        print(f"   ‚Ä¢ Token {token} ‚Üí '{char}' (ASCII {32 + token})")

    # Resonance stability analysis
    print("\nüìà RESONANCE STABILITY:")
    stability_scores = []
    for i in range(len(resonance_data) - 1):
        current_max = resonance_data[i]['max_resonance']
        next_max = resonance_data[i + 1]['max_resonance']
        stability = 1.0 - abs(current_max - next_max) / max(current_max, next_max)
        stability_scores.append(stability)

    avg_stability = np.mean(stability_scores) if stability_scores else 0
    print(f"   ‚Ä¢ Average resonance stability: {avg_stability:.3f}")
    print(f"   ‚Ä¢ Echo quality consistently: {resonance_data[0]['echo_quality']:.4f}")

    # Root cause analysis
    print("\nüîç ROOT CAUSE ANALYSIS:")
    print("   1. OPTICAL PROBE SIMPLIFICATION:")
    print("      ‚Ä¢ Using psi_last.mean().item() (scalar) for coupling")
    print("      ‚Ä¢ Ignores the full 4D quaternion structure")
    print("      ‚Ä¢ Should use proper quaternion inner product")

    print("   2. RESONANCE CALCULATION:")
    print("      ‚Ä¢ f(Œª,t) = I‚ÇÄ¬∑sin(œât + Œ±Œª)¬∑exp[i(œât - kŒª + Œ≤Œª¬≤)]")
    print("      ‚Ä¢ Coupling: |‚ü®f(Œª,t), Œ®‚ü©|¬≤ where Œ® is scalar mean")
    print("      ‚Ä¢ Should be: |‚ü®f(Œª,t), Œ®‚ü©|¬≤ where Œ® is full quaternion")

    print("   3. VOCABULARY SIZE:")
    print(f"      ‚Ä¢ Only {resonance_data[0]['vocab_size']} tokens analyzed")
    print("      ‚Ä¢ May be too small for effective resonance discrimination")

    print("   4. CALIBRATION ISSUES:")
    print("      ‚Ä¢ Recalibration triggered (resson√¢ncia < 0.001)")
    print("      ‚Ä¢ Indicates fundamental measurement problem")

    # Recommendations
    print("\nüí° RECOMMENDATIONS:")
    print("   1. Implement proper quaternion optical probe")
    print("   2. Use full 4D quaternion inner products")
    print("   3. Increase vocabulary size for better discrimination")
    print("   4. Implement multi-dimensional resonance measurement")
    print("   5. Add quaternion-specific coupling mechanisms")

    return {
        'resonance_stats': {
            'mean': float(resonance_array.mean()),
            'max': float(resonance_array.max()),
            'min': float(resonance_array.min()),
            'std': float(resonance_array.std())
        },
        'token_analysis': {
            'selected_tokens': selected_tokens,
            'unique_tokens': len(set(selected_tokens)),
            'token_frequencies': token_frequencies
        },
        'issues': [
            'Very low resonance values indicate weak coupling',
            'Optical probe uses scalar approximation instead of quaternion',
            'Limited vocabulary size affects discrimination',
            'Recalibration frequently triggered'
        ]
    }

def analyze_optical_probe_implementation():
    """
    Analyze the optical probe implementation in the code.
    """

    print("\nüîß OPTICAL PROBE IMPLEMENTATION ANALYSIS")
    print("=" * 50)

    print("Current implementation issues:")
    print("1. psi_mean = psi_last.mean().item()  # Single scalar!")
    print("2. coupling = np.abs(f_lambda * psi_mean)**2  # 1D coupling")
    print("3. Missing quaternion structure utilization")

    print("\nCorrect implementation should be:")
    print("1. Use full quaternion state Œ® ‚àà ‚Ñç")
    print("2. Implement quaternion inner product ‚ü®f, Œ®‚ü©")
    print("3. f(Œª,t) as quaternion wave function")
    print("4. |‚ü®f(Œª,t), Œ®‚ü©|¬≤ with proper quaternion norm")

if __name__ == "__main__":
    results = analyze_token_resonance_patterns()
    analyze_optical_probe_implementation()

    print("\nüìã SUMMARY:")
    print(f"   ‚Ä¢ Resonance values are critically low (< 0.001)")
    print(f"   ‚Ä¢ Optical probe needs quaternion-aware implementation")
    print(f"   ‚Ä¢ Token selection shows limited diversity")
    print(f"   ‚Ä¢ Fundamental measurement issue identified")