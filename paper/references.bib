@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{merity2016pointer,
  title={Pointer sentinel mixture models},
  author={Merity, Stephen and Xiong, Caiming and Bradbury, James and Socher, Richard},
  journal={arXiv preprint arXiv:1609.07843},
  year={2016}
}

@article{hirose2003complex,
  title={Complex-valued neural networks: Theories and applications},
  author={Hirose, Akira},
  journal={World Scientific},
  year={2003}
}

@article{trabelsi2018deep,
  title={Deep complex networks},
  author={Trabelsi, Chiheb and Bilaniuk, Olexa and Zhang, Ying and Serdyuk, Dmitriy and Subramanian, Sandeep and Santos, João Felipe and Mehri, Soroush and Rostamzadeh, Negar and Bengio, Yoshua and Pal, Christopher J},
  journal={arXiv preprint arXiv:1705.09792},
  year={2018}
}

@article{parcollet2018quaternion,
  title={Quaternion recurrent neural networks},
  author={Parcollet, Titouan and Morchid, Mohamed and Linarès, Georges},
  journal={arXiv preprint arXiv:1806.04418},
  year={2018}
}

@article{su2021roformer,
  title={Roformer: Enhanced transformer with rotary position embedding},
  author={Su, Jianlin and Lu, Yu and Pan, Shengfeng and Murtadha, Ahmed and Wen, Bo and Liu, Yunfeng},
  journal={arXiv preprint arXiv:2104.09864},
  year={2021}
}

@article{dong2022complex,
  title={Complex vision transformer: A unified transformer for complex vision tasks},
  author={Dong, Haoran and Bao, Jianmin and Yang, Wenhao and Chen, Dongdong and Yuan, Lu and Chen, Fang and Zhang, Lu and Yu, Dongdong and Chen, Hangbo and Zhu, Xiaowei and others},
  journal={arXiv preprint arXiv:2204.01697},
  year={2022}
}

@article{jaegle2021perceiver,
  title={Perceiver: General perception with iterative attention},
  author={Jaegle, Andrew and Gimeno, Felix and Brock, Andrew and Zisserman, Andrew and Vinyals, Oriol and Carreira, Joao},
  journal={arXiv preprint arXiv:2103.03206},
  year={2021}
}

@article{lee2019set,
  title={Set transformer: A framework for attention-based permutation-invariant neural networks},
  author={Lee, Juho and Lee, Yoonho and Kim, Jungtaek and Kosiorek, Adam and Choi, Seungjin and Teh, Yee Whye},
  journal={arXiv preprint arXiv:1810.00825},
  year={2019}
}