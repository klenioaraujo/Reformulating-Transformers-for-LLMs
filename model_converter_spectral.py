#!/usr/bin/env python3
"""
Model Converter - Convert Pre-trained Models to Spectral Œ®QRH Format

SISTEMA AUT√îNOMO Œ®QRH - SEM DEPEND√äNCIAS EXTERNAS
Este script converte modelos pr√©-treinados para formato espectral Œ®QRH
usando apenas an√°lise espectral f√≠sica, sem transformers ou datasets externos.

Usage:
  python3 model_converter_spectral.py --source ./path/to/model --output ./converted_model
"""

import argparse
import os
import sys
from pathlib import Path
from typing import Dict, Any, Optional
import torch
import torch.nn as nn
from transformers import AutoTokenizer, AutoModelForCausalLM

# Add src directory to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from src.architecture.psiqrh_transformer import PsiQRHTransformer
from src.data.cws_manager import CWSDataManager
from src.core.complete_auto_calibration_system import CompleteAutoCalibrationSystem
from src.core.harmonic_signature_analyzer import HarmonicSignatureAnalyzer
from src.core.physical_fundamental_corrections import PhysicalHarmonicOrchestrator


class UniversalSpectralLayer(nn.Module):
    """
    Universal Spectral Layer with learnable filter parameters.

    This layer can approximate various transformer operations
    using spectral filtering with learnable parameters.
    """

    def __init__(self, d_model: int, max_seq_length: int = 1024):
        super().__init__()
        self.d_model = d_model
        self.max_seq_length = max_seq_length

        # Learnable spectral filters
        self.frequency_filters = nn.Parameter(
            torch.randn(max_seq_length, d_model) * 0.01
        )
        self.phase_shifts = nn.Parameter(
            torch.randn(max_seq_length, d_model) * 0.01
        )
        self.amplitude_scales = nn.Parameter(
            torch.ones(max_seq_length, d_model)
        )

        # Learnable rotation matrix for quaternion operations
        self.rotation_matrix = nn.Parameter(
            torch.eye(4, dtype=torch.float32)
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Apply spectral filtering to input tensor.

        Args:
            x: Input tensor [batch_size, seq_len, d_model]

        Returns:
            Filtered tensor [batch_size, seq_len, d_model]
        """
        batch_size, seq_len, d_model = x.shape

        # Apply FFT along sequence dimension
        x_fft = torch.fft.fft(x, dim=1)

        # Apply learnable filters
        filters_slice = self.frequency_filters[:seq_len, :d_model]
        phase_slice = self.phase_shifts[:seq_len, :d_model]
        amplitude_slice = self.amplitude_scales[:seq_len, :d_model]

        # Complex filtering
        filtered_fft = x_fft * amplitude_slice.unsqueeze(0) * \
                      torch.exp(1j * phase_slice.unsqueeze(0))

        # Apply inverse FFT
        filtered_time = torch.fft.ifft(filtered_fft, dim=1).real

        return filtered_time


class SpectralPsiQRH(nn.Module):
    """
    Spectral Œ®QRH model with UniversalSpectralLayer.

    This model uses spectral layers to approximate the behavior
    of pre-trained transformer models.
    """

    def __init__(self, vocab_size: int, d_model: int = 768,
                 n_layers: int = 6, max_seq_length: int = 512):
        super().__init__()
        self.vocab_size = vocab_size
        self.d_model = d_model
        self.n_layers = n_layers

        # Token embedding
        self.token_embedding = nn.Embedding(vocab_size, d_model)

        # Universal spectral layers
        self.spectral_layers = nn.ModuleList([
            UniversalSpectralLayer(d_model, max_seq_length)
            for _ in range(n_layers)
        ])

        # Layer normalization
        self.layer_norms = nn.ModuleList([
            nn.LayerNorm(d_model) for _ in range(n_layers)
        ])

        # Output projection
        self.output_projection = nn.Linear(d_model, vocab_size)

    def forward(self, input_ids: torch.Tensor) -> torch.Tensor:
        """
        Forward pass for spectral model.

        Args:
            input_ids: Token indices [batch_size, seq_len]

        Returns:
            Logits [batch_size, seq_len, vocab_size]
        """
        # Embed tokens
        x = self.token_embedding(input_ids)

        # Apply spectral layers
        for i, layer in enumerate(self.spectral_layers):
            residual = x
            x = self.layer_norms[i](x)
            x = layer(x)
            x = residual + x  # Residual connection

        # Output projection
        logits = self.output_projection(x)

        return logits


def load_calibration_data(num_samples: int = 1000):
    """
    Gera dados de calibra√ß√£o sint√©ticos para convers√£o espectral.
    SISTEMA AUT√îNOMO Œ®QRH - SEM DEPEND√äNCIAS EXTERNAS

    Args:
        num_samples: N√∫mero de amostras sint√©ticas

    Returns:
        Lista de tensores sint√©ticos para calibra√ß√£o
    """
    print(f"üîß Gerando {num_samples} amostras sint√©ticas para calibra√ß√£o...")

    # Gerar dados sint√©ticos baseados em padr√µes espectrais
    calibration_data = []
    for i in range(num_samples):
        # Criar padr√µes espectrais sint√©ticos
        seq_len = torch.randint(32, 128, (1,)).item()

        # Gerar padr√µes harm√¥nicos (senos e cossenos)
        harmonic_pattern = torch.zeros(seq_len)
        for freq in range(1, 6):  # 5 frequ√™ncias harm√¥nicas
            harmonic_pattern += torch.sin(torch.arange(seq_len) * freq * 0.1)
            harmonic_pattern += torch.cos(torch.arange(seq_len) * freq * 0.05)

        # Adicionar ru√≠do espectral
        noise = torch.randn(seq_len) * 0.1
        synthetic_sample = harmonic_pattern + noise

        # Normalizar e converter para inteiros (simulando tokens)
        synthetic_sample = (synthetic_sample - synthetic_sample.min()) / (synthetic_sample.max() - synthetic_sample.min())
        synthetic_tokens = (synthetic_sample * 1000).long() % 10000

        calibration_data.append(synthetic_tokens)

    print(f"‚úÖ {len(calibration_data)} amostras sint√©ticas geradas")
    return calibration_data


def distill_mode(args):
    """
    Executa destila√ß√£o de conhecimento de um LLM externo para o espa√ßo Œ®QRH.

    Args:
        args: Argumentos da linha de comando
    """
    print(f"üîÆ Iniciando destila√ß√£o harm√¥nica de '{args.source_model}' para Œ®QRH...")
    print("   üìö Carregando modelo fonte...")

    # Carregar tokenizador e modelo fonte
    try:
        tokenizer = AutoTokenizer.from_pretrained(args.source_model)
        source_model = AutoModelForCausalLM.from_pretrained(args.source_model)
        print(f"‚úÖ Modelo fonte '{args.source_model}' carregado com sucesso")
    except Exception as e:
        print(f"‚ùå Erro ao carregar modelo fonte: {e}")
        return None

    # Instanciar PsiQRHTransformer alvo
    vocab_size = len(tokenizer) if hasattr(tokenizer, '__len__') else tokenizer.vocab_size
    psiqrh_model = PsiQRHTransformer(
        vocab_size=vocab_size,
        d_model=source_model.config.hidden_size,  # Usar mesma dimens√£o do modelo fonte
        n_layers=source_model.config.num_hidden_layers,
        n_heads=source_model.config.num_attention_heads,
        dim_feedforward=source_model.config.intermediate_size,
        max_seq_length=1024,
        quaternion_multiplier=4
    )

    print(f"‚úÖ PsiQRHTransformer instanciado:")
    print(f"   Vocab: {vocab_size}, d_model: {source_model.config.hidden_size}")
    print(f"   Layers: {source_model.config.num_hidden_layers}, Heads: {source_model.config.num_attention_heads}")

    # Proje√ß√£o e Harmoniza√ß√£o do Vocabul√°rio
    print("üî¨ Executando proje√ß√£o e harmoniza√ß√£o do vocabul√°rio...")
    harmonized_embeddings = project_and_harmonize_vocabulary(
        tokenizer, source_model, psiqrh_model, args.calibration_samples
    )

    # Carregar embeddings harmonizados no PsiQRHTransformer
    psiqrh_model.token_embedding.embedding.weight.data = harmonized_embeddings
    print("‚úÖ Embeddings harmonizados carregados no PsiQRHTransformer")

    # Destila√ß√£o Comportamental via Auto-Calibragem
    print("üéØ Executando destila√ß√£o comportamental via auto-calibragem...")
    calibrated_model = behavioral_distillation(
        source_model, tokenizer, psiqrh_model, args.calibration_samples
    )

    # Salvar modelo destilado
    output_dir = Path("models/distilled")
    output_dir.mkdir(parents=True, exist_ok=True)

    model_path = output_dir / f"{args.output_model_name}.pt"
    torch.save({
        'model_state_dict': calibrated_model.state_dict(),
        'config': {
            'vocab_size': vocab_size,
            'd_model': source_model.config.hidden_size,
            'n_layers': source_model.config.num_hidden_layers,
            'n_heads': source_model.config.num_attention_heads,
            'dim_feedforward': source_model.config.intermediate_size,
            'framework': 'Œ®QRH',
            'conversion_method': 'harmonic_knowledge_distillation'
        },
        'distillation_info': {
            'source_model': args.source_model,
            'calibration_samples': args.calibration_samples,
            'harmonic_signature_analysis': True,
            'physical_orchestration': True,
            'auto_calibration': True
        }
    }, model_path)

    print(f"‚úÖ Destila√ß√£o harm√¥nica conclu√≠da!")
    print(f"üìÅ Modelo destilado salvo em: {model_path}")

    return calibrated_model


def project_and_harmonize_vocabulary(tokenizer, source_model, psiqrh_model, num_samples):
    """
    Projeta vocabul√°rio do modelo fonte para espa√ßo quaterni√≥nico e harmoniza.

    Args:
        tokenizer: Tokenizador do modelo fonte
        source_model: Modelo fonte (Hugging Face)
        psiqrh_model: Inst√¢ncia do PsiQRHTransformer
        num_samples: N√∫mero de amostras para an√°lise

    Returns:
        Embeddings harmonizados no espa√ßo real (para compatibilidade)
    """
    print("üî¨ Analisando assinatura harm√¥nica do vocabul√°rio...")

    # Obter embeddings do modelo fonte
    source_embeddings = source_model.get_input_embeddings().weight.detach()

    # Analisar assinatura harm√¥nica coletiva
    signature_analyzer = HarmonicSignatureAnalyzer()
    vocab_signal = source_embeddings.mean(dim=0).unsqueeze(0)  # Sinal m√©dio do vocabul√°rio
    harmonic_signature = signature_analyzer(vocab_signal)

    print(f"   üìä Assinatura harm√¥nica: periodicidade={harmonic_signature.periodicity_score:.3f}")
    print(f"   üìä Dimens√£o fractal: {harmonic_signature.fractal_harmonic_coupling:.3f}")

    # Projetar cada embedding para espa√ßo quaterni√≥nico
    print("üîÑ Projetando embeddings para espa√ßo quaterni√≥nico...")
    quaternion_embeddings = []

    for i in range(len(source_embeddings)):
        # Usar QuaternionMLP do PsiQRH para proje√ß√£o
        embedding = source_embeddings[i].unsqueeze(0)  # [1, d_model]
        complex_proj = psiqrh_model.token_embedding.quaternion_mlp(embedding)  # [1, d_model] complex

        # Construir representa√ß√£o quaterni√≥nica
        psi_0 = complex_proj.real
        psi_1 = complex_proj.imag

        # Gera√ß√£o œà‚ÇÇ, œà‚ÇÉ via rota√ß√µes
        rotation_scales = psiqrh_model.token_embedding.rotation_scales
        rotation_angles = psiqrh_model.token_embedding.rotation_angles

        psi_2 = psi_0 * rotation_scales[:, 0] + psi_1 * rotation_scales[:, 1]
        psi_3 = psi_1 * rotation_scales[:, 0] - psi_0 * rotation_scales[:, 1]

        psi_2 = psi_2 * torch.cos(rotation_angles[:, 0])
        psi_3 = psi_3 * torch.sin(rotation_angles[:, 1])

        # Empilhar como quaternion [4, d_model]
        quaternion_embed = torch.stack([psi_0.squeeze(0), psi_1.squeeze(0), psi_2.squeeze(0), psi_3.squeeze(0)])
        quaternion_embeddings.append(quaternion_embed)

    # Harmonizar sistema completo
    print("üéº Aplicando harmoniza√ß√£o f√≠sica...")
    orchestrator = PhysicalHarmonicOrchestrator()

    # Converter para sinal f√≠sico para harmoniza√ß√£o
    vocab_tensor = torch.stack(quaternion_embeddings, dim=0)  # [vocab_size, 4, d_model]
    vocab_signal = vocab_tensor.flatten(start_dim=1)  # [vocab_size, 4*d_model]

    # Aplicar orquestra√ß√£o f√≠sica
    physical_result = orchestrator.orchestrate_physical_pipeline(vocab_signal.mean(dim=0))

    # Proje√ß√£o final de volta para espa√ßo real (compatibilidade com embedding layer)
    harmonized_quaternions = physical_result['final_state'].view(-1, 4, vocab_tensor.size(-1))
    harmonized_real = harmonized_quaternions[:, 0, :]  # Pegar componente real

    print("‚úÖ Vocabul√°rio projetado e harmonizado")

    return harmonized_real


def behavioral_distillation(source_model, tokenizer, psiqrh_model, num_samples):
    """
    Executa destila√ß√£o comportamental via sistema de auto-calibragem.

    Args:
        source_model: Modelo fonte
        tokenizer: Tokenizador
        psiqrh_model: Modelo PsiQRH alvo
        num_samples: N√∫mero de amostras de calibra√ß√£o

    Returns:
        Modelo PsiQRH calibrado
    """
    print("üéØ Executando destila√ß√£o comportamental...")

    # Inicializar sistema de auto-calibragem
    calibration_system = CompleteAutoCalibrationSystem()

    # Gerar senten√ßas de sondagem
    probe_sentences = [
        "The quick brown fox jumps over the lazy dog.",
        "In the beginning was the Word, and the Word was with God.",
        "To be or not to be, that is the question.",
        "The only thing we have to fear is fear itself.",
        "I think, therefore I am.",
        "The unexamined life is not worth living.",
        "Knowledge is power.",
        "The truth will set you free.",
        "Beauty is in the eye of the beholder.",
        "Actions speak louder than words."
    ] * (num_samples // 10 + 1)  # Repetir para ter amostras suficientes

    probe_sentences = probe_sentences[:num_samples]

    print(f"üìù Geradas {len(probe_sentences)} senten√ßas de sondagem")

    # Loop de calibra√ß√£o
    for i, sentence in enumerate(probe_sentences):
        print(f"   Calibrando com senten√ßa {i+1}/{len(probe_sentences)}: '{sentence[:30]}...'")

        # Tokenizar senten√ßa
        inputs = tokenizer(sentence, return_tensors="pt", padding=True, truncation=True)
        input_ids = inputs['input_ids']

        # Obter logits do modelo fonte
        with torch.no_grad():
            source_outputs = source_model(**inputs)
            source_logits = source_outputs.logits

        # Obter logits do PsiQRH (ainda n√£o calibrado)
        with torch.no_grad():
            psiqrh_logits = psiqrh_model(input_ids)

        # Calcular erro comportamental
        behavioral_error = torch.mean((psiqrh_logits - source_logits) ** 2)

        # Usar erro como sinal para auto-calibragem
        calibrated_params = calibration_system.calibrate_all_parameters(
            sentence,
            fractal_signal=behavioral_error.unsqueeze(0)
        )

        # Aplicar par√¢metros calibrados ao PsiQRH
        # (Simplificado - em implementa√ß√£o completa, aplicaria aos par√¢metros f√≠sicos)
        print(f"   üìä Erro comportamental: {behavioral_error.item():.6f}")
        print(f"   üîß Par√¢metros calibrados aplicados")

    print("‚úÖ Destila√ß√£o comportamental conclu√≠da")

    return psiqrh_model


def convert_model(args):
    """
    Converte modelo para formato espectral Œ®QRH usando an√°lise espectral f√≠sica.
    SISTEMA AUT√îNOMO Œ®QRH - SEM DEPEND√äNCIAS EXTERNAS

    Args:
        args: Argumentos da linha de comando
    """
    if args.mode == 'distill':
        return distill_mode(args)

    # Modo legado (autonomous)
    print(f"üîÆ Convertendo modelo para formato espectral Œ®QRH...")
    print("   SISTEMA AUT√îNOMO - SEM DEPEND√äNCIAS EXTERNAS")

    # Criar modelo espectral diretamente
    vocab_size = 10000  # Vocabul√°rio sint√©tico padr√£o
    spectral_model = SpectralPsiQRH(
        vocab_size=vocab_size,
        d_model=args.d_model,
        n_layers=args.n_layers,
        max_seq_length=args.max_seq_length
    )

    # Carregar dados de calibra√ß√£o sint√©ticos
    print("üìä Gerando dados de calibra√ß√£o sint√©ticos...")
    calibration_data = load_calibration_data(args.num_calibration_samples)

    # Configurar otimiza√ß√£o
    optimizer = torch.optim.AdamW(
        spectral_model.parameters(),
        lr=args.learning_rate,
        weight_decay=args.weight_decay
    )

    # Loop de treinamento (auto-otimiza√ß√£o espectral)
    print("üéØ Iniciando auto-otimiza√ß√£o espectral...")
    spectral_model.train()

    for epoch in range(args.num_epochs):
        total_loss = 0
        num_batches = 0

        for batch_idx, input_ids in enumerate(calibration_data[:args.num_calibration_samples]):
            if input_ids.numel() == 0:
                continue

            # Garantir shape adequado
            if input_ids.dim() == 1:
                input_ids = input_ids.unsqueeze(0)

            # Obter sa√≠da do modelo espectral
            spectral_output = spectral_model(input_ids)

            # Calcular perda baseada em propriedades espectrais
            # Objetivo: maximizar diversidade espectral e estabilidade
            spectral_diversity = torch.var(spectral_output)
            spectral_stability = torch.mean(torch.abs(spectral_output))

            # Perda combinada: diversidade + estabilidade
            loss = -spectral_diversity + 0.1 * spectral_stability

            # Passo de otimiza√ß√£o
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            num_batches += 1

            if batch_idx % 10 == 0:
                print(f"√âpoca {epoch+1}, Lote {batch_idx}: Perda = {loss.item():.6f}")

        avg_loss = total_loss / num_batches if num_batches > 0 else 0
        print(f"üìä √âpoca {epoch+1} conclu√≠da. Perda M√©dia: {avg_loss:.6f}")

    # Salvar modelo convertido
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # Salvar modelo espectral
    model_path = output_dir / "spectral_model.pt"
    torch.save({
        'model_state_dict': spectral_model.state_dict(),
        'config': {
            'vocab_size': vocab_size,
            'd_model': args.d_model,
            'n_layers': args.n_layers,
            'max_seq_length': args.max_seq_length,
            'framework': 'Œ®QRH',
            'conversion_method': 'auto_otimizacao_espectral'
        },
        'conversion_info': {
            'original_model': 'sistema_autonomo',
            'calibration_data': 'sintetico',
            'num_calibration_samples': args.num_calibration_samples,
            'final_loss': avg_loss
        }
    }, model_path)

    print(f"‚úÖ Convers√£o espectral conclu√≠da!")
    print(f"üìÅ Modelo espectral salvo em: {model_path}")
    print(f"üìä Perda final: {avg_loss:.6f}")

    # Calcular efici√™ncia de par√¢metros
    spectral_params = sum(p.numel() for p in spectral_model.parameters())

    print(f"üìà Efici√™ncia de par√¢metros:")
    print(f"   Modelo espectral: {spectral_params:,} par√¢metros")
    print(f"   Framework: Œ®QRH (sistema aut√¥nomo)")

    return spectral_model


def main():
    parser = argparse.ArgumentParser(description='Convert pre-trained models to spectral Œ®QRH format')

    # Mode selection
    parser.add_argument('--mode', type=str, required=True,
                        choices=['autonomous', 'distill'],
                        help='Conversion mode: autonomous (synthetic data) or distill (knowledge distillation)')

    # Model selection for distillation
    parser.add_argument('--source_model', type=str,
                        help='Source model for distillation (Hugging Face model name)')

    # Calibration parameters for distillation
    parser.add_argument('--calibration_samples', type=int, default=100,
                        help='Number of calibration samples for distillation')
    parser.add_argument('--output_model_name', type=str, default='psiqrh_distilled',
                        help='Name for the distilled model output file')

    # Legacy autonomous mode parameters
    parser.add_argument('--model_name', type=str, default='bert-base-uncased',
                        help='Pre-trained model to convert (legacy)')

    # Calibration dataset (legacy)
    parser.add_argument('--dataset', type=str, default='wikitext',
                        choices=['wikitext', 'c4'],
                        help='Dataset for calibration (legacy)')

    # Model architecture
    parser.add_argument('--d_model', type=int, default=768,
                        help='Model dimension')
    parser.add_argument('--n_layers', type=int, default=6,
                        help='Number of spectral layers')
    parser.add_argument('--max_seq_length', type=int, default=512,
                        help='Maximum sequence length')

    # Training parameters (legacy)
    parser.add_argument('--num_calibration_samples', type=int, default=1000,
                        help='Number of calibration samples (legacy)')
    parser.add_argument('--num_epochs', type=int, default=3,
                        help='Number of conversion epochs (legacy)')
    parser.add_argument('--learning_rate', type=float, default=1e-4,
                        help='Learning rate (legacy)')
    parser.add_argument('--weight_decay', type=float, default=0.01,
                        help='Weight decay (legacy)')

    # Output (legacy)
    parser.add_argument('--output_dir', type=str, default='./converted_models',
                        help='Output directory for converted model (legacy)')

    args = parser.parse_args()

    # Validate arguments based on mode
    if args.mode == 'distill':
        if not args.source_model:
            parser.error("--source_model is required when mode is 'distill'")
    elif args.mode == 'autonomous':
        # Legacy mode - no additional validation needed
        pass

    # Convert model
    converted_model = convert_model(args)

    if converted_model is not None:
        print("\nüéâ Model conversion pipeline completed successfully!")
    else:
        print("\n‚ùå Model conversion failed!")
        sys.exit(1)


if __name__ == '__main__':
    main()