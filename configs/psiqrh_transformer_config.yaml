# Configura√ß√£o Completa do PsiQRH Transformer
# ===========================================
#
# Configura√ß√£o centralizada para o transformer Œ®QRH completo,
# integrando todos os componentes sem hardcoding.

psiqrh_transformer:
  # ===== Arquitetura B√°sica =====
  model:
    vocab_size: 50000
    d_model: 64                    # Dimens√£o base (ser√° multiplicado por 4 para quaternion)
    n_layers: 6
    n_heads: 8
    dim_feedforward: 256
    max_seq_length: 1024
    quaternion_multiplier: 4       # Multiplicador quaterni√¥nico

  # ===== Componentes Ativ√°veis =====
  components:
    use_kuramoto: true             # Habilitar Kuramoto Spectral Layer
    use_working_memory: true       # Habilitar Conscious Working Memory
    use_phase_sync: true           # Habilitar Phase Synchronization
    use_cognitive_filters: false   # Habilitar Semantic Adaptive Filters
    use_fractal_analysis: true     # Habilitar an√°lise fractal em tempo real

  # ===== Embedding e Codifica√ß√£o Posicional =====
  embedding:
    type: 'quaternion'             # 'quaternion' ou 'standard'
    dropout: 0.1
    learned_positional: false      # Se True, usa embedding aprend√≠vel

  positional_encoding:
    type: 'spectral'               # 'spectral', 'sinusoidal', 'learned'
    max_len: 5000
    frequency_init: 'random'       # 'random' ou 'fixed'
    frequency_scale: 6.283185307   # 2œÄ

  # ===== Attention Configuration =====
  attention:
    type: 'spectral'               # 'spectral', 'standard', 'flash'
    use_spectral_filter: true
    adaptive_filter_dim: 256       # Dimens√£o do filtro adaptativo
    dropout: 0.1
    attention_dropout: 0.1

  # ===== Feed-Forward Network =====
  feedforward:
    activation: 'spectral'         # 'spectral', 'gelu', 'relu', 'swish'
    use_adaptive_dropout: true
    dropout: 0.1
    intermediate_dropout: 0.1

  # ===== Kuramoto Integration =====
  kuramoto:
    enabled: true                  # Redundante com components.use_kuramoto, mas expl√≠cito
    config_path: 'configs/kuramoto_config.yaml'
    grid_size: 32
    coupling_strength: 1.0
    device: 'cpu'
    layer_scale_init: 0.1          # Escala inicial para conex√£o residual

  # ===== Phase Synchronization =====
  phase_synchronization:
    enabled: true
    grid_size: 32
    sync_threshold: 0.9
    extract_rhythms: true          # Extrair ritmos theta/alpha/beta/gamma
    create_phase_maps: true        # Criar mapas topogr√°ficos
    noise_filtering: true          # Filtrar ru√≠do via sincroniza√ß√£o coletiva
    visualization_enabled: false   # Habilitar visualiza√ß√µes autom√°ticas

  # ===== Working Memory =====
  working_memory:
    enabled: true
    config_path: 'configs/working_memory_config.yaml'
    memory_size: 1024
    embed_dim: 64
    layer_scale_init: 0.1
    influence_weight: 0.3          # Peso da mem√≥ria na sa√≠da

  # ===== Cognitive Filters =====
  cognitive_filters:
    enabled: false                 # Desabilitado por padr√£o
    config_path: 'configs/cognitive_filters_config.yaml'
    apply_after: 'attention'       # 'attention', 'kuramoto', 'memory'

  # ===== Harmonic Layer Coupling =====
  harmonic_coupling:
    enabled: true                  # Sincroniza√ß√£o harm√¥nica entre camadas
    config_path: 'configs/harmonic_coupling_config.yaml'
    preset: 'standard'             # 'standard', 'strong', 'weak', 'adaptive'

  # ===== Fractal Analysis =====
  fractal_analysis:
    enabled: true
    analysis_frequency: 1000       # A cada N passos
    real_time: true
    update_alpha: true             # Atualizar par√¢metro Œ± baseado em D
    dimension_range: [1.0, 3.0]
    target_dimension: 2.0

  # ===== Normaliza√ß√£o =====
  normalization:
    type: 'quaternion_layer_norm'  # 'quaternion_layer_norm', 'layer_norm', 'rms_norm'
    eps: 1.0e-6
    elementwise_affine: true

  # ===== Layer Scaling =====
  layer_scaling:
    use_layer_scale: true
    init_values:
      attention: 1.0
      kuramoto: 0.1                # Reduzido para estabilidade
      memory: 0.1
      feedforward: 1.0

  # ===== Regulariza√ß√£o =====
  regularization:
    dropout: 0.1
    attention_dropout: 0.1
    feedforward_dropout: 0.1
    spectral_dropout: 0.0
    path_dropout: 0.0              # Stochastic depth

  # ===== Conserva√ß√£o de Energia =====
  energy_conservation:
    enabled: true
    tolerance: 0.05                # [0.95, 1.05]
    apply_normalization: true      # Normalizar para conservar energia
    log_violations: true           # Log quando energia n√£o conservada

  # ===== Treinamento =====
  training:
    gradient_checkpointing: false  # Economizar mem√≥ria
    mixed_precision: false         # AMP (Automatic Mixed Precision)
    compile_model: false           # torch.compile (PyTorch 2.0+)

  # ===== Infer√™ncia =====
  inference:
    use_cache: true                # Cache de aten√ß√£o
    beam_size: 1                   # Beam search
    temperature: 1.0
    top_k: 50
    top_p: 0.9

  # ===== Performance =====
  performance:
    device: 'cpu'                  # 'cpu', 'cuda', 'mps'
    dtype: 'float32'               # 'float32', 'float16', 'bfloat16'
    num_workers: 4
    pin_memory: true

  # ===== Visualiza√ß√£o e Debug =====
  visualization:
    enabled: false                 # Habilitar visualiza√ß√µes autom√°ticas
    save_phase_maps: false
    save_frequency: 100            # Salvar a cada N steps
    output_dir: 'visualizations/'

  debug:
    log_shapes: false
    log_energy: false
    log_gradients: false
    log_metrics: true
    verbose: false

  # ===== Checkpointing =====
  checkpointing:
    save_frequency: 1000           # Salvar a cada N steps
    checkpoint_dir: 'checkpoints/'
    keep_last_n: 5                 # Manter √∫ltimos N checkpoints
    save_optimizer: true

# ===== Presets R√°pidos =====
presets:
  # Configura√ß√£o minimalista para testes r√°pidos
  minimal:
    model:
      d_model: 32
      n_layers: 2
      n_heads: 4
      dim_feedforward: 128
    components:
      use_kuramoto: false
      use_working_memory: false
      use_phase_sync: false

  # Configura√ß√£o padr√£o balanceada
  standard:
    model:
      d_model: 64
      n_layers: 6
      n_heads: 8
      dim_feedforward: 256
    components:
      use_kuramoto: true
      use_working_memory: true
      use_phase_sync: true

  # Configura√ß√£o completa para produ√ß√£o
  full:
    model:
      d_model: 128
      n_layers: 12
      n_heads: 16
      dim_feedforward: 512
    components:
      use_kuramoto: true
      use_working_memory: true
      use_phase_sync: true
      use_cognitive_filters: true

# ======================================================================
# üî¨ INSTRU√á√ïES DE VALIDA√á√ÉO DO N√öCLEO
# ======================================================================
# Para garantir que qualquer altera√ß√£o nesta configura√ß√£o n√£o quebre as
# propriedades matem√°ticas fundamentais do sistema Œ®QRH (como a
# conserva√ß√£o de energia), execute o teste de valida√ß√£o do n√∫cleo.
#
# Este teste verifica:
#   1. Conserva√ß√£o de Energia
#   2. Teorema de Parseval (Corretude da FFT)
#   3. Efici√™ncia de Mem√≥ria e Par√¢metros
#   4. Propriedades do Quaternion Rotacional
#
# COMO EXECUTAR:
# No diret√≥rio raiz do projeto, execute o seguinte comando:
#
# make validate-core
#
# Se o teste falhar, revise suas configura√ß√µes ou o c√≥digo modificado.
# A normaliza√ß√£o de energia agora √© obrigat√≥ria para garantir a
# estabilidade do sistema.
# ======================================================================

  # Configura√ß√£o para experimentos com consci√™ncia
  consciousness:
    model:
      d_model: 64
      n_layers: 8
      n_heads: 8
      dim_feedforward: 256
    components:
      use_kuramoto: true
      use_working_memory: true
      use_phase_sync: true
    fractal_analysis:
      analysis_frequency: 100      # An√°lise mais frequente
      real_time: true
