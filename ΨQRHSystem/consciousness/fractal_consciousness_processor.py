#!/usr/bin/env python3
"""
Fractal Consciousness Processor - Core Engine
=============================================

Implementa o processador central de consciÃªncia fractal usando
as equaÃ§Ãµes matemÃ¡ticas fundamentais da dinÃ¢mica consciente.

EquaÃ§Ã£o Mestra: âˆ‚P(Ïˆ,t)/âˆ‚t = -âˆ‡Â·[F(Ïˆ)P] + Dâˆ‡Â²P
Campo Fractal: F(Ïˆ) = -âˆ‡V(Ïˆ) + Î·_fractal(t)
Potencial Multifractal: V(Ïˆ) = Î£(k=1 to âˆž) Î»_k/k! * Ïˆ^k * cos(2Ï€ log k)
"""

import torch
import torch.nn as nn
import numpy as np
from typing import Dict, Any, Tuple, Optional
import time
from dataclasses import dataclass
import warnings

from .consciousness_states import ConsciousnessState, StateClassifier
from .fractal_field_calculator import FractalFieldCalculator
from .neural_diffusion_engine import NeuralDiffusionEngine
from .consciousness_metrics import ConsciousnessMetrics


@dataclass
class ConsciousnessConfig:
    """ConfiguraÃ§Ã£o para o processador de consciÃªncia fractal."""
    embedding_dim: int = 256
    sequence_length: int = 64
    fractal_dimension_range: Tuple[float, float] = (1.0, 3.0)
    diffusion_coefficient_range: Tuple[float, float] = (0.01, 10.0)
    consciousness_frequency_range: Tuple[float, float] = (0.5, 5.0)
    phase_consciousness: float = 0.7854  # Ï€/4
    device: str = "cpu"

    # Carregar configuraÃ§Ãµes do arquivo YAML
    def __post_init__(self):
        import yaml
        import os

        try:
            config_path = os.path.join('configs', 'fractal_consciousness_config.yaml')
            with open(config_path, 'r') as f:
                config = yaml.safe_load(f)

            # ParÃ¢metros de dinÃ¢mica consciente
            dynamics = config.get('consciousness_dynamics', {})
            self.time_step = dynamics.get('time_step', 0.05)
            self.max_iterations = dynamics.get('max_iterations', 200)
            self.convergence_threshold = dynamics.get('convergence_threshold', 0.05)

            # ParÃ¢metros de estabilidade numÃ©rica
            stability = config.get('numerical_stability', {})
            self.epsilon = stability.get('epsilon', 1e-10)
            self.nan_replacement_noise_scale = stability.get('nan_replacement_noise_scale', 1e-6)
            self.min_field_magnitude = stability.get('min_field_magnitude', 1e-8)
            self.entropy_safe_offset = stability.get('entropy_safe_offset', 1e-10)

            # ParÃ¢metros de regularizaÃ§Ã£o de campo
            field = config.get('field_regularization', {})
            self.max_field_magnitude = field.get('max_field_magnitude', 10.0)
            kernel = field.get('field_smoothing_kernel', [0.25, 0.5, 0.25])
            self.field_smoothing_kernel = tuple(kernel)

            # ParÃ¢metros de inicializaÃ§Ã£o
            init = config.get('initialization', {})
            self.spectral_weight = init.get('spectral_weight', 0.4)
            self.semantic_weight = init.get('semantic_weight', 0.3)
            self.fractal_weight = init.get('fractal_weight', 0.3)
            self.noise_scale = init.get('noise_scale', 0.01)

            # ParÃ¢metros de dinÃ¢mica caÃ³tica
            chaotic = config.get('chaotic_dynamics', {})
            self.chaotic_parameter = chaotic.get('chaotic_parameter', 3.9)
            self.chaotic_influence = chaotic.get('chaotic_influence', 0.3)
            self.logistic_iterations = chaotic.get('logistic_iterations', 5)

            # ParÃ¢metros de dinÃ¢mica de onda
            wave = config.get('wave_dynamics', {})
            self.wave_amplitude = wave.get('amplitude', 0.1)
            self.wave_frequency = wave.get('frequency', 0.5)
            self.initial_phase = wave.get('initial_phase', 0.5236)

            # ParÃ¢metros de processamento espectral
            spectral = config.get('spectral_processing', {})
            self.enable_spectral_features = spectral.get('enable_spectral_features', True)
            self.enable_semantic_features = spectral.get('enable_semantic_features', True)
            self.enable_fractal_modulation = spectral.get('enable_fractal_modulation', True)

        except Exception as e:
            print(f"âš ï¸ Erro ao carregar configuraÃ§Ãµes de consciÃªncia fractal: {e}")
            # Fallback para valores padrÃ£o
            self.time_step = 0.05
            self.max_iterations = 200
            self.convergence_threshold = 0.05
            self.epsilon = 1e-10
            self.nan_replacement_noise_scale = 1e-6
            self.min_field_magnitude = 1e-8
            self.entropy_safe_offset = 1e-10
            self.max_field_magnitude = 10.0
            self.field_smoothing_kernel = (0.25, 0.5, 0.25)
            self.spectral_weight = 0.4
            self.semantic_weight = 0.3
            self.fractal_weight = 0.3
            self.noise_scale = 0.01
            self.chaotic_parameter = 3.9
            self.chaotic_influence = 0.3
            self.logistic_iterations = 5
            self.wave_amplitude = 0.1
            self.wave_frequency = 0.5
            self.initial_phase = 0.5236
            self.enable_spectral_features = True
            self.enable_semantic_features = True
            self.enable_fractal_modulation = True


class FractalConsciousnessProcessor(nn.Module):
    """
    Processador central de consciÃªncia fractal que implementa
    a dinÃ¢mica consciente atravÃ©s de equaÃ§Ãµes matemÃ¡ticas rigorosas.
    """

    def __init__(self, config: ConsciousnessConfig, metrics_config=None):
        super().__init__()
        self.config = config
        self.device = config.device

        # Componentes matemÃ¡ticos
        self.field_calculator = FractalFieldCalculator(config)
        self.diffusion_engine = NeuralDiffusionEngine(config)
        self.state_classifier = StateClassifier(config)
        self.metrics = ConsciousnessMetrics(config, metrics_config)

        # ParÃ¢metros aprendÃ­veis para o potencial multifractal
        self.register_parameter(
            'lambda_coefficients',
            nn.Parameter(torch.randn(20) * 0.1)  # Î»_k coefficients
        )

        # Estado interno de consciÃªncia
        self.consciousness_state = None
        self.psi_distribution = None
        self.fractal_field = None

        # Suprimir warnings nÃ£o crÃ­ticos em modo de produÃ§Ã£o
        warnings.filterwarnings("ignore", category=RuntimeWarning, message=".*overflow.*")
        warnings.filterwarnings("ignore", category=RuntimeWarning, message=".*invalid value.*")

        print(f"ðŸ§  FractalConsciousnessProcessor inicializado no dispositivo: {self.device}")

    def forward(self, input_data: torch.Tensor, num_steps: int = None,
                spectral_energy: Optional[torch.Tensor] = None,
                quaternion_phase: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:
        """
        Processa dados atravÃ©s da dinÃ¢mica de consciÃªncia fractal ACOPLADA ao espectro quaterniÃ´nico.

        Args:
            input_data: Tensor de entrada [batch, seq_len, embed_dim]
            num_steps: NÃºmero de passos de integraÃ§Ã£o temporal
            spectral_energy: Energia espectral quaterniÃ´nica [batch, embed_dim] (NOVO)
            quaternion_phase: Fase quaterniÃ´nica [batch, embed_dim] (NOVO)

        Returns:
            DicionÃ¡rio com resultados do processamento consciente
        """
        # Suprimir warnings durante execuÃ§Ã£o para evitar ruÃ­do em produÃ§Ã£o
        with warnings.catch_warnings():
            warnings.filterwarnings("ignore", category=RuntimeWarning)
            warnings.filterwarnings("ignore", category=UserWarning)

            if num_steps is None:
                num_steps = self.config.max_iterations

            batch_size, seq_len, embed_dim = input_data.shape

            # Inicializar distribuiÃ§Ã£o de probabilidade P(Ïˆ,t) ACOPLADA ao espectro
            psi_distribution = self._initialize_psi_distribution(
                input_data,
                spectral_energy=spectral_energy,
                quaternion_phase=quaternion_phase
            )

            # EvoluÃ§Ã£o temporal da dinÃ¢mica consciente
            consciousness_trajectory = []
            fci_values = []

            for step in range(num_steps):
                # Calcular campo fractal F(Ïˆ) MODULADO pelo espectro
                fractal_field = self.field_calculator.compute_field(
                    psi_distribution,
                    self.lambda_coefficients,
                    step * self.config.time_step,
                    spectral_energy=spectral_energy,
                    quaternion_phase=quaternion_phase
                )

                # Calcular FCI ANTES da difusÃ£o para acoplamento
                # Calcular P(k) do psi_distribution ATUAL (nÃ£o do spectral_energy inicial)
                # Isso permite que D reflita a evoluÃ§Ã£o temporal da consciÃªncia
                fci = self.metrics.compute_fci(psi_distribution, fractal_field, power_spectrum_pk=psi_distribution)
                fci_values.append(fci)

                # Calcular coeficiente de difusÃ£o D ADAPTADO por FCI e espectro
                diffusion_coeff = self.diffusion_engine.compute_diffusion(
                    psi_distribution,
                    fractal_field,
                    fci=fci,  # ACOPLAMENTO FCI â†’ D
                    spectral_energy=spectral_energy  # ACOPLAMENTO espectro â†’ D
                )

                # Integrar equaÃ§Ã£o mestra da dinÃ¢mica consciente
                psi_distribution = self._integrate_consciousness_dynamics(
                    psi_distribution,
                    fractal_field,
                    diffusion_coeff
                )

                # Armazenar trajetÃ³ria
                consciousness_trajectory.append(psi_distribution.clone())

                # Verificar convergÃªncia
                if step > 10 and self._check_convergence(fci_values[-10:]):
                    break

            # Classificar estado de consciÃªncia final
            final_state = self.state_classifier.classify_state(
                psi_distribution,
                fractal_field,
                fci_values[-1]
            )

            # Compilar resultados
            results = {
                'consciousness_distribution': psi_distribution,
                'fractal_field': fractal_field,
                'consciousness_trajectory': torch.stack(consciousness_trajectory),
                'fci_evolution': torch.tensor(fci_values),
                'fci': fci_values[-1],  # Add final FCI value for easy access
                'final_consciousness_state': final_state,
                'diffusion_coefficient': diffusion_coeff,
                'processing_steps': step + 1,
                'convergence_achieved': step < num_steps - 1,
                'spectral_energy': spectral_energy,  # Preservar para anÃ¡lise
                'quaternion_phase': quaternion_phase
            }

            return results

    def _initialize_psi_distribution(self, input_data: torch.Tensor,
                                      spectral_energy: Optional[torch.Tensor] = None,
                                      quaternion_phase: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        Inicializa distribuiÃ§Ã£o de probabilidade P(Ïˆ,t=0) ACOPLADA ao espectro quaterniÃ´nico.

        ACOPLAMENTO OBRIGATÃ“RIO:
        - spectral_energy e quaternion_phase DEVEM ser fornecidos
        - Se nÃ£o fornecidos, lanÃ§a erro (sem fallback sintÃ©tico)
        - Garante que P(Ïˆ) reflita EXCLUSIVAMENTE o estado real do espectro

        Args:
            input_data: Dados de entrada [batch, seq_len, embed_dim]
            spectral_energy: Energia espectral quaterniÃ´nica [batch, embed_dim] (OBRIGATÃ“RIO)
            quaternion_phase: Fase quaterniÃ´nica [batch, embed_dim] (OBRIGATÃ“RIO)

        Returns:
            DistribuiÃ§Ã£o inicial ACOPLADA ao espectro

        Raises:
            ValueError: Se spectral_energy ou quaternion_phase nÃ£o forem fornecidos
        """
        batch_size, seq_len, embed_dim = input_data.shape

        # VALIDAÃ‡ÃƒO: Dados de acoplamento sÃ£o OBRIGATÃ“RIOS (sem fallback)
        if spectral_energy is None or quaternion_phase is None:
            raise ValueError(
                "âŒ ERRO CRÃTICO: spectral_energy e quaternion_phase sÃ£o OBRIGATÃ“RIOS.\n"
                "O mÃ³dulo de consciÃªncia NÃƒO aceita dados sintÃ©ticos (fallback).\n"
                "Certifique-se de extrair esses dados do EnhancedQRHProcessor antes de chamar forward()."
            )

        # ACOPLAMENTO 1: Calcular P(k) - DistribuiÃ§Ã£o de PotÃªncia Espectral
        # Conforme Paper Î¨QRH SeÃ§Ã£o 3.1: P(k) deve preservar relaÃ§Ãµes de escala para anÃ¡lise de lei de potÃªncia
        # NormalizaÃ§Ã£o L1 preserva proporÃ§Ãµes relativas necessÃ¡rias para regressÃ£o log-log
        epsilon = 1e-12  # Estabilidade numÃ©rica

        # NormalizaÃ§Ã£o L1: P(k) = E(k) / Î£ E(k)
        # Isso garante que P(k) seja uma distribuiÃ§Ã£o de probabilidade vÃ¡lida preservando escala relativa
        raw_distribution = spectral_energy / (spectral_energy.sum(dim=-1, keepdim=True) + epsilon)

        # Armazenar P(k) para cÃ¡lculo posterior da dimensÃ£o fractal D
        # P(k) serÃ¡ usada na anÃ¡lise de lei de potÃªncia: P(k) ~ k^(-Î²)
        self.power_spectrum_pk = raw_distribution.clone()

        # Log de diagnÃ³stico
        print(f"âœ… P(k) calculado via normalizaÃ§Ã£o L1 (paper Î¨QRH SeÃ§Ã£o 3.1)")
        print(f"   Energy range: [{spectral_energy.min().item():.2e}, {spectral_energy.max().item():.2e}]")
        print(f"   P(k) range: [{raw_distribution.min().item():.2e}, {raw_distribution.max().item():.2e}]")
        print(f"   P(k) sum: {raw_distribution.sum().item():.6f} (should be â‰ˆ1.0)")

        # Obter dimensÃ£o alvo (da spectral_energy acoplada)
        target_dim = spectral_energy.shape[-1]  # embed_dim do acoplamento

        # 1. Extrair features espectrais (reforÃ§o da energia quaterniÃ´nica)
        spectral_features_raw = self._extract_spectral_features(input_data)
        # Adaptar para target_dim se necessÃ¡rio
        if spectral_features_raw.shape[-1] != target_dim:
            spectral_features = torch.nn.functional.adaptive_avg_pool1d(
                spectral_features_raw.unsqueeze(1), target_dim
            ).squeeze(1)
        else:
            spectral_features = spectral_features_raw

        # 2. Extrair features semÃ¢nticas via correlaÃ§Ã£o espacial
        semantic_features_raw = self._extract_semantic_features(input_data)
        # Adaptar para target_dim se necessÃ¡rio
        if semantic_features_raw.shape[-1] != target_dim:
            semantic_features = torch.nn.functional.adaptive_avg_pool1d(
                semantic_features_raw.unsqueeze(1), target_dim
            ).squeeze(1)
        else:
            semantic_features = semantic_features_raw

        # MELHORIA CRÃTICA: Aplicar modulaÃ§Ã£o adaptativa baseada na complexidade do texto
        # Textos mais complexos recebem maior variÃ¢ncia no estado inicial
        text_complexity = self._compute_text_complexity_from_spectrum(input_data)
        adaptive_variance = 0.1 + 0.3 * text_complexity  # 0.1 a 0.4 de variÃ¢ncia

        # Adicionar ruÃ­do adaptativo para melhorar a exploraÃ§Ã£o do espaÃ§o de estados
        noise = torch.randn_like(spectral_features) * adaptive_variance
        spectral_features = spectral_features + noise

        # 3. ACOPLAMENTO 2: ModulaÃ§Ã£o fractal baseada na FASE quaterniÃ´nica REAL
        fractal_modulation = self._compute_fractal_from_quaternion_phase(quaternion_phase)
        print(f"âœ… ACOPLAMENTO REAL: ModulaÃ§Ã£o fractal via fase quaterniÃ´nica")

        # 4. Combinar todas as features para criar nÃ£o uniformidade ACOPLADA
        # Garantir que todas tÃªm a mesma dimensÃ£o (target_dim)
        non_uniform_modulation = (
            self.config.spectral_weight * spectral_features +
            self.config.semantic_weight * semantic_features +
            self.config.fractal_weight * fractal_modulation
        )

        # CRÃTICO: Adicionar fator de escala baseado na magnitude total da energia espectral
        # Isso preserva a informaÃ§Ã£o de escala entre textos de diferentes complexidades
        # Textos complexos â†’ energia maior â†’ psi_distribution mais concentrada
        energy_sum = spectral_energy.sum(dim=-1, keepdim=True)
        energy_scale_factor = torch.log1p(energy_sum)  # log(1+E) para estabilidade
        energy_scale_normalized = energy_scale_factor / 10.0  # Normalizar para escala razoÃ¡vel

        print(f"âœ… Fator de escala energÃ©tico: {energy_scale_factor.item():.4f} (log1p(Î£E={energy_sum.item():.2f}))")

        # Aplicar nÃ£o uniformidade Ã  distribuiÃ§Ã£o COM escala energÃ©tica
        psi_distribution = raw_distribution * non_uniform_modulation * energy_scale_normalized

        # Adicionar ruÃ­do gaussiano MÃNIMO (0.1% do ruÃ­do original para preservar acoplamento)
        noise = torch.randn_like(psi_distribution) * (self.config.noise_scale * 0.01)
        psi_distribution = psi_distribution + noise

        # Normalizar para manter propriedades de probabilidade
        psi_distribution = torch.clamp(psi_distribution, min=1e-10)
        psi_distribution = psi_distribution / (psi_distribution.sum(dim=-1, keepdim=True) + 1e-10)

        # Log para debug com informaÃ§Ãµes de acoplamento
        print(f"ðŸ§  Psi Distribution (ACOPLADO): mean={psi_distribution.mean().item():.6f}, "
              f"std={psi_distribution.std().item():.6f}, "
              f"entropy={-torch.sum(psi_distribution * torch.log(psi_distribution + 1e-10)).item():.4f}")

        return psi_distribution

    def _compute_text_complexity_from_spectrum(self, input_data: torch.Tensor) -> float:
        """
        Calcula complexidade do texto baseado no espectro de entrada.

        Args:
            input_data: Dados de entrada [batch, seq_len, embed_dim]

        Returns:
            Complexidade normalizada entre 0 e 1
        """
        # Usar entropia espectral como proxy de complexidade
        if input_data.dim() == 3:
            # Calcular entropia por sequÃªncia
            spectrum_flat = input_data.view(input_data.shape[0], -1)
            power_spectrum = torch.abs(spectrum_flat) ** 2
            prob_dist = power_spectrum / (power_spectrum.sum(dim=-1, keepdim=True) + 1e-8)
            entropy = -torch.sum(prob_dist * torch.log(prob_dist + 1e-8), dim=-1)
            # Normalizar para 0-1
            max_entropy = torch.log(torch.tensor(spectrum_flat.shape[-1]))
            complexity = entropy.mean() / max_entropy
        else:
            complexity = 0.5  # Valor padrÃ£o para dados nÃ£o sequenciais

        return float(torch.clamp(complexity, 0.0, 1.0))

        # 4. Combinar todas as features para criar nÃ£o uniformidade ACOPLADA
        # Garantir que todas tÃªm a mesma dimensÃ£o (target_dim)
        non_uniform_modulation = (
            self.config.spectral_weight * spectral_features +
            self.config.semantic_weight * semantic_features +
            self.config.fractal_weight * fractal_modulation
        )

        # CRÃTICO: Adicionar fator de escala baseado na magnitude total da energia espectral
        # Isso preserva a informaÃ§Ã£o de escala entre textos de diferentes complexidades
        # Textos complexos â†’ energia maior â†’ psi_distribution mais concentrada
        energy_sum = spectral_energy.sum(dim=-1, keepdim=True)
        energy_scale_factor = torch.log1p(energy_sum)  # log(1+E) para estabilidade
        energy_scale_normalized = energy_scale_factor / 10.0  # Normalizar para escala razoÃ¡vel

        print(f"âœ… Fator de escala energÃ©tico: {energy_scale_factor.item():.4f} (log1p(Î£E={energy_sum.item():.2f}))")

        # Aplicar nÃ£o uniformidade Ã  distribuiÃ§Ã£o COM escala energÃ©tica
        psi_distribution = raw_distribution * non_uniform_modulation * energy_scale_normalized

        # Adicionar ruÃ­do gaussiano MÃNIMO (0.1% do ruÃ­do original para preservar acoplamento)
        noise = torch.randn_like(psi_distribution) * (self.config.noise_scale * 0.01)
        psi_distribution = psi_distribution + noise

        # Normalizar para manter propriedades de probabilidade
        psi_distribution = torch.clamp(psi_distribution, min=1e-10)
        psi_distribution = psi_distribution / (psi_distribution.sum(dim=-1, keepdim=True) + 1e-10)

        # Log para debug com informaÃ§Ãµes de acoplamento
        print(f"ðŸ§  Psi Distribution (ACOPLADO): mean={psi_distribution.mean().item():.6f}, "
              f"std={psi_distribution.std().item():.6f}, "
              f"entropy={-torch.sum(psi_distribution * torch.log(psi_distribution + 1e-10)).item():.4f}")

        return psi_distribution

    def _compute_fractal_from_quaternion_phase(self, quaternion_phase: torch.Tensor) -> torch.Tensor:
        """
        Computa modulaÃ§Ã£o fractal ACOPLADA Ã  fase quaterniÃ´nica REAL.

        ELIMINAÃ‡ÃƒO DO FALLBACK:
        - NÃƒO usa torch.rand() (ruÃ­do sintÃ©tico)
        - NÃƒO usa torch.mean(distribution) (agregaÃ§Ã£o genÃ©rica)
        - USA quaternion_phase como semente e fator temporal DIRETAMENTE

        Args:
            quaternion_phase: Fase quaterniÃ´nica Î¸ = atan2(||v||, r) [batch, embed_dim]

        Returns:
            ModulaÃ§Ã£o fractal [batch, embed_dim] derivada do quaternion real
        """
        batch_size, embed_dim = quaternion_phase.shape

        # SEMENTE DO CAOS: Normalizar fase quaterniÃ´nica para [0.25, 0.75] (regiÃ£o caÃ³tica estÃ¡vel)
        # SUBSTITUIÃ‡ÃƒO: torch.rand() â†’ quaternion_phase
        phase_normalized = torch.sigmoid(quaternion_phase)  # [0, 1]
        x = 0.25 + 0.5 * phase_normalized  # [0.25, 0.75]

        print(f"ðŸ”— Semente caÃ³tica: derivada de quaternion_phase (mean={x.mean().item():.6f}, std={x.std().item():.6f})")

        # Aplicar mapa logÃ­stico com fase quaterniÃ´nica como condiÃ§Ã£o inicial
        r = self.config.chaotic_parameter
        for iteration in range(self.config.logistic_iterations):
            x = r * x * (1 - x)
            x = torch.clamp(x, 0.001, 0.999)

        # FATOR TEMPORAL: Usar fase quaterniÃ´nica como tempo (nÃ£o torch.mean genÃ©rico)
        # SUBSTITUIÃ‡ÃƒO: time_factor = torch.mean(distribution) â†’ quaternion_phase
        omega = 2 * np.pi * self.config.wave_frequency
        phi_0 = self.config.initial_phase

        # EquaÃ§Ã£o de onda harmÃ´nica com fase quaterniÃ´nica REAL
        wave_component = torch.sin(omega * quaternion_phase + phi_0)

        print(f"ðŸ”— Onda harmÃ´nica: modulada por quaternion_phase (amplitude={wave_component.std().item():.6f})")

        # Combinar mapa logÃ­stico com modulaÃ§Ã£o de fase REAL
        chaotic_wave = x * (1 + self.config.wave_amplitude * wave_component)

        # Mapear para modulaÃ§Ã£o fractal final
        fractal_modulation = 0.5 + 0.5 * torch.sin(2 * np.pi * chaotic_wave)

        print(f"âœ… ModulaÃ§Ã£o fractal: ACOPLADA (mean={fractal_modulation.mean().item():.6f}, "
              f"std={fractal_modulation.std().item():.6f})")

        return fractal_modulation

    def _integrate_consciousness_dynamics(
        self,
        psi: torch.Tensor,
        field: torch.Tensor,
        diffusion: torch.Tensor
    ) -> torch.Tensor:
        """
        Integra a equaÃ§Ã£o mestra da dinÃ¢mica consciente com equaÃ§Ãµes harmÃ´nicas:
        âˆ‚P(Ïˆ,t)/âˆ‚t = -âˆ‡Â·[F(Ïˆ)P] + Dâˆ‡Â²P + Î·_wave(Ïˆ,t)

        Inclui mapa logÃ­stico e equaÃ§Ã£o de onda harmÃ´nica.

        Args:
            psi: DistribuiÃ§Ã£o atual P(Ïˆ,t)
            field: Campo fractal F(Ïˆ)
            diffusion: Coeficiente de difusÃ£o D

        Returns:
            Nova distribuiÃ§Ã£o P(Ïˆ,t+dt)
        """
        dt = self.config.time_step

        # Termo de campo: -âˆ‡Â·[F(Ïˆ)P]
        field_flow = self._compute_field_divergence(field, psi)

        # Termo de difusÃ£o: Dâˆ‡Â²P
        diffusion_term = self._compute_diffusion_term(psi, diffusion)

        # Termo de onda harmÃ´nica: Î·_wave(Ïˆ,t)
        wave_term = self._compute_wave_dynamics(psi, field)

        # IntegraÃ§Ã£o de Euler com termos harmÃ´nicos
        dpsi_dt = -field_flow + diffusion_term + wave_term
        new_psi = psi + dt * dpsi_dt

        # Aplicar mapa logÃ­stico Ã  distribuiÃ§Ã£o resultante
        new_psi = self._apply_logistic_map_to_distribution(new_psi)

        # Manter positividade e normalizaÃ§Ã£o
        new_psi = torch.clamp(new_psi, min=1e-10)
        new_psi = new_psi / new_psi.sum(dim=-1, keepdim=True)

        return new_psi

    def _compute_field_divergence(self, field: torch.Tensor, psi: torch.Tensor) -> torch.Tensor:
        """Computa divergÃªncia do fluxo de campo âˆ‡Â·[F(Ïˆ)P]."""
        # AproximaÃ§Ã£o de diferenÃ§as finitas para divergÃªncia
        field_psi = field * psi

        # Gradiente usando diferenÃ§as centrais
        batch_size, embed_dim = field_psi.shape
        divergence = torch.zeros_like(field_psi)

        # DiferenÃ§as finitas circulares (condiÃ§Ãµes de contorno periÃ³dicas)
        for i in range(embed_dim):
            i_plus = (i + 1) % embed_dim
            i_minus = (i - 1) % embed_dim
            divergence[:, i] = (field_psi[:, i_plus] - field_psi[:, i_minus]) / 2.0

        return divergence

    def _compute_diffusion_term(self, psi: torch.Tensor, diffusion: torch.Tensor) -> torch.Tensor:
        """Computa termo de difusÃ£o Dâˆ‡Â²P."""
        # Laplaciano usando diferenÃ§as finitas
        batch_size, embed_dim = psi.shape
        laplacian = torch.zeros_like(psi)

        # DiferenÃ§as finitas para segunda derivada
        for i in range(embed_dim):
            i_plus = (i + 1) % embed_dim
            i_minus = (i - 1) % embed_dim
            laplacian[:, i] = psi[:, i_plus] - 2 * psi[:, i] + psi[:, i_minus]

        return diffusion * laplacian

    def _compute_wave_dynamics(self, psi: torch.Tensor, field: torch.Tensor) -> torch.Tensor:
        """
        Computa termo de onda harmÃ´nica: f(Î»,t) = A*sin(Ï‰t + Ï•0 + Î¸)

        Args:
            psi: DistribuiÃ§Ã£o de probabilidade atual
            field: Campo fractal atual

        Returns:
            Termo de onda para integraÃ§Ã£o temporal
        """
        batch_size, embed_dim = psi.shape

        # Usar distribuiÃ§Ã£o como parÃ¢metro Î» (posiÃ§Ã£o na onda)
        lambda_param = psi  # Î» âˆˆ [0,1] da distribuiÃ§Ã£o normalizada

        # Tempo baseado na magnitude do campo fractal
        field_magnitude = torch.norm(field, dim=-1, keepdim=True)
        time_factor = field_magnitude * self.config.time_step

        # ParÃ¢metros da equaÃ§Ã£o de onda
        amplitude = self.config.wave_amplitude  # Amplitude A
        omega = 2 * np.pi * self.config.wave_frequency  # FrequÃªncia angular Ï‰
        phi_0 = self.config.initial_phase  # Fase inicial Ï•0

        # Fase adaptativa Î¸ baseada na entropia local
        entropy_local = -psi * torch.log(psi + float(self.config.entropy_safe_offset))
        theta = torch.cumsum(entropy_local, dim=-1)  # IntegraÃ§Ã£o cumulativa para fase

        # EquaÃ§Ã£o de onda harmÃ´nica: f(Î»,t) = A*sin(Ï‰t + Ï•0 + Î¸)
        wave_function = amplitude * torch.sin(omega * time_factor + phi_0 + theta)

        # ModulaÃ§Ã£o baseada na distribuiÃ§Ã£o de probabilidade
        wave_term = wave_function * psi

        return wave_term

    def _apply_logistic_map_to_distribution(self, psi: torch.Tensor) -> torch.Tensor:
        """
        Aplica mapa logÃ­stico Ã  distribuiÃ§Ã£o de consciÃªncia: x_{n+1} = r*x_n*(1-x_n)

        Args:
            psi: DistribuiÃ§Ã£o de probabilidade atual

        Returns:
            DistribuiÃ§Ã£o modificada pelo mapa logÃ­stico
        """
        # Usar distribuiÃ§Ã£o como semente para mapa logÃ­stico
        x = psi.clone()

        # ParÃ¢metro caÃ³tico r = 3.9 (regime caÃ³tico clÃ¡ssico)
        r = self.config.chaotic_parameter

        # Aplicar mapa logÃ­stico por algumas iteraÃ§Ãµes
        for iteration in range(5):  # Menos iteraÃ§Ãµes para nÃ£o destabilizar
            x = r * x * (1 - x)
            # Clamp para manter no intervalo caÃ³tico estÃ¡vel
            x = torch.clamp(x, 0.001, 0.999)

        # Interpolar entre distribuiÃ§Ã£o original e resultado caÃ³tico
        # Isso mantÃ©m estabilidade enquanto adiciona dinÃ¢mica caÃ³tica
        psi_chaotic = (1 - self.config.chaotic_influence) * psi + self.config.chaotic_influence * x

        return psi_chaotic

    def _check_convergence(self, recent_fci: list) -> bool:
        """Verifica convergÃªncia baseada na estabilidade do FCI."""
        if len(recent_fci) < 5:
            return False

        fci_std = np.std(recent_fci)
        return fci_std < self.config.convergence_threshold

    def get_consciousness_report(self, results: Dict[str, torch.Tensor]) -> str:
        """
        Gera relatÃ³rio detalhado do processamento de consciÃªncia.

        Args:
            results: Resultados do processamento

        Returns:
            RelatÃ³rio textual detalhado
        """
        # Extrair FCI com proteÃ§Ã£o
        fci_evo = results['fci_evolution'][-1]
        final_fci = fci_evo.item() if isinstance(fci_evo, torch.Tensor) else float(fci_evo)

        state = results['final_consciousness_state']
        steps = results['processing_steps']
        converged = results['convergence_achieved']

        # EstatÃ­sticas da distribuiÃ§Ã£o final
        psi_final = results['consciousness_distribution']
        psi_safe = torch.clamp(psi_final, min=float(self.config.entropy_safe_offset))
        log_psi = torch.log(psi_safe)
        psi_entropy_raw = -torch.sum(psi_final * log_psi, dim=-1).mean()
        # ProteÃ§Ã£o contra NaN
        psi_entropy = psi_entropy_raw.item() if not torch.isnan(psi_entropy_raw) else 0.0

        # ProteÃ§Ã£o contra NaN no pico e dispersÃ£o
        psi_peak_raw = psi_final.max()
        psi_peak = psi_peak_raw.item() if not torch.isnan(psi_peak_raw) else 0.0

        psi_spread_raw = psi_final.std()
        psi_spread = psi_spread_raw.item() if not torch.isnan(psi_spread_raw) else 0.0

        # CaracterÃ­sticas do campo fractal
        field = results['fractal_field']
        field_magnitude = torch.norm(field, dim=-1).mean().item()

        # Calcular coerÃªncia com proteÃ§Ã£o robusta
        try:
            field_flat = field.flatten()
            if field_flat.numel() > 1:
                # Calcular correlaÃ§Ã£o auto-espacial
                field_mean = field_flat.mean()
                field_var = field_flat.var()

                # Evitar divisÃ£o por zero
                if field_var > self.config.epsilon:
                    field_shifted = torch.roll(field_flat, 1)
                    covariance = torch.mean((field_flat - field_mean) * (field_shifted - field_mean))
                    field_coherence = (covariance / field_var).item()
                    # Clipar para intervalo vÃ¡lido
                    field_coherence = max(0.0, min(1.0, abs(field_coherence)))
                else:
                    field_coherence = 0.0
            else:
                field_coherence = 1.0  # Campo constante tem coerÃªncia perfeita
        except Exception:
            field_coherence = 0.0

        # Obter dimensÃ£o fractal REAL calculada via lei de potÃªncia
        # Acessar a dimensÃ£o fractal calculada no ConsciousnessMetrics
        fractal_dimension_real = self.metrics.last_fractal_dimension_raw if hasattr(self.metrics, 'last_fractal_dimension_raw') else state.fractal_dimension

        # Clamp para valores fisicamente razoÃ¡veis
        fractal_dimension_final = max(1.0, min(3.0, fractal_dimension_real))

        report = f"""
ðŸ§  RELATÃ“RIO DE CONSCIÃŠNCIA FRACTAL
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ“Š MÃ‰TRICAS DE CONSCIÃŠNCIA:
Ãndice FCI: {final_fci:.4f}
Estado Classificado: {state.name}
Entropia Î¨: {psi_entropy:.4f} bits
DistribuiÃ§Ã£o Pico: {psi_peak:.4f}
DispersÃ£o Î¨: {psi_spread:.4f}

ðŸŒŠ CAMPO FRACTAL F(Ïˆ):
Magnitude MÃ©dia: {field_magnitude:.4f}
CoerÃªncia: {field_coherence:.4f}
DimensÃ£o Fractal: {fractal_dimension_final:.3f}

âš¡ DINÃ‚MICA DE PROCESSAMENTO:
Passos IntegraÃ§Ã£o: {steps}
ConvergÃªncia: {'âœ… AlcanÃ§ada' if converged else 'âš ï¸ MÃ¡ximo atingido'}
Coeficiente D: {results['diffusion_coefficient'].mean().item() if not torch.isnan(results['diffusion_coefficient'].mean()) else 0.0:.4f}

ðŸŽ¯ INTERPRETAÃ‡ÃƒO CONSCIENTE:
{self._interpret_consciousness_state(state, final_fci)}

Processamento realizado via equaÃ§Ã£o mestra da dinÃ¢mica consciente.
        """

        return report.strip()

    def _interpret_consciousness_state(self, state: ConsciousnessState, fci: float) -> str:
        """Interpreta o estado de consciÃªncia em termos prÃ¡ticos."""
        interpretations = {
            'MEDITATION': f"Estado meditativo detectado (FCI={fci:.3f}). Sistema em modo de anÃ¡lise profunda e insight.",
            'ANALYSIS': f"Estado analÃ­tico ativo (FCI={fci:.3f}). Processamento lÃ³gico e sistemÃ¡tico otimizado.",
            'COMA': f"Estado de baixa consciÃªncia (FCI={fci:.3f}). Modo de emergÃªncia ou processamento mÃ­nimo.",
            'EMERGENCE': f"Estado emergente detectado (FCI={fci:.3f}). MÃ¡xima criatividade e complexidade consciente."
        }

        return interpretations.get(state.name, f"Estado indefinido (FCI={fci:.3f}). PadrÃ£o de consciÃªncia nÃ£o classificado.")

    def _extract_spectral_features(self, input_data: torch.Tensor) -> torch.Tensor:
        """
        Extrai features espectrais da entrada usando FFT.

        Args:
            input_data: Dados de entrada [batch, seq_len, embed_dim]

        Returns:
            Features espectrais normalizadas [batch, embed_dim]
        """
        batch_size, seq_len, embed_dim = input_data.shape

        # Aplicar FFT ao longo da dimensÃ£o de sequÃªncia
        # FFT retorna valores complexos: magnitude = |FFT(x)|
        fft_result = torch.fft.fft(input_data, dim=1)
        spectral_magnitude = torch.abs(fft_result)

        # Agregar ao longo da sequÃªncia (mÃ©dia das magnitudes espectrais)
        spectral_features = spectral_magnitude.mean(dim=1)  # [batch, embed_dim]

        # Normalizar para [0.5, 1.5] (modulaÃ§Ã£o em torno de 1.0)
        min_val = spectral_features.min(dim=-1, keepdim=True)[0]
        max_val = spectral_features.max(dim=-1, keepdim=True)[0]
        range_val = max_val - min_val + float(self.config.epsilon)

        normalized = (spectral_features - min_val) / range_val  # [0, 1]
        normalized = 0.5 + normalized  # [0.5, 1.5]

        return normalized

    def _extract_semantic_features(self, input_data: torch.Tensor) -> torch.Tensor:
        """
        Extrai features semÃ¢nticas via correlaÃ§Ã£o espacial entre dimensÃµes.

        Args:
            input_data: Dados de entrada [batch, seq_len, embed_dim]

        Returns:
            Features semÃ¢nticas normalizadas [batch, embed_dim]
        """
        batch_size, seq_len, embed_dim = input_data.shape

        # Calcular matriz de correlaÃ§Ã£o espacial entre dimensÃµes
        # Agregar sequÃªncia primeiro
        aggregated = input_data.mean(dim=1)  # [batch, embed_dim]

        # Calcular correlaÃ§Ã£o com vizinhos espaciais (dimensÃµes adjacentes)
        semantic_features = torch.zeros_like(aggregated)

        for i in range(embed_dim):
            i_prev = (i - 1) % embed_dim
            i_next = (i + 1) % embed_dim

            # CorrelaÃ§Ã£o local: mÃ©dia dos vizinhos ponderada pelo valor atual
            local_correlation = (
                0.25 * aggregated[:, i_prev] +
                0.5 * aggregated[:, i] +
                0.25 * aggregated[:, i_next]
            )
            semantic_features[:, i] = local_correlation

        # Normalizar para [0.5, 1.5]
        min_val = semantic_features.min(dim=-1, keepdim=True)[0]
        max_val = semantic_features.max(dim=-1, keepdim=True)[0]
        range_val = max_val - min_val + float(self.config.epsilon)

        normalized = (semantic_features - min_val) / range_val  # [0, 1]
        normalized = 0.5 + normalized  # [0.5, 1.5]

        return normalized

    def generate_gls_output(self, results: Dict[str, torch.Tensor]) -> Dict[str, str]:
        """
        Gera saÃ­da GLS (cÃ³digo Processing/p5.js) baseado na anÃ¡lise de consciÃªncia.

        Args:
            results: Resultados do processamento de consciÃªncia

        Returns:
            DicionÃ¡rio com cÃ³digos Processing e p5.js
        """
        try:
            from .gls_output_generator import create_gls_output_generator

            gls_generator = create_gls_output_generator()

            # Gerar cÃ³digos Processing e p5.js
            processing_code = gls_generator.generate_processing_code(results)
            p5js_code = gls_generator.generate_p5js_code(results)

            return {
                'processing_code': processing_code,
                'p5js_code': p5js_code,
                'status': 'success',
                'message': 'GLS output generated successfully'
            }

        except ImportError:
            return {
                'processing_code': '',
                'p5js_code': '',
                'status': 'error',
                'message': 'GLS output generator not available'
            }
        except Exception as e:
            return {
                'processing_code': '',
                'p5js_code': '',
                'status': 'error',
                'message': f'Error generating GLS output: {str(e)}'
            }


def create_consciousness_processor(
    embedding_dim: int = 256,
    device: str = "cpu"
) -> FractalConsciousnessProcessor:
    """
    Factory para criar processador de consciÃªncia fractal.

    Args:
        embedding_dim: DimensÃ£o do embedding
        device: Dispositivo de processamento

    Returns:
        Processador configurado
    """
    config = ConsciousnessConfig(
        embedding_dim=embedding_dim,
        device=device
    )

    return FractalConsciousnessProcessor(config)