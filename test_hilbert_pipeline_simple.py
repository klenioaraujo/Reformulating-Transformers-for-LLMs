#!/usr/bin/env python3
"""
Teste Simples do Pipeline Î¨QRH-Transformers com DeepSeek
=======================================================

VersÃ£o simplificada para evitar travamentos de memÃ³ria.
"""

import torch
import sys
import os

# Adicionar diretÃ³rio base ao path
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, BASE_DIR)

from psiqrh_transformers import (
    HilbertConfig,
    HilbertLlamaForCausalLM,
)

def test_minimal_deepseek():
    """
    Teste minimalista com configuraÃ§Ãµes pequenas
    """
    print("ğŸ§ª Teste Minimalista Î¨QRH-Transformers")
    print("=" * 50)

    try:
        # ConfiguraÃ§Ã£o minimalista similar ao DeepSeek
        config = HilbertConfig(
            vocab_size=32000,
            hidden_size=256,  # Muito menor para teste
            num_attention_heads=8,
            num_hidden_layers=2,  # Apenas 2 camadas
            intermediate_size=1024,
            hilbert_space="complex",  # ComeÃ§ar com complexo (mais simples)
            spectral_alpha=1.0,
            fractal_dimension=1.5,
            use_spectral_filtering=False,  # Desabilitar para teste
            use_fractal_embedding=True,
        )

        print("âœ… ConfiguraÃ§Ã£o criada:")
        print(f"   ğŸ“ EspaÃ§o de Hilbert: {config.hilbert_space}")
        print(f"   ğŸ§  Hidden Size: {config.hidden_size}")
        print(f"   ğŸ“š Vocab Size: {config.vocab_size}")
        print(f"   ğŸ”¢ Layers: {config.num_hidden_layers}")

        # Criar modelo pequeno
        print("\nğŸ”„ Criando modelo...")
        model = HilbertLlamaForCausalLM(config)

        # Contar parÃ¢metros
        total_params = sum(p.numel() for p in model.parameters())
        print("âœ… Modelo criado!")
        print(f"   ğŸ“Š ParÃ¢metros: {total_params:,} ({total_params/1e6:.1f}M)")

        # Teste de forward pass mÃ­nimo
        print("\nğŸ§ª Testando forward pass...")
        batch_size, seq_len = 1, 4  # Muito pequeno
        input_ids = torch.randint(0, min(1000, config.vocab_size), (batch_size, seq_len))

        with torch.no_grad():
            outputs = model(input_ids, return_dict=True)
            logits = outputs['logits']

        print("âœ… Forward pass OK!")
        print(f"   ğŸ“¥ Input: {input_ids.shape}")
        print(f"   ğŸ“¤ Output: {logits.shape}")
        print(f"   ğŸ“Š Logits range: [{logits.min().item():.3f}, {logits.max().item():.3f}]")
        # Teste de geraÃ§Ã£o simples
        print("\nğŸ¤– Testando geraÃ§Ã£o...")
        generated = input_ids.clone()
        for _ in range(2):  # Apenas 2 tokens
            with torch.no_grad():
                outputs = model(generated, return_dict=True)
                next_token = torch.argmax(outputs['logits'][:, -1, :], dim=-1, keepdim=True)
                generated = torch.cat([generated, next_token], dim=-1)

        print("âœ… GeraÃ§Ã£o OK!")
        print(f"   ğŸ“ Original: {input_ids[0].tolist()}")
        print(f"   ğŸ¤– Gerado: {generated[0].tolist()}")

        return True

    except Exception as e:
        print(f"âŒ Erro: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_different_spaces():
    """
    Testa diferentes espaÃ§os de Hilbert
    """
    print("\nğŸ”¬ Testando espaÃ§os de Hilbert diferentes")
    print("=" * 50)

    spaces = ["complex", "quaternion"]
    results = {}

    for space in spaces:
        print(f"\nğŸ§ª Testando espaÃ§o: {space}")
        try:
            config = HilbertConfig(
                vocab_size=1000,
                hidden_size=128,
                num_attention_heads=4,
                num_hidden_layers=1,
                hilbert_space=space,
                use_spectral_filtering=False,
            )

            model = HilbertLlamaForCausalLM(config)
            input_ids = torch.randint(0, config.vocab_size, (1, 3))

            with torch.no_grad():
                outputs = model(input_ids, return_dict=True)

            print(f"   âœ… {space}: OK")
            results[space] = True

        except Exception as e:
            print(f"   âŒ {space}: {e}")
            results[space] = False

    return results

def main():
    """
    FunÃ§Ã£o principal
    """
    print("Î¨QRH Transformers - Teste Simples com DeepSeek")
    print("=" * 60)

    # Teste 1: Modelo minimalista
    success1 = test_minimal_deepseek()

    # Teste 2: Diferentes espaÃ§os
    results = test_different_spaces()

    # Resultado final
    print("\n" + "=" * 60)
    if success1:
        print("ğŸ‰ Teste principal: SUCESSO!")
        print("âœ… Î¨QRH-Transformers funcional")
    else:
        print("âŒ Teste principal: FALHA")

    print("\nğŸ“Š EspaÃ§os de Hilbert testados:")
    for space, success in results.items():
        status = "âœ…" if success else "âŒ"
        print(f"   {status} {space}")

    successful_spaces = sum(results.values())
    print(f"\nğŸ“ˆ {successful_spaces}/{len(results)} espaÃ§os funcionais")

    if success1 and successful_spaces > 0:
        print("\nğŸš€ Pronto para integraÃ§Ã£o com DeepSeek!")
        print("ğŸ’¡ Para usar com modelo real:")
        print("   1. Ajuste hidden_size para 4096")
        print("   2. Aumente num_hidden_layers para 32")
        print("   3. Use from_pretrained() com pesos do DeepSeek")
    else:
        print("\nâš ï¸  Revisar implementaÃ§Ã£o antes de prosseguir")

if __name__ == "__main__":
    main()