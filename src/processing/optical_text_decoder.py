"""
Optical Text Decoder - Zero Fallbacks, Zero Statistical Sampling
=================================================================

Decodifica estado quaterni√¥nico em texto via resson√¢ncia √≥ptica PURA,
eliminando qualquer vest√≠gio de l√≥gica estat√≠stica ou fallbacks.

Princ√≠pio: Gera√ß√£o autoregressiva via detec√ß√£o f√≠sica de picos de resson√¢ncia,
onde cada token √© "medido" atrav√©s de an√°lise de sinais (derivadas primeira/segunda),
n√£o amostrado probabilisticamente.

Copyright (C) 2025 Klenio Araujo Padilha
Licensed under GNU GPLv3
"""

import torch
import torch.nn.functional as F
from typing import List, Dict, Optional, Tuple
import numpy as np

# DCF System imports
from src.processing.token_analysis import DCFTokenAnalysis, analyze_tokens_dcf


class OpticalTextDecoder:
    """
    Decodificador de texto via f√≠sica √≥ptica PURA para Œ®QRH - Zero Fallbacks.

    Pipeline F√çSICO (sem estat√≠stica):
    1. Estado quaterni√¥nico inicial
    2. Sonda √≥ptica autoregressiva com T_q e sharpness emergentes
    3. Gera√ß√£o de tokens via DETEC√á√ÉO F√çSICA de picos de resson√¢ncia
    4. Parada por colapso de consci√™ncia (FCI < 0.05)

    A sele√ß√£o de tokens √© uma MEDI√á√ÉO F√çSICA, n√£o uma amostragem estat√≠stica.
    Cada token emerge da an√°lise de derivadas primeira/segunda do sinal de resson√¢ncia.
    """

    def __init__(self,
                 vocab_size: int = 50257,
                 max_tokens: int = 100,
                 min_fci_threshold: float = 0.05,
                 device: str = 'cpu'):
        """
        Args:
            vocab_size: Tamanho do vocabul√°rio
            max_tokens: M√°ximo de tokens a gerar
            min_fci_threshold: Limiar m√≠nimo de FCI para parada
            device: Dispositivo (cpu/cuda)
        """
        self.vocab_size = vocab_size
        self.max_tokens = max_tokens
        self.min_fci_threshold = min_fci_threshold
        self.device = device

        # Importar calculadores de par√¢metros emergentes
        from src.core.quantum_temperature import QuantumTemperatureCalculator
        from src.core.optical_coherence import OpticalCoherenceCalculator

        self.temp_calculator = QuantumTemperatureCalculator(
            T_min=0.1,
            T_max=5.0
        )
        self.coherence_calculator = OpticalCoherenceCalculator(
            s_baseline=2.0,
            s_min=0.5,
            s_max=5.0,
            coherence_method='autocorr'
        )

        # ========== DCF SYSTEM INITIALIZATION ==========
        # Sistema de An√°lise de Tokens via Din√¢mica de Consci√™ncia Fractal
        print("üß† Inicializando Sistema DCF (Din√¢mica de Consci√™ncia Fractal)...")

        try:
            self.dcf_analyzer = DCFTokenAnalysis(device=self.device)
            self.dcf_active = True
            print("üéØ Sistema DCF totalmente operacional!")
        except Exception as e:
            print(f"‚ùå Sistema DCF falhou: {e}")
            self.dcf_analyzer = None
            self.dcf_active = False
            raise RuntimeError("Sistema DCF obrigat√≥rio falhou - ZERO FALLBACK POLICY")

    @torch.jit.script
    def optical_probe_resonance_jit(
        psi: torch.Tensor,
        vocab_size: int,
        alpha: float,
        beta: float
    ) -> torch.Tensor:
        """
        Calcula resson√¢ncia √≥ptica entre estado quaterni√¥nico e ondas de sonda (JIT compiled).

        Args:
            psi: Estado quaterni√¥nico [batch, 4]
            vocab_size: Tamanho do vocabul√°rio
            alpha: Par√¢metro fractal Œ±
            beta: Par√¢metro fractal Œ≤

        Returns:
            Resson√¢ncia [vocab_size]
        """
        batch_size = psi.shape[0]

        # Gerar ondas de sonda para todo vocabul√°rio
        lambda_indices = torch.arange(vocab_size, device=psi.device, dtype=torch.float32)
        lambda_indices = lambda_indices.unsqueeze(0).expand(batch_size, -1)

        # Configura√ß√£o Padilha
        I0, omega, k = 1.0, 2.0 * 3.141592653589793, 2.0 * 3.141592653589793 / 0.5
        t = 1.0

        # Œª normalizado: [0, 1]
        lambda_val = lambda_indices / vocab_size

        # Gerar ondas de sonda
        amplitude = I0 * torch.sin(omega * t + alpha * lambda_val)
        phase = omega * t - k * lambda_val + beta * (lambda_val ** 2)

        wave_real = amplitude * torch.cos(phase)
        wave_imag = amplitude * torch.sin(phase)

        # Mapear para quaternion (simplificado)
        probe_waves = torch.stack([wave_real, wave_imag,
                                  torch.zeros_like(wave_real),
                                  torch.zeros_like(wave_real)], dim=-1)

        # Normalizar quaterni√µes de sonda (simplificado para JIT)
        norms = torch.sqrt(torch.sum(probe_waves ** 2, dim=-1, keepdim=True))
        probe_waves = probe_waves / (norms + 1e-8)

        # Calcular energia de acoplamento: |‚ü®f(Œª), Œ®‚ü©|¬≤
        psi_expanded = psi.unsqueeze(1).expand(-1, vocab_size, -1)
        coupling = (probe_waves * psi_expanded).sum(dim=-1)
        energy = coupling ** 2

        return energy.squeeze(0)  # [vocab_size]

    def optical_probe_resonance(self,
                                psi: torch.Tensor,
                                alpha: float,
                                beta: float) -> torch.Tensor:
        """
        Calcula resson√¢ncia √≥ptica entre estado quaterni√¥nico e ondas de sonda.

        Args:
            psi: Estado quaterni√¥nico [batch, 4]
            alpha: Par√¢metro fractal Œ±
            beta: Par√¢metro fractal Œ≤

        Returns:
            Resson√¢ncia [vocab_size]
        """
        return self.optical_probe_resonance_jit(psi, self.vocab_size, alpha, beta)

    def apply_quantum_noise(self, energy: torch.Tensor, T_q: float) -> torch.Tensor:
        """
        Aplica ru√≠do t√©rmico qu√¢ntico √† energia de resson√¢ncia.

        Args:
            energy: Energia de resson√¢ncia [vocab_size]
            T_q: Temperatura qu√¢ntica

        Returns:
            Energia com ru√≠do t√©rmico
        """
        # Ru√≠do t√©rmico: exp(Œµ/T_q) onde Œµ ~ N(0, T_q)
        thermal_noise = torch.randn_like(energy) * T_q
        energy_thermal = energy * torch.exp(thermal_noise / T_q)

        return energy_thermal

    def resonance_peak_decoding(self, resonance: torch.Tensor, T_q: float) -> Tuple[int, Dict]:
        """
        SUBSTITU√çDO PELO SISTEMA DCF: Decodifica√ß√£o por pico de resson√¢ncia agora usa
        Din√¢mica de Consci√™ncia Fractal em vez de an√°lise est√°tica de sinais.

        Esta implementa√ß√£o f√≠sica substitui softmax+multinomial por sistema din√¢mico
        baseado em osciladores Kuramoto, m√©tricas de consci√™ncia fractal e feedback adaptativo.

        Args:
            resonance: Vetor de resson√¢ncia [vocab_size] - usado como logits para DCF
            T_q: Temperatura qu√¢ntica (mantida para compatibilidade)

        Returns:
            Tupla: (√≠ndice do token selecionado, dicion√°rio com informa√ß√µes completas do DCF)
        """
        print(f"üîÑ Usando Sistema DCF para sele√ß√£o de token (anteriormente: an√°lise de picos)")

        # Usar resson√¢ncia como logits para o sistema DCF
        # O sistema DCF tratar√° isso como entrada para din√¢mica de osciladores
        dcf_result = self.dcf_token_analysis(resonance, num_candidates=min(50, len(resonance)))

        selected_token = dcf_result['selected_token']

        print(f"üéØ DCF selecionou token {selected_token}:")
        print(f"   - M√©todo: {dcf_result['method']}")
        print(f"   - FCI: {dcf_result['fci_value']:.3f}")
        print(f"   - Estado: {dcf_result['consciousness_state']}")
        print(f"   - Sincroniza√ß√£o: {dcf_result['synchronization_order']:.3f}")

        return selected_token, dcf_result

    def decode_to_text(self,
                      psi_initial: torch.Tensor,
                      alpha: float,
                      beta: float,
                      consciousness_processor,
                      token_decoder) -> Tuple[str, Dict]:
        """
        Decodifica√ß√£o autoregressiva de texto via f√≠sica √≥ptica.

        Args:
            psi_initial: Estado quaterni√¥nico inicial [batch, 4]
            alpha: Par√¢metro fractal Œ±
            beta: Par√¢metro fractal Œ≤
            consciousness_processor: Processador de consci√™ncia
            token_decoder: Fun√ß√£o para decodificar token_id ‚Üí string

        Returns:
            (texto_gerado, m√©tricas)
        """
        generated_tokens = []
        metrics = {
            'tokens_generated': 0,
            'final_fci': 0.0,
            'avg_temperature': 0.0,
            'avg_sharpness': 0.0,
            'stopped_by': 'max_tokens'
        }

        current_psi = psi_initial
        temperatures = []
        sharpnesses = []

        print(f"üöÄ Iniciando decodifica√ß√£o √≥ptica autoregressiva...")
        print(f"   - Estado inicial: {current_psi.shape}")
        print(f"   - Par√¢metros: Œ±={alpha:.3f}, Œ≤={beta:.3f}")

        for step in range(self.max_tokens):
            # Recalcular consci√™ncia
            batch_size, seq_len, quat_dim = current_psi.shape
            dummy_input = torch.randn(batch_size, seq_len, 64, device=self.device)

            # Extrair dados de acoplamento do estado atual
            spectral_energy = torch.abs(current_psi[..., 0])  # Componente real
            # Corrigir opera√ß√£o complexa para evitar erro de imag
            quaternion_phase = torch.atan2(current_psi[..., 1], current_psi[..., 0])  # Fase calculada manualmente

            consciousness_results = consciousness_processor(
                dummy_input,
                spectral_energy=spectral_energy,
                quaternion_phase=quaternion_phase
            )
            current_fci = consciousness_results.get('fci', 0.0)
            # Extract fractal dimension from consciousness state if available
            final_state = consciousness_results.get('final_consciousness_state')
            D_fractal = final_state.fractal_dimension if final_state else 1.5
            # CLZ is not directly available, use default or compute from entropy
            CLZ = 0.5  # Default value since not directly available

            # Calcular par√¢metros emergentes
            T_q = self.temp_calculator.compute_quantum_temperature(
                D_fractal=D_fractal,
                FCI=current_fci,
                CLZ=CLZ
            )

            # Sonda √≥ptica para resson√¢ncia
            resonance = self.optical_probe_resonance(
                current_psi[:, -1, :],  # √öltimo estado
                alpha=alpha,
                beta=beta
            )

            sharpness = self.coherence_calculator.compute_optical_sharpness(
                resonance_field=resonance,
                D_fractal=D_fractal,
                FCI=current_fci
            )

            # Aplicar sharpness
            resonance_sharp = resonance ** sharpness

            # Aplicar ru√≠do t√©rmico
            resonance_thermal = self.apply_quantum_noise(resonance_sharp, T_q)

            # Decodifica√ß√£o por pico de resson√¢ncia (substitui amostragem estat√≠stica)
            next_token_id, dcf_info = self.resonance_peak_decoding(resonance_thermal, T_q)

            # Decodificar token
            try:
                next_token = token_decoder(next_token_id)
                generated_tokens.append(next_token)
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Erro na decodifica√ß√£o do token {next_token_id}: {e}")
                break

            # Atualizar m√©tricas
            temperatures.append(T_q)
            sharpnesses.append(sharpness)

            print(f"   Step {step + 1}: token='{next_token}', FCI={current_fci:.3f}, T_q={T_q:.3f}, s={sharpness:.3f}")

            # Parar se consci√™ncia colapsar
            if current_fci < self.min_fci_threshold:
                print(f"   üõë Parada por colapso de consci√™ncia: FCI={current_fci:.3f} < {self.min_fci_threshold}")
                metrics['stopped_by'] = 'consciousness_collapse'
                break

            # Parar se token de fim de sequ√™ncia
            if next_token in ['</s>', '<|endoftext|>', '\n'] and step > 5:
                print(f"   üõë Parada por token de fim de sequ√™ncia")
                metrics['stopped_by'] = 'end_token'
                break

            # Atualizar estado (simplificado - em produ√ß√£o usar embedding)
            # Para demonstra√ß√£o, manter estado atual
            if step < self.max_tokens - 1:
                # Adicionar pequena perturba√ß√£o para simular evolu√ß√£o
                noise = torch.randn_like(current_psi) * 0.01
                current_psi = current_psi + noise

        # Calcular m√©tricas finais
        metrics.update({
            'tokens_generated': len(generated_tokens),
            'final_fci': current_fci,
            'avg_temperature': np.mean(temperatures) if temperatures else 0.0,
            'avg_sharpness': np.mean(sharpnesses) if sharpnesses else 0.0,
            'dcf_analysis': dcf_info  # Adicionar informa√ß√µes do DCF
        })

        # Juntar tokens em texto
        generated_text = ''.join(generated_tokens)

        print(f"\n‚úÖ Decodifica√ß√£o conclu√≠da:")
        print(f"   - Texto: '{generated_text}'")
        print(f"   - Tokens: {metrics['tokens_generated']}")
        print(f"   - FCI final: {metrics['final_fci']:.3f}")
        print(f"   - T_q m√©dio: {metrics['avg_temperature']:.3f}")
        print(f"   - Sharpness m√©dio: {metrics['avg_sharpness']:.3f}")
        print(f"   - Parada por: {metrics['stopped_by']}")

        return generated_text, metrics

    def dcf_token_analysis(self, logits: torch.Tensor, num_candidates: int = 50) -> Dict:
        """
        Sistema de An√°lise de Tokens via Din√¢mica de Consci√™ncia Fractal (DCF) - ZERO FALLBACK

        Usa o sistema DCFTokenAnalysis centralizado para an√°lise din√¢mica de tokens.
        ZERO FALLBACK POLICY: Sistema deve falhar claramente se DCF n√£o estiver dispon√≠vel.

        Args:
            logits: Logits do modelo base [vocab_size]
            num_candidates: N√∫mero de tokens candidatos (usado para compatibilidade)

        Returns:
            Dicion√°rio com token selecionado e relat√≥rio detalhado DCF

        Raises:
            RuntimeError: Se sistema DCF n√£o estiver dispon√≠vel
        """
        if not self.dcf_active or self.dcf_analyzer is None:
            raise RuntimeError("Sistema DCF obrigat√≥rio n√£o dispon√≠vel - ZERO FALLBACK POLICY")

        # Usar o sistema DCF centralizado
        result = self.dcf_analyzer.analyze_tokens(logits)

        # Adaptar formato para compatibilidade com c√≥digo existente
        adapted_result = {
            'selected_token': result['selected_token'],
            'final_probability': result['final_probability'],
            'fci_value': result['fci_value'],
            'consciousness_state': result['consciousness_state'],
            'synchronization_order': result['synchronization_order'],
            'interpretation': result['analysis_report'],
            'method': result['dcf_metadata']['method'],
            'detailed_metrics': {
                'num_candidates': result['dcf_metadata']['n_candidates'],
                'diffusion_coefficient': result['dcf_metadata']['diffusion_coefficient'],
                'new_diffusion_coefficient': result['dcf_metadata']['diffusion_coefficient'],  # Atualizado internamente
                'sync_orders': [],  # N√£o dispon√≠vel no formato atual
                'top_logits': [],   # N√£o dispon√≠vel no formato atual
                'candidate_tokens': [],  # N√£o dispon√≠vel no formato atual
                'final_probabilities': []  # N√£o dispon√≠vel no formato atual
            }
        }

        return adapted_result



def create_optical_text_decoder(
    vocab_size: int = 50257,
    max_tokens: int = 100,
    min_fci_threshold: float = 0.05,
    device: str = 'cpu'
) -> OpticalTextDecoder:
    """
    Factory function para criar OpticalTextDecoder.

    Args:
        vocab_size: Tamanho do vocabul√°rio
        max_tokens: M√°ximo de tokens a gerar
        min_fci_threshold: Limiar m√≠nimo de FCI para parada
        device: Dispositivo

    Returns:
        Inst√¢ncia de OpticalTextDecoder
    """
    return OpticalTextDecoder(
        vocab_size=vocab_size,
        max_tokens=max_tokens,
        min_fci_threshold=min_fci_threshold,
        device=device
    )