"""
Œ®QRH Pipeline - Processamento F√≠sico Completo (SEM forward())
==============================================================

Pipeline aut√¥nomo de processamento espectral-quaterni√¥nico:

    texto_bruto ‚Üí sinal_cont√≠nuo ‚Üí Œ®(x) ‚Üí processamento_espectral ‚Üí medida ‚Üí texto_sa√≠da

N√ÉO √© uma classe nn.Module. √â uma fun√ß√£o pura process(text: str) -> str.

Copyright (C) 2025 Klenio Araujo Padilha
Licensed under GNU GPLv3
"""

import torch
from typing import Dict, Optional
import sys
from pathlib import Path

# Adicionar src/ ao path
sys.path.insert(0, str(Path(__file__).parent.parent))

from core.spectral_harmonic_processor import (
    quaternion_from_signal,
    spectral_attention,
    harmonic_evolution,
    process_signal_stack,
    QuaternionMLP
)
from processing.text_to_wave import (
    text_to_fractal_embedding,
    create_spectral_character_map
)
from processing.wave_to_text import (
    wave_to_text,
    optical_probe
)


def process(text: str,
           n_layers: int = 6,
           alpha: float = 1.0,
           embed_dim: int = 64,
           temperature: float = 1.0,
           return_metrics: bool = False) -> str:
    """
    Pipeline f√≠sico RIGOROSO Œ®QRH (doe.md Se√ß√µes 2.9.1-2.9.4).

    RIGOROUS IMPLEMENTATION:
    - Uses MLP for quaternion mapping (NOT FFT) - doe.md 2.9.1
    - Uses Hamilton product for attention - doe.md 2.9.2
    - Uses unit quaternion R for evolution - doe.md 2.9.3

    Fluxo:
    1. Texto ‚Üí Embedding Fractal (an√°lise espectral)
    2. Embedding ‚Üí Quaternions Œ®(x) via MLP (RIGOROUS)
    3. Processamento Espectral-Harm√¥nico (n camadas)
    4. Colapso de Medida ‚Üí Caracteres
    5. Caracteres ‚Üí Texto

    Args:
        text: Texto de entrada (string bruta)
        n_layers: N√∫mero de camadas de processamento
        alpha: Par√¢metro do filtro espectral F(k)
        embed_dim: Dimens√£o do embedding (deve ser divis√≠vel por 4)
        temperature: Temperatura de amostragem
        return_metrics: Retornar m√©tricas de processamento

    Returns:
        Texto processado (string)
    """
    metrics = {}

    # 1. CONVERS√ÉO TEXTO ‚Üí SINAL CONT√çNUO
    # N√ÉO usa tokeniza√ß√£o - an√°lise espectral direta
    signal = text_to_fractal_embedding(text, embed_dim=embed_dim)  # [seq_len, embed_dim]
    seq_len = signal.shape[0]
    metrics['input_length'] = seq_len

    # Adicionar dimens√£o de batch
    signal = signal.unsqueeze(0)  # [1, seq_len, embed_dim]

    # 2. CRIAR MLP PARA QUATERNION MAPPING (RIGOROUS - doe.md 2.9.1)
    mlp = QuaternionMLP(embed_dim=embed_dim)

    # 3. PROCESSAMENTO ESPECTRAL-HARM√îNICO RIGOROSO
    # Substitui transformer.forward() por pipeline f√≠sico
    processed_signal = process_signal_stack(signal, n_layers=n_layers, alpha=alpha, mlp=mlp)

    # Remover batch dimension
    processed_signal = processed_signal.squeeze(0)  # [seq_len, embed_dim]

    # 4. CONVERS√ÉO SINAL ‚Üí QUATERNIONS (via MLP rigoroso)
    # Para medi√ß√£o qu√¢ntica
    processed_signal_batch = processed_signal.unsqueeze(0)  # [1, seq_len, embed_dim]
    psi_sequence = quaternion_from_signal(processed_signal_batch, mlp=mlp)
    psi_sequence = psi_sequence.squeeze(0)  # [seq_len, embed_dim, 4]

    # 5. COLAPSO DE MEDIDA ‚Üí TEXTO
    # N√ÉO usa softmax sobre vocab - usa proje√ß√£o em modos espectrais
    spectral_map = create_spectral_character_map(n_modes=embed_dim)
    output_text = wave_to_text(psi_sequence, spectral_map, temperature=temperature, min_seq_len=10)

    metrics['output_length'] = len(output_text)
    metrics['rigorous_mode'] = 'MLP-based quaternion mapping (doe.md 2.9.1)'

    if return_metrics:
        return output_text, metrics
    else:
        return output_text


def process_with_consciousness(text: str,
                               n_layers: int = 6,
                               alpha: float = 1.0,
                               embed_dim: int = 64) -> Dict:
    """
    Processamento Œ®QRH com an√°lise de consci√™ncia via AUTOCALIBRA√á√ÉO.

    Usa o sistema de autocalibra√ß√£o j√° implementado:
    - FractalConsciousnessProcessor (autocalibragem de D)
    - ConsciousnessMetrics (c√°lculo de FCI)
    - Enhanced QRH Processor (alpha adaptativo)

    Args:
        text: Texto de entrada
        n_layers: N√∫mero de camadas
        alpha: Par√¢metro espectral (inicial, ser√° autocaliobrado)
        embed_dim: Dimens√£o do embedding

    Returns:
        Dicion√°rio com texto processado e m√©tricas de consci√™ncia
    """
    # Usar sistema de autocalibra√ß√£o completo via Enhanced QRH Processor
    try:
        from ..core.enhanced_qrh_processor import EnhancedQRHProcessor
        from ..conscience.fractal_consciousness_processor import FractalConsciousnessProcessor

        # Criar processador enhanced (com autocalibragem)
        processor = EnhancedQRHProcessor(device='cpu')

        # Processar texto primeiro
        result = processor.process_text(text)

        # Processar consci√™ncia SEPARADAMENTE usando dados de acoplamento
        from ..conscience.fractal_consciousness_processor import create_consciousness_processor
        consciousness_processor = create_consciousness_processor(embedding_dim=64, device='cpu')

        # Extrair dados de acoplamento para processamento de consci√™ncia
        spectral_energy = result['consciousness_coupling']['spectral_energy']
        quaternion_phase = result['consciousness_coupling']['quaternion_phase']

        # Processar consci√™ncia fractal usando forward()
        # Criar tensor de entrada dummy para forward()
        dummy_input = torch.randn(1, 64, 64)  # [batch, seq_len, embed_dim]

        consciousness_results = consciousness_processor(
            dummy_input,
            spectral_energy=spectral_energy,
            quaternion_phase=quaternion_phase
        )

        # Adicionar resultados de consci√™ncia ao resultado
        result['consciousness_results'] = consciousness_results

        # EXTRA: Gerar texto real via wave_to_text se FCI for alto o suficiente
        generated_text = text  # fallback

        # Aplicar bootstrap cognitivo se FCI estiver baixo
        # Use lowercase 'fci' key for consistency across the system
        current_fci = consciousness_results.get('fci', consciousness_results.get('FCI', 0)) if consciousness_results else 0
        if consciousness_results and current_fci < 0.25:
            try:
                from .consciousness_bootstrapper import create_consciousness_bootstrapper

                print(f"üß† [psiqrh_pipeline] FCI baixo ({current_fci:.3f}), aplicando bootstrap cognitivo...")

                # Criar bootstrapper com par√¢metros SUPER agressivos
                bootstrapper = create_consciousness_bootstrapper(
                    chaos_strength=0.8,  # MUITO mais agressivo
                    logistic_r=3.99,
                    min_fci_threshold=0.25,
                    max_boost_iterations=10  # Mais itera√ß√µes
                )

                # Aplicar bootstrap
                if 'qrh_output' in result:
                    print(f"üîç [psiqrh_pipeline] DEBUG - qrh_output encontrado, shape: {result['qrh_output'].shape}")
                    psi_sequence = result['qrh_output']  # [batch, seq_len, embed_dim, 4]
                    print(f"üîç [psiqrh_pipeline] DEBUG - psi_sequence shape: {psi_sequence.shape}")
                    print(f"üîç [psiqrh_pipeline] DEBUG - consciousness_results keys: {consciousness_results.keys()}")

                    psi_boosted, consciousness_results = bootstrapper.apply_bootstrap(
                        psi_sequence.squeeze(0),  # Remove batch dimension
                        consciousness_results,
                        consciousness_processor
                    )

                    # Use lowercase 'fci' key for consistency across the system
                    current_fci = consciousness_results.get('fci', consciousness_results.get('FCI', 0))
                    print(f"‚úÖ [psiqrh_pipeline] Bootstrap aplicado: FCI = {current_fci:.3f}")
                else:
                    print(f"‚ö†Ô∏è  [psiqrh_pipeline] qrh_output n√£o encontrado no resultado")
            except Exception as e:
                print(f"‚ö†Ô∏è  [psiqrh_pipeline] Erro no bootstrap cognitivo: {e}")

        # Gerar texto se FCI for alto o suficiente
        # Use lowercase 'fci' key for consistency across the system
        current_fci = consciousness_results.get('fci', consciousness_results.get('FCI', 0)) if consciousness_results else 0
        if consciousness_results and current_fci > 0.25:
            try:
                from .wave_to_text import wave_to_text
                from .text_to_wave import create_spectral_character_map

                # Converter estado qu√¢ntico processado para texto
                # Usar qrh_output do EnhancedQRHProcessor
                if 'qrh_output' in result:
                    psi_sequence = result['qrh_output']  # [batch, seq_len, embed_dim, 4]
                    print(f"üîç [psiqrh_pipeline] qrh_output shape: {psi_sequence.shape}")
                    # Ensure proper shape for wave_to_text: [seq_len, embed_dim, 4]
                    if psi_sequence.dim() == 4:
                        psi_sequence = psi_sequence.squeeze(0)  # Remove batch dimension
                    print(f"üîç [psiqrh_pipeline] psi_sequence shape after squeeze: {psi_sequence.shape}")
                    spectral_map = create_spectral_character_map(n_modes=psi_sequence.shape[-2])
                    generated_text = wave_to_text(psi_sequence, spectral_map, min_seq_len=10)
                    print(f"üéØ [psiqrh_pipeline] Texto gerado via wave_to_text: '{generated_text}'")
            except Exception as e:
                print(f"‚ö†Ô∏è  [psiqrh_pipeline] Erro na gera√ß√£o de texto: {e}")
                generated_text = result.get('text_analysis', text)
        else:
            # FCI ainda baixo - usar an√°lise espectral
            generated_text = result.get('text_analysis', text)
            print(f"‚ÑπÔ∏è  [psiqrh_pipeline] FCI ainda baixo ({current_fci:.3f}), usando an√°lise espectral")

        # Extrair m√©tricas autocalibradas
        if consciousness_results:
            # Get FCI from multiple possible locations in consciousness results
            fci_value = None
            if 'fci' in consciousness_results:
                fci_value = consciousness_results['fci']
            elif 'FCI' in consciousness_results:
                fci_value = consciousness_results['FCI']
            elif 'fci_evolution' in consciousness_results and len(consciousness_results['fci_evolution']) > 0:
                fci_value = consciousness_results['fci_evolution'][-1]
                if isinstance(fci_value, torch.Tensor):
                    fci_value = fci_value.item()

            metrics = {
                'fractal_dimension': consciousness_results.get('fractal_dimension'),
                'fci': fci_value,
                'consciousness_state': consciousness_results.get('consciousness_state', {}).get('name'),
                'alpha_adapted': consciousness_results.get('alpha_adapted'),
                'autocalibracao': 'ATIVADA'
            }
        else:
            metrics = {
                'fractal_dimension': None,
                'fci': None,
                'autocalibracao': 'ERRO',
                'error': 'consciousness_results n√£o dispon√≠vel'
            }

        return {
            'output': generated_text,
            'metrics': metrics,
            'full_result': result
        }

    except Exception as e:
        # Se enhanced processor falhar, retornar processamento b√°sico
        output_text, basic_metrics = process(
            text, n_layers=n_layers, alpha=alpha,
            embed_dim=embed_dim, return_metrics=True
        )

        return {
            'output': output_text,
            'metrics': {
                **basic_metrics,
                'autocalibracao': 'DESATIVADA',
                'error': str(e)
            }
        }


def batch_process(texts: list,
                 n_layers: int = 6,
                 alpha: float = 1.0,
                 embed_dim: int = 64) -> list:
    """
    Processamento em lote de m√∫ltiplos textos.

    Args:
        texts: Lista de strings
        n_layers: N√∫mero de camadas
        alpha: Par√¢metro espectral
        embed_dim: Dimens√£o do embedding

    Returns:
        Lista de textos processados
    """
    outputs = []

    for text in texts:
        output = process(text, n_layers=n_layers, alpha=alpha, embed_dim=embed_dim)
        outputs.append(output)

    return outputs


def interactive_process(n_layers: int = 6,
                       alpha: float = 1.0,
                       embed_dim: int = 64):
    """
    Modo interativo para processamento Œ®QRH.

    Loop:
    1. Usu√°rio digita texto
    2. Sistema processa via pipeline f√≠sico
    3. Exibe resultado e m√©tricas
    4. Repete at√© 'quit'
    """
    print("=" * 60)
    print("Œ®QRH Interactive Pipeline")
    print("=" * 60)
    print(f"Configura√ß√£o: {n_layers} camadas, Œ±={alpha}, dim={embed_dim}")
    print("Digite 'quit' para sair\n")

    while True:
        try:
            text = input(">>> ")

            if text.lower() in ['quit', 'exit', 'q']:
                print("Encerrando...")
                break

            if not text.strip():
                continue

            # Processar
            result = process_with_consciousness(
                text, n_layers=n_layers,
                alpha=alpha, embed_dim=embed_dim
            )

            # Exibir resultado
            print(f"\nSa√≠da: {result['output']}")
            print(f"M√©tricas:")
            for key, value in result['metrics'].items():
                print(f"  {key}: {value}")
            print()

        except KeyboardInterrupt:
            print("\nInterrompido pelo usu√°rio")
            break
        except Exception as e:
            print(f"Erro: {e}")
            continue


if __name__ == "__main__":
    # Teste b√°sico
    test_text = "Hello PSIQRH"
    print(f"Input: {test_text}")

    output = process(test_text, n_layers=3, embed_dim=64)
    print(f"Output: {output}")

    # Modo interativo
    # interactive_process(n_layers=3, alpha=1.0, embed_dim=64)
