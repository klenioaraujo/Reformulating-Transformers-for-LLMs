#!/usr/bin/env python3
"""
Î¨QRH Zero False Positive Validator - Prompt Engine para Testes Rigorosos
=======================================================================

Garante zero false positives, zero hardcoding, zero fullbacks e zero monks:
- ValidaÃ§Ã£o dinÃ¢mica baseada em dados reais
- DetecÃ§Ã£o de hardcoding e valores fixos
- AnÃ¡lise de padrÃµes de fullback/monk
- Salvamento automÃ¡tico em tmp/
"""

import sys
import os
import json
import hashlib
import inspect
import ast
import re
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional
import numpy as np
import torch

# Adicionar path para importar mÃ³dulos do projeto
sys.path.append(str(Path(__file__).parent.parent))


class ZeroFalsePositiveValidator:
    """Engine de validaÃ§Ã£o rigorosa para garantir testes autÃªnticos"""

    def __init__(self):
        self.validation_results = {}
        self.hardcoding_patterns = [
            r'\b\d+\.\d+\b',  # NÃºmeros fixos
            r'\b\d+\b',       # Inteiros fixos
            r'\"[^\"]*\"',   # Strings fixas
            r'\'[^\']*\'',   # Strings fixas
            r'\bTrue\b|\bFalse\b',  # Booleanos fixos
        ]
        self.fullback_patterns = [
            r'except.*pass',    # ExceÃ§Ãµes ignoradas
            r'except.*return.*default',  # Retornos padrÃ£o
            r'if.*error.*return.*default',  # Fallbacks
        ]
        self.monk_patterns = [
            r'print.*test',     # Prints de teste
            r'logging\.debug',  # Logs de debug
            r'assert.*True',    # Asserts vazios
        ]

    def validate_test_file(self, file_path: Path) -> Dict[str, Any]:
        """Valida arquivo de teste para anti-patterns"""
        print(f"ğŸ” Validando arquivo: {file_path.name}")

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # AnÃ¡lise AST para detecÃ§Ã£o estrutural
            tree = ast.parse(content)

            validation = {
                'file_name': file_path.name,
                'file_hash': hashlib.md5(content.encode()).hexdigest(),
                'hardcoding_detected': self._detect_hardcoding(content),
                'fullback_detected': self._detect_fullbacks(content),
                'monk_detected': self._detect_monks(content),
                'ast_analysis': self._analyze_ast(tree),
                'dynamic_validation': self._validate_dynamic_patterns(content),
                'validation_score': 0.0,
                'status': 'pending'
            }

            # Calcular score de validaÃ§Ã£o
            validation['validation_score'] = self._calculate_validation_score(validation)
            validation['status'] = 'passed' if validation['validation_score'] >= 0.9 else 'failed'

            return validation

        except Exception as e:
            return {
                'file_name': file_path.name,
                'error': str(e),
                'status': 'error'
            }

    def _detect_hardcoding(self, content: str) -> List[Dict[str, Any]]:
        """Detecta hardcoding no cÃ³digo"""
        detected = []

        for pattern in self.hardcoding_patterns:
            matches = re.finditer(pattern, content)
            for match in matches:
                # Ignorar valores em comentÃ¡rios
                line_start = content.rfind('\n', 0, match.start()) + 1
                line_end = content.find('\n', match.start())
                line = content[line_start:line_end] if line_end != -1 else content[line_start:]

                if not line.strip().startswith('#'):
                    detected.append({
                        'pattern': pattern,
                        'value': match.group(),
                        'position': match.start(),
                        'line': line.strip()
                    })

        return detected

    def _detect_fullbacks(self, content: str) -> List[Dict[str, Any]]:
        """Detecta padrÃµes de fullback"""
        detected = []

        for pattern in self.fullback_patterns:
            matches = re.finditer(pattern, content, re.IGNORECASE | re.DOTALL)
            for match in matches:
                detected.append({
                    'pattern': pattern,
                    'context': match.group(),
                    'position': match.start()
                })

        return detected

    def _detect_monks(self, content: str) -> List[Dict[str, Any]]:
        """Detecta padrÃµes de monk (testes artificiais)"""
        detected = []

        for pattern in self.monk_patterns:
            matches = re.finditer(pattern, content, re.IGNORECASE)
            for match in matches:
                detected.append({
                    'pattern': pattern,
                    'context': match.group(),
                    'position': match.start()
                })

        return detected

    def _analyze_ast(self, tree: ast.AST) -> Dict[str, Any]:
        """AnÃ¡lise AST para detecÃ§Ã£o de padrÃµes estruturais"""
        analysis = {
            'function_count': 0,
            'class_count': 0,
            'test_methods': [],
            'assert_count': 0,
            'dynamic_patterns': []
        }

        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                analysis['function_count'] += 1
                if node.name.startswith('test'):
                    analysis['test_methods'].append(node.name)
            elif isinstance(node, ast.ClassDef):
                analysis['class_count'] += 1
            elif isinstance(node, ast.Assert):
                analysis['assert_count'] += 1
                # Verificar se assert Ã© dinÃ¢mico
                if self._is_dynamic_assert(node):
                    analysis['dynamic_patterns'].append('dynamic_assert')

        return analysis

    def _is_dynamic_assert(self, node: ast.Assert) -> bool:
        """Verifica se assert Ã© dinÃ¢mico (nÃ£o hardcoded)"""
        # Verificar se o teste envolve variÃ¡veis ou chamadas de funÃ§Ã£o
        for child in ast.walk(node.test):
            if isinstance(child, (ast.Name, ast.Call, ast.Attribute)):
                return True
        return False

    def _validate_dynamic_patterns(self, content: str) -> Dict[str, Any]:
        """Valida padrÃµes dinÃ¢micos no cÃ³digo"""
        patterns = {
            'random_usage': len(re.findall(r'random\.', content)) > 0,
            'numpy_usage': len(re.findall(r'numpy\.|np\.', content)) > 0,
            'torch_usage': len(re.findall(r'torch\.', content)) > 0,
            'variable_assignment': len(re.findall(r'\w+\s*=', content)) > 10,
            'function_calls': len(re.findall(r'\w+\(', content)) > 5
        }

        return patterns

    def _calculate_validation_score(self, validation: Dict[str, Any]) -> float:
        """Calcula score de validaÃ§Ã£o baseado em detecÃ§Ãµes"""
        score = 1.0

        # Penalizar hardcoding
        hardcoding_penalty = min(1.0, len(validation['hardcoding_detected']) * 0.1)
        score -= hardcoding_penalty * 0.3

        # Penalizar fullbacks
        fullback_penalty = min(1.0, len(validation['fullback_detected']) * 0.2)
        score -= fullback_penalty * 0.4

        # Penalizar monks
        monk_penalty = min(1.0, len(validation['monk_detected']) * 0.15)
        score -= monk_penalty * 0.3

        # Recompensar padrÃµes dinÃ¢micos
        dynamic_bonus = sum(1 for v in validation['dynamic_validation'].values() if v) / 5.0
        score += dynamic_bonus * 0.2

        return max(0.0, min(1.0, score))

    def validate_test_suite(self, test_files: List[Path]) -> Dict[str, Any]:
        """Valida suÃ­te completa de testes"""
        print("ğŸš€ VALIDANDO SUÃTE COMPLETA DE TESTES Î¨QRH")
        print("=" * 60)

        results = {
            'validation_timestamp': str(np.datetime64('now')),
            'total_files': len(test_files),
            'files_validated': [],
            'overall_score': 0.0,
            'anti_pattern_summary': {},
            'recommendations': []
        }

        total_score = 0.0
        validated_count = 0

        for test_file in test_files:
            if test_file.exists():
                file_validation = self.validate_test_file(test_file)
                results['files_validated'].append(file_validation)

                if file_validation.get('status') == 'passed':
                    total_score += file_validation['validation_score']
                    validated_count += 1

                print(f"ğŸ“Š {test_file.name}: {file_validation.get('validation_score', 0):.3f} - {file_validation.get('status', 'error')}")

        if validated_count > 0:
            results['overall_score'] = total_score / validated_count

        # Gerar sumÃ¡rio de anti-patterns
        results['anti_pattern_summary'] = self._generate_anti_pattern_summary(results['files_validated'])

        # Gerar recomendaÃ§Ãµes
        results['recommendations'] = self._generate_recommendations(results)

        return results

    def _generate_anti_pattern_summary(self, files_validated: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Gera sumÃ¡rio de anti-patterns detectados"""
        summary = {
            'total_hardcoding': 0,
            'total_fullbacks': 0,
            'total_monks': 0,
            'files_with_issues': 0
        }

        for file_val in files_validated:
            if file_val.get('status') != 'error':
                summary['total_hardcoding'] += len(file_val.get('hardcoding_detected', []))
                summary['total_fullbacks'] += len(file_val.get('fullback_detected', []))
                summary['total_monks'] += len(file_val.get('monk_detected', []))

                if any([file_val.get('hardcoding_detected'), file_val.get('fullback_detected'), file_val.get('monk_detected')]):
                    summary['files_with_issues'] += 1

        return summary

    def _generate_recommendations(self, results: Dict[str, Any]) -> List[str]:
        """Gera recomendaÃ§Ãµes baseadas na validaÃ§Ã£o"""
        recommendations = []

        anti_patterns = results['anti_pattern_summary']

        if anti_patterns['total_hardcoding'] > 0:
            recommendations.append(f"ğŸ”§ Substituir {anti_patterns['total_hardcoding']} valores hardcoded por cÃ¡lculos dinÃ¢micos")

        if anti_patterns['total_fullbacks'] > 0:
            recommendations.append(f"ğŸ›¡ï¸  Remover {anti_patterns['total_fullbacks']} padrÃµes de fullback por tratamento adequado de erros")

        if anti_patterns['total_monks'] > 0:
            recommendations.append(f"ğŸ§ª Eliminar {anti_patterns['total_monks']} padrÃµes de monk por testes autÃªnticos")

        if results['overall_score'] < 0.9:
            recommendations.append("âš ï¸  Implementar mais padrÃµes dinÃ¢micos e menos valores fixos")

        if len(recommendations) == 0:
            recommendations.append("âœ… SuÃ­te de testes atende aos critÃ©rios de zero false positives")

        return recommendations

    def save_validation_report(self, results: Dict[str, Any], output_dir: Path = None) -> Path:
        """Salva relatÃ³rio de validaÃ§Ã£o"""
        if output_dir is None:
            output_dir = Path(__file__).parent.parent / 'tmp'

        output_dir.mkdir(exist_ok=True)

        timestamp = str(np.datetime64('now')).replace(':', '').replace('-', '').replace(' ', '_')
        output_file = output_dir / f"Î¨QRH_zero_false_positive_validation_{timestamp}.json"

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        print(f"ğŸ’¾ RelatÃ³rio salvo em: {output_file}")
        return output_file


def main():
    """FunÃ§Ã£o principal"""

    # Definir arquivos de teste para validaÃ§Ã£o
    test_files = [
        Path(__file__).parent / "Î¨QRH_dataflow_mapper.py",
        Path(__file__).parent / "Î¨QRH_humanchat_analyzer.py",
        Path(__file__).parent / "Î¨QRH_test_prompt_engine.py",
        Path(__file__).parent / "run_complete_tests.py",
        Path(__file__).parent / "advanced_mathematical_tests.py",
        Path(__file__).parent / "spectral_analysis.py",
        Path(__file__).parent / "consciousness_integration.py"
    ]

    validator = ZeroFalsePositiveValidator()

    try:
        # Executar validaÃ§Ã£o completa
        validation_results = validator.validate_test_suite(test_files)

        # Salvar relatÃ³rio
        report_path = validator.save_validation_report(validation_results)

        # Resumo final
        print("\n" + "=" * 60)
        print("ğŸ¯ VALIDAÃ‡ÃƒO COMPLETA CONCLUÃDA")
        print(f"ğŸ“Š Score Geral: {validation_results['overall_score']:.3f}")
        print(f"ğŸ“ Arquivos Validados: {validation_results['total_files']}")
        print(f"ğŸ”§ Hardcoding Detectado: {validation_results['anti_pattern_summary']['total_hardcoding']}")
        print(f"ğŸ›¡ï¸  Fullbacks Detectados: {validation_results['anti_pattern_summary']['total_fullbacks']}")
        print(f"ğŸ§ª Monks Detectados: {validation_results['anti_pattern_summary']['total_monks']}")

        print("\nğŸ“‹ RECOMENDAÃ‡Ã•ES:")
        for rec in validation_results['recommendations']:
            print(f"   {rec}")

        print(f"\nğŸ“„ RelatÃ³rio completo: {report_path}")

    except Exception as e:
        print(f"ğŸ’¥ ERRO durante validaÃ§Ã£o: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()