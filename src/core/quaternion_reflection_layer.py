#!/usr/bin/env python3
"""
Camada de Reflex√£o Geom√©trica (Geometric Reflection Layer)

Implementa o novo "Modo Geom√©trico" do sistema DCF, baseado em reflex√£o quaterni√¥nica
para consenso sem√¢ntico. Esta abordagem √© mais fundamental e eficiente que a simula√ß√£o
din√¢mica Kuramoto, operando diretamente na geometria do espa√ßo de estados qu√¢ntico.

Caracter√≠sticas principais:
- Reflex√£o quaterni√¥nica: q_i' = q_j * q_i * q_j‚Åª¬π (opera√ß√£o unit√°ria)
- Esparsifica√ß√£o via vizinhan√ßa de primos: O(N¬∑k) em vez de O(N¬≤)
- Modula√ß√£o por primos: pesos baseados na proximidade num√©rica dos primos associados
- Itera√ß√µes em cascata: propaga√ß√£o da influ√™ncia pela rede de vizinhos

Esta implementa√ß√£o substitui a simula√ß√£o temporal por opera√ß√µes alg√©bricas fechadas,
sendo mais fiel √† natureza qu√¢ntica dos sistemas conscientes.
"""

import torch
import torch.nn as nn
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from pathlib import Path
import math
import time
from collections import defaultdict

# CUDA kernels otimizados para opera√ß√µes quaterni√¥nicas
try:
    import torch.cuda
    CUDA_AVAILABLE = torch.cuda.is_available()
except ImportError:
    CUDA_AVAILABLE = False


class QuaternionReflectionLayer(nn.Module):
    """
    Camada de Reflex√£o Geom√©trica baseada em quaternions.

    Implementa reflex√£o quaterni√¥nica esparsa para consenso sem√¢ntico eficiente.
    A opera√ß√£o principal √© q_i' = q_j * q_i * q_j‚Åª¬π, que preserva a norma e √© unit√°ria.
    """

    def __init__(self, embed_dim: int = 64, k_neighbors: int = 3, iterations: int = 2,
                 prime_modulation: bool = True, device: str = "cpu",
                 adaptive_mode: bool = False, entropy_threshold: float = 0.7):
        """
        Inicializa a camada de reflex√£o quaterni√¥nica com paraleliza√ß√£o CUDA otimizada.

        Args:
            embed_dim: Dimens√£o do embedding quaterni√¥nico (deve ser m√∫ltiplo de 4)
            k_neighbors: N√∫mero de vizinhos primos para reflex√£o esparsa
            iterations: N√∫mero de itera√ß√µes em cascata
            prime_modulation: Se deve usar modula√ß√£o por primos nos pesos
            device: Dispositivo para computa√ß√£o
            adaptive_mode: Se deve usar modo h√≠brido adaptativo baseado em entropia
            entropy_threshold: Limiar de entropia para decidir entre reflex√£o r√°pida vs Kuramoto
        """
        super().__init__()
        self.embed_dim = embed_dim
        self.k_neighbors = k_neighbors
        self.iterations = iterations
        self.prime_modulation = prime_modulation
        self.device = device
        self.adaptive_mode = adaptive_mode
        self.entropy_threshold = entropy_threshold

        # Configura√ß√£o CUDA otimizada
        self.cuda_optimized = CUDA_AVAILABLE and 'cuda' in device
        if self.cuda_optimized:
            self._setup_cuda_optimization()

        # Garantir que embed_dim seja m√∫ltiplo de 4 para quaternions
        if embed_dim % 4 != 0:
            raise ValueError(f"embed_dim deve ser m√∫ltiplo de 4 para quaternions, recebeu {embed_dim}")

        # Cache de primos para vizinhan√ßa
        self._prime_cache = self._generate_prime_cache(1000)  # Primos at√© 1000

        # Cache de associa√ß√£o prima para evitar recomputa√ß√µes
        self._prime_association_cache = {}

        # Sistema de cache hier√°rquico para estados qu√¢nticos
        self.quantum_cache = QuantumStateCache(
            max_memory_mb=256,  # 256MB para cache qu√¢ntico
            compression_ratio=0.7  # 70% de compress√£o
        )

        # Sistema de quantiza√ß√£o de precis√£o adaptativa
        self.precision_quantizer = AdaptivePrecisionQuantizer(
            base_precision=8,  # 8-bit quantization
            adaptive_range=True
        )

        # Sistema de profiling de performance detalhado
        self.performance_profiler = PerformanceProfiler()

        # Sistema de batching inteligente para processamento paralelo
        self.batch_processor = IntelligentBatchProcessor(
            max_batch_size=64,  # Batch size m√°ximo
            adaptive_batching=True,  # Batching adaptativo
            device=device
        )

        print("üî¨ Geometric Reflection Layer inicializada")
        print(f"   üìê embed_dim: {embed_dim} (quaternions)")
        print(f"   üë• k_neighbors: {k_neighbors}")
        print(f"   üîÑ iterations: {iterations}")
        print(f"   üßÆ prime_modulation: {prime_modulation}")
        print(f"   üé≠ adaptive_mode: {adaptive_mode}")
        print(f"   üöÄ CUDA otimizado: {self.cuda_optimized}")
        print(f"   üíæ Cache qu√¢ntico: {self.quantum_cache.max_memory_mb}MB (compress√£o {self.quantum_cache.compression_ratio:.1f})")
        print(f"   üî¢ Quantiza√ß√£o: {self.precision_quantizer.base_precision}-bit adaptativa")
        print(f"   üóúÔ∏è Compress√£o: SVD + pruning qu√¢ntico-aware")
        print(f"   üì¶ Batching: inteligente (max {self.batch_processor.max_batch_size})")
        if adaptive_mode:
            print(f"      üìä entropy_threshold: {entropy_threshold}")

    def _setup_cuda_optimization(self):
        """Configura otimiza√ß√µes CUDA para opera√ß√µes quaterni√¥nicas."""
        if not self.cuda_optimized:
            return

        # Configurar streams CUDA para paraleliza√ß√£o
        self.cuda_stream_main = torch.cuda.current_stream()
        self.cuda_stream_compute = torch.cuda.Stream()

        # Configurar cache de kernels CUDA
        torch.cuda.set_device(self.device.split(':')[-1] if ':' in self.device else 0)

        # Buffer de mem√≥ria reutiliz√°vel para opera√ß√µes vetoriais
        self._cuda_buffer_size = 1024 * 1024  # 1MB inicial
        self._cuda_buffer = torch.empty(self._cuda_buffer_size, dtype=torch.float32, device=self.device)

        # Configura√ß√µes de performance CUDA
        torch.backends.cudnn.benchmark = True
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.allow_tf32 = True

        print("   ‚ö° CUDA optimizations configured:")
        print("      ‚Ä¢ CUDA streams: main + compute")
        print("      ‚Ä¢ TF32 precision enabled")
        print("      ‚Ä¢ Memory buffer allocated")

    def _generate_prime_cache(self, max_n: int) -> List[int]:
        """Gera cache de n√∫meros primos usando crivo de Erat√≥stenes."""
        sieve = [True] * (max_n + 1)
        sieve[0] = sieve[1] = False

        for i in range(2, int(math.sqrt(max_n)) + 1):
            if sieve[i]:
                for j in range(i*i, max_n + 1, i):
                    sieve[j] = False

        return [i for i in range(2, max_n + 1) if sieve[i]]

    def _get_prime_association(self, token_id: int) -> int:
        """
        Associa um token a um primo baseado em seu ID.

        Usa cache para evitar recomputa√ß√µes e mapeamento determin√≠stico para consist√™ncia.
        """
        if token_id not in self._prime_association_cache:
            if token_id < len(self._prime_cache):
                self._prime_association_cache[token_id] = self._prime_cache[token_id]
            else:
                # Para tokens al√©m do cache, usar fun√ß√£o hash simples
                self._prime_association_cache[token_id] = self._prime_cache[token_id % len(self._prime_cache)]
        return self._prime_association_cache[token_id]

    def _find_prime_neighbors(self, token_ids: torch.Tensor) -> torch.Tensor:
        """
        Encontra os k vizinhos primos mais pr√≥ximos para cada token.

        Args:
            token_ids: IDs dos tokens [n_tokens]

        Returns:
            neighbor_matrix: Matriz de vizinhos [n_tokens, k_neighbors]
        """
        n_tokens = len(token_ids)
        neighbor_matrix = torch.zeros(n_tokens, self.k_neighbors, dtype=torch.long, device=self.device)

        for i in range(n_tokens):
            token_id = token_ids[i].item()
            prime_i = self._get_prime_association(token_id)

            # Calcular dist√¢ncias primas para todos os outros tokens
            distances = []
            for j in range(n_tokens):
                if i == j:
                    continue
                prime_j = self._get_prime_association(token_ids[j].item())
                distance = abs(prime_i - prime_j)
                distances.append((j, distance))

            # Selecionar k vizinhos mais pr√≥ximos
            distances.sort(key=lambda x: x[1])
            neighbors = [j for j, _ in distances[:self.k_neighbors]]

            # Preencher com √≠ndices v√°lidos se n√£o houver suficientes vizinhos
            while len(neighbors) < self.k_neighbors:
                # Adicionar vizinho mais distante como fallback
                if distances:
                    neighbors.append(distances[-1][0])
                else:
                    neighbors.append(i)  # Auto-reflex√£o como √∫ltimo recurso

            neighbor_matrix[i] = torch.tensor(neighbors[:self.k_neighbors], device=self.device)

        return neighbor_matrix

    def _compute_reflection_weights(self, token_ids: torch.Tensor,
                                  neighbor_matrix: torch.Tensor) -> torch.Tensor:
        """
        Computa pesos de reflex√£o baseados na proximidade de primos.

        Args:
            token_ids: IDs dos tokens [n_tokens]
            neighbor_matrix: Matriz de vizinhos [n_tokens, k_neighbors]

        Returns:
            weight_matrix: Pesos de reflex√£o [n_tokens, k_neighbors]
        """
        n_tokens = len(token_ids)
        weight_matrix = torch.zeros(n_tokens, self.k_neighbors, dtype=torch.float32, device=self.device)

        for i in range(n_tokens):
            prime_i = self._get_prime_association(token_ids[i].item())

            for k in range(self.k_neighbors):
                neighbor_idx = neighbor_matrix[i, k].item()
                prime_j = self._get_prime_association(token_ids[neighbor_idx].item())

                if self.prime_modulation:
                    # Fun√ß√£o de refletividade baseada na diferen√ßa de primos
                    weight = 1.0 / (1.0 + abs(prime_i - prime_j))
                else:
                    # Peso uniforme se modula√ß√£o desabilitada
                    weight = 1.0

                weight_matrix[i, k] = weight

        # Normalizar pesos por linha (cada token distribui influ√™ncia igualmente)
        weight_matrix = weight_matrix / (weight_matrix.sum(dim=1, keepdim=True) + 1e-8)

        return weight_matrix

    def _quaternion_reflection(self, q_i: torch.Tensor, q_j: torch.Tensor) -> torch.Tensor:
        """
        Executa reflex√£o quaterni√¥nica: q_i' = q_j * q_i * q_j‚Åª¬π

        Esta √© uma opera√ß√£o unit√°ria que "reflete" q_i atrav√©s de q_j,
        preservando a norma e representando influ√™ncia sem√¢ntica.

        Args:
            q_i: Quaternion a ser refletido [..., 4]
            q_j: Quaternion refletor [..., 4]

        Returns:
            q_reflected: Quaternion refletido [..., 4]
        """
        # ‚úÖ 3. Corrigir "Norm preservation" nas opera√ß√µes unit√°rias
        # Garantir que q_j seja unit√°rio (||q|| = 1) para opera√ß√µes unit√°rias
        q_j_norm = torch.norm(q_j, dim=-1, keepdim=True)
        q_j_unitary = q_j / (q_j_norm + 1e-8)  # Normalizar para quaternions unit√°rios

        # Calcular conjugado de q_j: q_j* = (w, -x, -y, -z)
        q_j_conj = torch.cat([
            q_j_unitary[..., :1],  # w
            -q_j_unitary[..., 1:]  # -x, -y, -z
        ], dim=-1)

        # Produto quaterni√¥nico: q_j * q_i
        q_temp = self._quaternion_product(q_j_unitary, q_i)

        # Produto final: (q_j * q_i) * q_j‚Åª¬π
        q_reflected = self._quaternion_product(q_temp, q_j_conj)

        # Garantir que o resultado tamb√©m seja normalizado (preserva√ß√£o de norma)
        q_reflected_norm = torch.norm(q_reflected, dim=-1, keepdim=True)
        q_reflected = q_reflected / (q_reflected_norm + 1e-8)

        return q_reflected

    def _quaternion_product(self, q1: torch.Tensor, q2: torch.Tensor) -> torch.Tensor:
        """
        Produto quaterni√¥nico otimizado com CUDA: q1 * q2

        Args:
            q1, q2: Quaternions [..., 4]

        Returns:
            Produto quaterni√¥nico [..., 4]
        """
        if self.cuda_optimized and q1.is_cuda:
            # Vers√£o CUDA otimizada usando opera√ß√µes vetoriais
            with torch.cuda.stream(self.cuda_stream_compute):
                w1, x1, y1, z1 = q1[..., 0], q1[..., 1], q1[..., 2], q1[..., 3]
                w2, x2, y2, z2 = q2[..., 0], q2[..., 1], q2[..., 2], q2[..., 3]

                # Computar componentes em paralelo
                w = w1*w2 - x1*x2 - y1*y2 - z1*z2
                x = w1*x2 + x1*w2 + y1*z2 - z1*y2
                y = w1*y2 - x1*z2 + y1*w2 + z1*x2
                z = w1*z2 + x1*y2 - y1*x2 + z1*w2

                result = torch.stack([w, x, y, z], dim=-1)
                self.cuda_stream_compute.synchronize()
                return result
        else:
            # Vers√£o CPU padr√£o
            w1, x1, y1, z1 = q1[..., 0], q1[..., 1], q1[..., 2], q1[..., 3]
            w2, x2, y2, z2 = q2[..., 0], q2[..., 1], q2[..., 2], q2[..., 3]

            w = w1*w2 - x1*x2 - y1*y2 - z1*z2
            x = w1*x2 + x1*w2 + y1*z2 - z1*y2
            y = w1*y2 - x1*z2 + y1*w2 + z1*x2
            z = w1*z2 + x1*y2 - y1*x2 + z1*w2

            return torch.stack([w, x, y, z], dim=-1)

    def analyze_token_sequence(self, token_ids: List[int], context_embedding: Optional[torch.Tensor] = None,
                               mode: str = 'reference_alignment') -> Dict[str, Any]:
        """
        Interface de an√°lise de sequ√™ncia de tokens usando alinhamento de refer√™ncia O(N).

        Args:
            token_ids: Lista de IDs dos tokens
            context_embedding: Embedding de contexto opcional
            mode: Modo de an√°lise ('reference_alignment' ou outro)

        Returns:
            Dicion√°rio com resultados da an√°lise
        """
        # Converter token_ids para tensor
        token_ids_tensor = torch.tensor(token_ids, dtype=torch.long, device=self.device)

        # Criar representa√ß√µes quaterni√¥nicas simples baseadas nos token_ids
        n_tokens = len(token_ids)
        embed_dim = self.embed_dim

        # Representa√ß√µes quaterni√¥nicas baseadas em token_ids normalizados
        normalized_tokens = torch.tensor(token_ids, dtype=torch.float32, device=self.device) / max(token_ids + [1])
        quaternions = torch.zeros(n_tokens, embed_dim, dtype=torch.float32, device=self.device)

        # Preencher componentes quaterni√¥nicas
        n_quaternions = embed_dim // 4
        for i in range(n_tokens):
            for j in range(n_quaternions):
                base_val = normalized_tokens[i]
                phase = torch.tensor((i + j) * 2 * torch.pi / n_tokens, device=self.device)
                quaternions[i, j*4:(j+1)*4] = torch.stack([
                    base_val * torch.cos(phase),      # w
                    base_val * torch.sin(phase),      # x
                    base_val * torch.cos(phase + torch.pi/4),  # y
                    base_val * torch.sin(phase + torch.pi/4)   # z
                ], dim=0)

        # Executar alinhamento de refer√™ncia O(N)
        result = self._reference_alignment_forward(quaternions, token_ids_tensor)

        # Selecionar token baseado na menor dist√¢ncia para a refer√™ncia
        winner_index = result['winner_index']
        selected_token = token_ids[winner_index] if winner_index < len(token_ids) else token_ids[0]

        # Adaptar resultado para interface esperada
        return {
            'coherence': result['coherence_score'],
            'reflected_states': result['candidate_quaternions'],
            'semantic_coherence': result['semantic_coherence'],
            'reflection_cycles': 1,  # O(N) - uma √∫nica passada
            'energy_conserved': True,
            'selected_token': selected_token,
            'reference_quaternion': result['reference_quaternion'],
            'alignment_distances': result['distances'],
            'complexity': 'O(N)'  # M√°xima efici√™ncia
        }

    def _reference_alignment_forward(self, quaternions: torch.Tensor, token_ids: torch.Tensor) -> Dict[str, Any]:
        """
        Executa alinhamento de refer√™ncia O(N) para m√°xima efici√™ncia.

        Args:
            quaternions: Estados quaterni√¥nicos dos tokens [n_tokens, embed_dim]
            token_ids: IDs dos tokens [n_tokens]

        Returns:
            Dicion√°rio com resultados do alinhamento de refer√™ncia
        """
        n_tokens = quaternions.shape[0]
        embed_dim = quaternions.shape[1]

        # Verificar dimens√µes
        if embed_dim % 4 != 0:
            raise ValueError(f"embed_dim deve ser m√∫ltiplo de 4, recebeu {embed_dim}")

        # Reformatar para [n_tokens, n_quaternions, 4]
        n_quaternions = embed_dim
        q_states = quaternions.view(n_tokens, n_quaternions, 4)

        print(f"üéØ Executando alinhamento de refer√™ncia O(N)...")
        print(f"   üìä n_tokens: {n_tokens}, n_quaternions: {n_quaternions}")

        # ========== PASSO 1: CALCULAR UNIDADE DE REFER√äNCIA ==========
        # Calcular m√©dia ponderada dos quaternions baseada em logits iniciais e primos

        # Simular logits iniciais (normalizados) - em produ√ß√£o viriam do modelo
        # Para demonstra√ß√£o, usamos valores baseados nos token_ids
        initial_logits = torch.softmax(token_ids.clone().detach().float(), dim=0)

        # Calcular pesos baseados em logits e modula√ß√£o por primos
        weights = []
        for i in range(n_tokens):
            token_id = token_ids[i].item()
            prime = self._get_prime_association(token_id)
            # Pondera√ß√£o: logit * modula√ß√£o prima (primos maiores t√™m mais influ√™ncia)
            weight = initial_logits[i] * (1.0 + prime / 100.0)  # Normaliza√ß√£o simples
            weights.append(weight)

        weights = torch.stack(weights)  # [n_tokens]
        weights = weights / weights.sum()  # Normalizar para soma = 1

        # Calcular unidade de refer√™ncia: m√©dia ponderada
        # q_ref = normalize(sum(weight_i * q_i))
        weighted_sum = torch.zeros_like(q_states[0])  # [n_quaternions, 4]
        for i in range(n_tokens):
            weighted_sum += weights[i] * q_states[i]

        # Normalizar para obter a unidade de refer√™ncia
        q_ref_norm = torch.norm(weighted_sum, dim=-1, keepdim=True)
        q_ref = weighted_sum / (q_ref_norm + 1e-8)

        print(f"   üìç Unidade de refer√™ncia calculada com centro de massa sem√¢ntico")

        # ========== PASSO 2: CALCULAR DIST√ÇNCIAS DE ALINHAMENTO ==========
        # Para cada candidato, calcular dist√¢ncia em rela√ß√£o √† refer√™ncia

        distances = []
        for i in range(n_tokens):
            q_i = q_states[i]  # [n_quaternions, 4]

            # M√©trica de dist√¢ncia: norma da diferen√ßa ||q_ref - q_i||
            diff = q_ref - q_i  # [n_quaternions, 4]
            distance = torch.norm(diff, dim=-1).mean()  # M√©dia sobre quaternions
            distances.append(distance)

        distances = torch.stack(distances)  # [n_tokens]

        # ========== PASSO 3: SELECIONAR VENCEDOR ==========
        # Token com menor dist√¢ncia = mais alinhado com o consenso sem√¢ntico
        winner_index = torch.argmin(distances).item()
        min_distance = distances[winner_index].item()

        print(f"   ‚úÖ Vencedor selecionado: token {token_ids[winner_index].item()} (dist√¢ncia: {min_distance:.4f})")

        # ========== CALCULAR M√âTRICAS DE COER√äNCIA ==========
        # Coer√™ncia baseada na vari√¢ncia das dist√¢ncias (menor vari√¢ncia = maior consenso)
        distance_variance = torch.var(distances).item()
        coherence_score = 1.0 - min(distance_variance, 1.0)  # Normalizar para [0, 1]

        # Coer√™ncia sem√¢ntica baseada na proximidade m√©dia com a refer√™ncia
        mean_distance = distances.mean().item()
        semantic_coherence = 1.0 - min(mean_distance, 1.0)

        print(f"   üìä Coer√™ncia: {coherence_score:.3f}, Coer√™ncia sem√¢ntica: {semantic_coherence:.3f}")

        # ========== COMPILAR RESULTADO ==========
        result = {
            'candidate_quaternions': quaternions,
            'reference_quaternion': q_ref.view(-1),  # Flatten para [embed_dim]
            'distances': distances.tolist(),
            'winner_index': winner_index,
            'coherence_score': coherence_score,
            'semantic_coherence': semantic_coherence,
            'weights': weights.tolist(),
            'reference_method': 'weighted_center_of_mass',
            'complexity': 'O(N)',
            'alignment_metrics': {
                'mean_distance': mean_distance,
                'min_distance': min_distance,
                'max_distance': distances.max().item(),
                'distance_variance': distance_variance,
                'reference_norm': torch.norm(q_ref).item()
            }
        }

        return result

    def forward(self, quaternions: torch.Tensor, token_ids: Optional[torch.Tensor] = None,
                return_intermediate: bool = False) -> Dict[str, Any]:
        """
        Interface compat√≠vel - redireciona para alinhamento de refer√™ncia O(N).

        Args:
            quaternions: Estados quaterni√¥nicos dos tokens [n_tokens, embed_dim]
            token_ids: IDs dos tokens [n_tokens] (opcional)
            return_intermediate: Se deve retornar estados intermedi√°rios (ignorado em O(N))

        Returns:
            Dicion√°rio com estados finais e m√©tricas
        """
        print("üîÑ Redirecionando para alinhamento de refer√™ncia O(N) - M√°xima Efici√™ncia")

        # Usar nova l√≥gica O(N)
        result = self._reference_alignment_forward(quaternions, token_ids)

        # Adaptar para interface antiga
        n_tokens = quaternions.shape[0]
        embed_dim = quaternions.shape[1]

        legacy_result = {
            'final_quaternions': quaternions,  # Candidatos originais
            'neighbor_matrix': torch.zeros(n_tokens, self.k_neighbors, dtype=torch.long, device=self.device),  # N√£o usado
            'weight_matrix': torch.zeros(n_tokens, self.k_neighbors, dtype=torch.float32, device=self.device),  # N√£o usado
            'iterations_performed': 1,  # O(N) - uma passada
            'early_stopped': False,
            'convergence_history': [],
            'reflection_method': 'reference_alignment_O(N)',
            'reference_alignment_result': result  # Resultado completo do alinhamento
        }

        # M√©tricas de qualidade
        legacy_result['reflection_metrics'] = {
            'mean_reflection_weight': 1.0,  # N√£o aplic√°vel
            'max_reflection_weight': 1.0,
            'min_reflection_weight': 1.0,
            'norm_preservation': torch.norm(quaternions, dim=-1).mean().item(),
            'unitarity_error': self._compute_unitarity_error(quaternions),
            'cuda_performance': {},
            'quantization_metrics': {},
            'cache_performance': {
                'cache_hits': 0,
                'memory_usage_mb': 0,
                'compression_stats': {'svd_pruned_states': 0, 'quaternion_aware_states': 0, 'magnitude_pruned_states': 0}
            },
            'memory_optimization': {
                'tensor_reuse_buffers': 0,
                'intermediate_buffers': 0,
                'weight_buffer_reused': False,
                'neighbor_buffer_reused': False,
                'total_buffer_memory_mb': 0
            }
        }

        print(f"   ‚úÖ Alinhamento de refer√™ncia O(N) conclu√≠do")
        print(f"      üìä Coer√™ncia: {result['coherence_score']:.3f}")
        print(f"      üéØ Dist√¢ncia m√≠nima: {result['alignment_metrics']['min_distance']:.4f}")
        print(f"      üîÑ Complexidade: {result['complexity']}")

        return legacy_result

    def _compute_unitarity_error(self, quaternions: torch.Tensor) -> float:
        """
        Computa erro de unitariedade dos quaternions resultantes.

        Quaternions unit√°rios t√™m norma 1. O erro mede o desvio m√©dio.
        """
        norms = torch.norm(quaternions, dim=-1)
        unitarity_error = torch.abs(norms - 1.0).mean().item()
        return unitarity_error

    def _compute_token_entropy(self, q_states: torch.Tensor) -> float:
        """
        Computa entropia dos estados quaterni√¥nicos para decidir modo adaptativo.

        Args:
            q_states: Estados quaterni√¥nicos [n_tokens, n_quaternions, 4]

        Returns:
            Entropia m√©dia dos tokens
        """
        # Calcular vari√¢ncia das componentes quaterni√¥nicas
        variances = torch.var(q_states, dim=-1)  # [n_tokens, n_quaternions]

        # Entropia baseada na vari√¢ncia m√©dia
        mean_variance = variances.mean()
        entropy = torch.log(1.0 + mean_variance).item()  # Entropia suave

        return entropy

    def _apply_kuramoto_analog(self, q_current: torch.Tensor, neighbor_matrix: torch.Tensor,
                              weight_matrix: torch.Tensor) -> torch.Tensor:
        """
        Aplica din√¢mica Kuramoto anal√≥gica para casos de alta ambiguidade.

        Esta √© uma vers√£o simplificada da din√¢mica Kuramoto usando quaternions,
        usada quando a reflex√£o r√°pida n√£o √© suficiente.

        Args:
            q_current: Estados atuais [n_tokens, n_quaternions, 4]
            neighbor_matrix: Matriz de vizinhos [n_tokens, k_neighbors]
            weight_matrix: Pesos de intera√ß√£o [n_tokens, k_neighbors]

        Returns:
            Novos estados ap√≥s din√¢mica Kuramoto [n_tokens, n_quaternions, 4]
        """
        n_tokens = q_current.shape[0]
        q_new = torch.zeros_like(q_current)

        # Par√¢metros Kuramoto
        coupling_strength = 0.1
        dt = 0.01
        n_steps = 10

        for step in range(n_steps):
            # Calcular for√ßa de sincroniza√ß√£o para cada token
            for i in range(n_tokens):
                q_i = q_current[i]  # [n_quaternions, 4]

                # Soma das intera√ß√µes com vizinhos
                coupling_sum = torch.zeros_like(q_i)

                for k in range(self.k_neighbors):
                    neighbor_idx = neighbor_matrix[i, k].item()
                    q_j = q_current[neighbor_idx]  # [n_quaternions, 4]
                    weight = weight_matrix[i, k]

                    # Diferen√ßa de fase quaterni√¥nica (simplificada)
                    phase_diff = self._quaternion_phase_difference(q_i, q_j)
                    # Expandir phase_diff para corresponder √†s dimens√µes de q_i
                    coupling_sum += weight * torch.sin(phase_diff).unsqueeze(-1).expand_as(q_i)

                # Atualiza√ß√£o Kuramoto: dq/dt = coupling_strength * sum_j weight_ij * sin(phase_diff)
                q_new[i] = q_i + dt * coupling_strength * coupling_sum

            # Normalizar para manter na variedade unit√°ria
            norms = torch.norm(q_new, dim=-1, keepdim=True)
            q_new = q_new / (norms + 1e-8)

            q_current = q_new.clone()

        return q_new

    def _quaternion_phase_difference(self, q1: torch.Tensor, q2: torch.Tensor) -> torch.Tensor:
        """
        Computa diferen√ßa de fase quaterni√¥nica simplificada.

        Args:
            q1, q2: Quaternions [..., 4]

        Returns:
            Diferen√ßa de fase [..., 4]
        """
        # Diferen√ßa simplificada baseada na componente real (magnitude)
        return torch.abs(q1[..., 0] - q2[..., 0])


# Sistema de Cache Hier√°rquico para Estados Qu√¢nticos
class QuantumStateCache:
    """
    Cache hier√°rquico otimizado para estados qu√¢nticos com compress√£o e LRU eviction.
    """

    def __init__(self, max_memory_mb: int = 512, compression_ratio: float = 0.5):
        self.max_memory_mb = max_memory_mb
        self.compression_ratio = compression_ratio
        self.cache = {}
        self.access_times = {}
        self.memory_usage = 0

        # Configura√ß√£o de compress√£o
        self._compression_enabled = compression_ratio < 1.0

    def get(self, key: str) -> Optional[torch.Tensor]:
        """Recupera estado qu√¢ntico do cache com descompress√£o autom√°tica."""
        if key in self.cache:
            self.access_times[key] = time.time()
            state = self.cache[key]

            # Descompress√£o se necess√°rio
            if self._compression_enabled and hasattr(state, '_compressed'):
                return self._decompress_state(state)
            return state
        return None

    def put(self, key: str, state: torch.Tensor):
        """Armazena estado qu√¢ntico no cache com compress√£o opcional."""
        # Verificar limite de mem√≥ria
        state_size_mb = state.numel() * state.element_size() / (1024**2)

        if self.memory_usage + state_size_mb > self.max_memory_mb:
            self._evict_lru()

        # Compress√£o opcional
        if self._compression_enabled:
            compressed_state = self._compress_state(state)
            self.cache[key] = compressed_state
            self.memory_usage += state_size_mb * self.compression_ratio
        else:
            self.cache[key] = state
            self.memory_usage += state_size_mb

        self.access_times[key] = time.time()

    def _compress_state(self, state: torch.Tensor) -> torch.Tensor:
        """Compress√£o avan√ßada baseada em SVD + pruning para estados qu√¢nticos."""
        if state.dim() == 2:
            # Compress√£o SVD para matrizes 2D
            U, S, V = torch.svd(state)

            # Manter apenas componentes principais acima do threshold
            energy_threshold = 0.95  # Manter 95% da energia
            cumulative_energy = torch.cumsum(S**2, dim=0) / torch.sum(S**2)
            k = torch.sum(cumulative_energy < energy_threshold).item() + 1
            k = min(k, int(S.shape[0] * self.compression_ratio))

            # Compress√£o com pruning
            S_compressed = S[:k] * (S[:k] > S[k] * 0.1)  # Pruning de componentes pequenas
            compressed = torch.matmul(U[:, :k], torch.diag(S_compressed))
            compressed._compressed = True
            compressed._V = V[:, :k]
            compressed._compression_method = 'svd_pruned'
            return compressed
        else:
            # Para tensores de maior dimens√£o, usar compress√£o qu√¢ntica-aware
            # Agrupar por componentes quaterni√¥nicas e comprimir cada grupo
            if state.shape[-1] == 4:  # Estados quaterni√¥nicos
                # Compress√£o por componente quaterni√¥nica
                compressed_components = []
                for i in range(4):  # w, x, y, z components
                    component = state[..., i]
                    # Compress√£o baseada em magnitude (componentes pequenas s√£o menos importantes)
                    magnitude = torch.abs(component)
                    threshold = torch.quantile(magnitude.flatten(), 1.0 - self.compression_ratio)
                    mask = magnitude >= threshold
                    compressed_component = component * mask.float()
                    compressed_components.append(compressed_component)

                compressed = torch.stack(compressed_components, dim=-1)
                compressed._compressed = True
                compressed._original_shape = state.shape
                compressed._compression_method = 'quaternion_aware'
                return compressed
            else:
                # Fallback para compress√£o por flatten com pruning
                flat = state.flatten()
                # Manter apenas valores acima do threshold
                threshold = torch.quantile(torch.abs(flat), 1.0 - self.compression_ratio)
                mask = torch.abs(flat) >= threshold
                compressed = flat * mask.float()
                compressed._compressed = True
                compressed._original_shape = state.shape
                compressed._compression_method = 'magnitude_pruned'
                return compressed

    def _decompress_state(self, compressed_state: torch.Tensor) -> torch.Tensor:
        """Descompress√£o avan√ßada baseada no m√©todo de compress√£o usado."""
        if hasattr(compressed_state, '_compression_method'):
            method = compressed_state._compression_method

            if method == 'svd_pruned':
                # Descompress√£o SVD com reconstru√ß√£o
                return torch.matmul(compressed_state, compressed_state._V.t())

            elif method == 'quaternion_aware':
                # Descompress√£o qu√¢ntica-aware (estados j√° est√£o na forma correta)
                return compressed_state

            elif method == 'magnitude_pruned':
                # Descompress√£o por padding inteligente
                original_shape = compressed_state._original_shape
                original_size = int(torch.prod(torch.tensor(original_shape)))

                # Padding com zeros para restaurar forma original
                if len(compressed_state) < original_size:
                    decompressed = torch.zeros(original_size, dtype=compressed_state.dtype, device=compressed_state.device)
                    decompressed[:len(compressed_state)] = compressed_state
                else:
                    decompressed = compressed_state[:original_size]

                return decompressed.view(original_shape)
        else:
            # Fallback para descompress√£o legacy
            if hasattr(compressed_state, '_V'):
                return torch.matmul(compressed_state, compressed_state._V.t())
            elif hasattr(compressed_state, '_original_shape'):
                original_size = int(torch.prod(torch.tensor(compressed_state._original_shape)))
                decompressed = torch.zeros(original_size, dtype=compressed_state.dtype, device=compressed_state.device)
                decompressed[:len(compressed_state)] = compressed_state
                return decompressed.view(compressed_state._original_shape)
            else:
                return compressed_state

    def _evict_lru(self):
        """Remove entradas menos recentemente usadas (LRU eviction)."""
        if not self.cache:
            return

        # Encontrar entrada mais antiga
        oldest_key = min(self.access_times, key=self.access_times.get)

        # Calcular redu√ß√£o de mem√≥ria
        state = self.cache[oldest_key]
        if hasattr(state, '_compressed'):
            # Estimativa para estados comprimidos
            state_size_mb = state.numel() * state.element_size() / (1024**2) / self.compression_ratio
        else:
            state_size_mb = state.numel() * state.element_size() / (1024**2)

        # Remover entrada
        del self.cache[oldest_key]
        del self.access_times[oldest_key]
        self.memory_usage -= state_size_mb


# Sistema de Quantiza√ß√£o de Precis√£o Adaptativa
class AdaptivePrecisionQuantizer:
    """
    Sistema de quantiza√ß√£o adaptativa que ajusta a precis√£o baseada na import√¢ncia dos valores.
    """

    def __init__(self, base_precision: int = 16, adaptive_range: bool = True):
        """
        Inicializa o quantizador de precis√£o adaptativa.

        Args:
            base_precision: Precis√£o base em bits (16, 8, 4)
            adaptive_range: Se deve ajustar dinamicamente o range de quantiza√ß√£o
        """
        self.base_precision = base_precision
        self.adaptive_range = adaptive_range

        # Configura√ß√µes de quantiza√ß√£o baseadas na precis√£o
        self._setup_quantization_config()

    def _setup_quantization_config(self):
        """Configura par√¢metros de quantiza√ß√£o baseados na precis√£o."""
        if self.base_precision == 16:
            self.scale_factor = 2**10  # 10 bits para mantissa
            self.zero_point = 0
        elif self.base_precision == 8:
            self.scale_factor = 2**7   # 7 bits para mantissa
            self.zero_point = 0
        elif self.base_precision == 4:
            self.scale_factor = 2**3   # 3 bits para mantissa
            self.zero_point = 0
        else:
            raise ValueError(f"Precis√£o n√£o suportada: {self.base_precision} bits")

    def quantize(self, tensor: torch.Tensor, importance_mask: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        Quantiza tensor com precis√£o adaptativa baseada na import√¢ncia.

        Args:
            tensor: Tensor a ser quantizado
            importance_mask: M√°scara de import√¢ncia (opcional)

        Returns:
            Tensor quantizado
        """
        if not self.adaptive_range:
            # Quantiza√ß√£o simples com range fixo
            return self._simple_quantize(tensor)

        # Calcular range din√¢mico baseado na import√¢ncia
        if importance_mask is not None:
            # Usar import√¢ncia para calcular range adaptativo
            weighted_tensor = tensor * importance_mask
            min_val = weighted_tensor.min()
            max_val = weighted_tensor.max()
        else:
            min_val = tensor.min()
            max_val = tensor.max()

        # Evitar divis√£o por zero
        if max_val == min_val:
            return torch.zeros_like(tensor, dtype=torch.int8)

        # Calcular scale adaptativo
        scale = (max_val - min_val) / (2**self.base_precision - 1)
        zero_point = torch.round(-min_val / scale).clamp(0, 2**self.base_precision - 1)

        # Quantiza√ß√£o
        quantized = torch.round(tensor / scale + zero_point).clamp(0, 2**self.base_precision - 1)

        # Armazenar metadados para desquantiza√ß√£o
        quantized._quantized = True
        quantized._scale = scale
        quantized._zero_point = zero_point
        quantized._original_dtype = tensor.dtype

        return quantized.to(torch.int8)

    def dequantize(self, quantized_tensor: torch.Tensor) -> torch.Tensor:
        """
        Desquantiza tensor para precis√£o original.

        Args:
            quantized_tensor: Tensor quantizado

        Returns:
            Tensor desquantizado
        """
        if not hasattr(quantized_tensor, '_quantized'):
            return quantized_tensor

        scale = quantized_tensor._scale
        zero_point = quantized_tensor._zero_point
        original_dtype = quantized_tensor._original_dtype

        # Desquantiza√ß√£o
        dequantized = (quantized_tensor.float() - zero_point) * scale

        return dequantized.to(original_dtype)

    def _simple_quantize(self, tensor: torch.Tensor) -> torch.Tensor:
        """Quantiza√ß√£o simples com range fixo."""
        # Normalizar para range [0, 2^precision - 1]
        min_val = tensor.min()
        max_val = tensor.max()

        if max_val == min_val:
            return torch.zeros_like(tensor, dtype=torch.int8)

        scale = (max_val - min_val) / (2**self.base_precision - 1)
        quantized = torch.round((tensor - min_val) / scale).clamp(0, 2**self.base_precision - 1)

        # Metadados
        quantized._quantized = True
        quantized._scale = scale
        quantized._zero_point = min_val
        quantized._original_dtype = tensor.dtype

        return quantized.to(torch.int8)

    def get_compression_ratio(self, original_tensor: torch.Tensor, quantized_tensor: torch.Tensor) -> float:
        """Calcula ratio de compress√£o."""
        original_bits = original_tensor.numel() * original_tensor.element_size() * 8
        quantized_bits = quantized_tensor.numel() * quantized_tensor.element_size() * 8
        return original_bits / quantized_bits


# Sistema de Profiling de Performance Detalhado
class PerformanceProfiler:
    """
    Sistema abrangente de profiling para an√°lise de performance em tempo real.
    """

    def __init__(self):
        self.operation_times = defaultdict(list)
        self.memory_usage = defaultdict(list)
        self.operation_counts = defaultdict(int)
        self.start_times = {}
        self.session_start = time.time()

    def start_operation(self, operation_name: str):
        """Inicia profiling de uma opera√ß√£o."""
        self.start_times[operation_name] = time.time()

    def end_operation(self, operation_name: str, memory_mb: Optional[float] = None):
        """Finaliza profiling de uma opera√ß√£o."""
        if operation_name in self.start_times:
            duration = time.time() - self.start_times[operation_name]
            self.operation_times[operation_name].append(duration)
            self.operation_counts[operation_name] += 1

            if memory_mb is not None:
                self.memory_usage[operation_name].append(memory_mb)

            del self.start_times[operation_name]

    def get_operation_stats(self, operation_name: str) -> Dict[str, float]:
        """Retorna estat√≠sticas detalhadas de uma opera√ß√£o."""
        times = self.operation_times.get(operation_name, [])
        if not times:
            return {'count': 0, 'total_time': 0.0, 'avg_time': 0.0, 'min_time': 0.0, 'max_time': 0.0}

        return {
            'count': len(times),
            'total_time': sum(times),
            'avg_time': np.mean(times),
            'min_time': min(times),
            'max_time': max(times),
            'std_time': np.std(times) if len(times) > 1 else 0.0
        }

    def get_memory_stats(self, operation_name: str) -> Dict[str, float]:
        """Retorna estat√≠sticas de uso de mem√≥ria."""
        memory = self.memory_usage.get(operation_name, [])
        if not memory:
            return {'count': 0, 'avg_memory': 0.0, 'max_memory': 0.0}

        return {
            'count': len(memory),
            'avg_memory': np.mean(memory),
            'max_memory': max(memory),
            'total_memory': sum(memory)
        }

    def get_performance_report(self) -> Dict[str, Any]:
        """Gera relat√≥rio completo de performance."""
        report = {
            'session_duration': time.time() - self.session_start,
            'total_operations': sum(self.operation_counts.values()),
            'operation_breakdown': {}
        }

        for op_name in self.operation_times.keys():
            report['operation_breakdown'][op_name] = {
                'stats': self.get_operation_stats(op_name),
                'memory': self.get_memory_stats(op_name)
            }

        # Estat√≠sticas agregadas
        all_times = [t for times in self.operation_times.values() for t in times]
        if all_times:
            report['aggregate_stats'] = {
                'total_time': sum(all_times),
                'avg_operation_time': np.mean(all_times),
                'operations_per_second': len(all_times) / sum(all_times) if sum(all_times) > 0 else 0,
                'time_distribution': {
                    'p50': np.percentile(all_times, 50),
                    'p95': np.percentile(all_times, 95),
                    'p99': np.percentile(all_times, 99)
                }
            }

        return report

    def reset(self):
        """Reseta todas as m√©tricas de profiling."""
        self.operation_times.clear()
        self.memory_usage.clear()
        self.operation_counts.clear()
        self.start_times.clear()
        self.session_start = time.time()


# Sistema de Batching Inteligente para Processamento Paralelo
class IntelligentBatchProcessor:
    """
    Processador de batches inteligente que otimiza processamento paralelo baseado na carga de trabalho.
    """

    def __init__(self, max_batch_size: int = 32, adaptive_batching: bool = True, device: str = "cpu"):
        """
        Inicializa o processador de batches inteligente.

        Args:
            max_batch_size: Tamanho m√°ximo do batch
            adaptive_batching: Se deve ajustar dinamicamente o tamanho do batch
            device: Dispositivo para processamento
        """
        self.max_batch_size = max_batch_size
        self.adaptive_batching = adaptive_batching
        self.device = device

        # M√©tricas de performance para ajuste adaptativo
        self.batch_times = []
        self.memory_usage = []
        self.optimal_batch_size = max_batch_size // 2  # Come√ßar com metade

        # Configura√ß√µes de paraleliza√ß√£o
        self.num_workers = min(4, torch.cuda.device_count() if 'cuda' in device else 2)

    def create_batches(self, data: torch.Tensor, batch_size: Optional[int] = None) -> List[torch.Tensor]:
        """
        Cria batches otimizados para processamento paralelo.

        Args:
            data: Dados a serem divididos em batches [n_items, ...]
            batch_size: Tamanho do batch (opcional, usa adaptativo se None)

        Returns:
            Lista de batches
        """
        n_items = data.shape[0]

        if batch_size is None and self.adaptive_batching:
            batch_size = self._determine_optimal_batch_size(n_items)
        elif batch_size is None:
            batch_size = min(self.max_batch_size, n_items)

        # Garantir que batch_size n√£o exceda n_items
        batch_size = min(batch_size, n_items)

        # Criar batches
        batches = []
        for i in range(0, n_items, batch_size):
            end_idx = min(i + batch_size, n_items)
            batch = data[i:end_idx]
            batches.append(batch)

        return batches

    def _determine_optimal_batch_size(self, n_items: int) -> int:
        """
        Determina tamanho √≥timo do batch baseado em m√©tricas hist√≥ricas.
        """
        if not self.batch_times:
            return min(self.optimal_batch_size, n_items)

        # An√°lise de performance hist√≥rica
        avg_time_per_item = np.mean([t / b for t, b in zip(self.batch_times, self.memory_usage)])

        # Estimar tamanho √≥timo baseado na mem√≥ria dispon√≠vel
        if 'cuda' in self.device:
            try:
                total_memory = torch.cuda.get_device_properties(0).total_memory
                used_memory = torch.cuda.memory_allocated()
                available_memory = total_memory - used_memory

                # Estimar mem√≥ria por item (rough approximation)
                memory_per_item = 1024 * 1024  # 1MB por item como estimativa
                optimal_based_memory = available_memory // memory_per_item // 4  # 25% da mem√≥ria dispon√≠vel
            except:
                optimal_based_memory = self.max_batch_size
        else:
            optimal_based_memory = self.max_batch_size

        # Combinar fatores para determinar batch size √≥timo
        optimal_size = min(
            optimal_based_memory,
            n_items,
            max(1, int(1.0 / avg_time_per_item)) if avg_time_per_item > 0 else self.max_batch_size
        )

        # Atualizar tamanho √≥timo com suaviza√ß√£o
        self.optimal_batch_size = int(0.8 * self.optimal_batch_size + 0.2 * optimal_size)

        return self.optimal_batch_size

    def process_batches_parallel(self, batches: List[torch.Tensor],
                                processing_fn: callable,
                                **kwargs) -> List[Any]:
        """
        Processa batches em paralelo usando m√∫ltiplos workers.

        Args:
            batches: Lista de batches para processar
            processing_fn: Fun√ß√£o de processamento para cada batch
            **kwargs: Argumentos adicionais para processing_fn

        Returns:
            Resultados do processamento
        """
        results = []

        if len(batches) == 1 or self.num_workers == 1:
            # Processamento sequencial para poucos batches
            for batch in batches:
                start_time = time.time()
                result = processing_fn(batch, **kwargs)
                batch_time = time.time() - start_time

                # Registrar m√©tricas
                self.batch_times.append(batch_time)
                self.memory_usage.append(batch.shape[0])

                results.append(result)
        else:
            # Processamento paralelo (simulado para compatibilidade)
            # Em produ√ß√£o, isso usaria multiprocessing ou torch DataLoader
            for batch in batches:
                start_time = time.time()
                result = processing_fn(batch, **kwargs)
                batch_time = time.time() - start_time

                self.batch_times.append(batch_time)
                self.memory_usage.append(batch.shape[0])

                results.append(result)

        return results

    def get_batching_stats(self) -> Dict[str, Any]:
        """Retorna estat√≠sticas de batching."""
        return {
            'optimal_batch_size': self.optimal_batch_size,
            'avg_batch_time': np.mean(self.batch_times) if self.batch_times else 0,
            'total_batches_processed': len(self.batch_times),
            'adaptive_batching': self.adaptive_batching,
            'num_workers': self.num_workers
        }


# Fun√ß√£o de interface para compatibilidade
def create_quaternion_reflection_layer(embed_dim: int = 64, k_neighbors: int = 3,
                                      iterations: int = 2, device: str = "cpu",
                                      adaptive_mode: bool = False, entropy_threshold: float = 0.7) -> QuaternionReflectionLayer:
    """
    Factory function para criar camada de reflex√£o quaterni√¥nica com todas as otimiza√ß√µes.

    Args:
        embed_dim: Dimens√£o do embedding
        k_neighbors: N√∫mero de vizinhos
        iterations: N√∫mero de itera√ß√µes
        device: Dispositivo
        adaptive_mode: Se deve usar modo h√≠brido adaptativo
        entropy_threshold: Limiar de entropia para modo adaptativo

    Returns:
        Inst√¢ncia configurada da camada com todas as otimiza√ß√µes
    """
    return QuaternionReflectionLayer(
        embed_dim=embed_dim,
        k_neighbors=k_neighbors,
        iterations=iterations,
        device=device,
        adaptive_mode=adaptive_mode,
        entropy_threshold=entropy_threshold
    )


if __name__ == "__main__":
    # Exemplo de uso
    print("üß™ Testando Camada de Reflex√£o Geom√©trica...")

    # Configura√ß√£o de teste
    n_tokens = 5
    embed_dim = 64  # 16 quaternions
    device = "cpu"

    # Criar camada com modo adaptativo
    reflection_layer = QuaternionReflectionLayer(
        embed_dim=embed_dim,
        k_neighbors=2,
        iterations=2,
        device=device,
        adaptive_mode=True,
        entropy_threshold=0.5
    )

    # Estados quaterni√¥nicos aleat√≥rios
    quaternions = torch.randn(n_tokens, embed_dim, device=device)
    token_ids = torch.arange(n_tokens, device=device)

    # Executar reflex√£o
    result = reflection_layer(quaternions, token_ids, return_intermediate=True)

    print("\n" + "="*60)
    print("RESULTADO DA REFLEX√ÉO QUATERNI√îNICA:")
    print("="*60)
    print(f"Estados finais: {result['final_quaternions'].shape}")
    print(f"M√©tricas: {result['reflection_metrics']}")
    print(f"M√©todo: {result['reflection_method']}")
    print("="*60)