#!/usr/bin/env python3
"""
Acoplamento Harm√¥nico entre Camadas Œ®QRH
========================================

Implementa sincroniza√ß√£o harm√¥nica entre:
1. Self-Attention (dom√≠nio espectral)
2. Kuramoto Spectral Neurons (osciladores acoplados)
3. Conscious Working Memory (mem√≥ria persistente)
4. Feed-Forward Network (transforma√ß√£o n√£o-linear)

Mathematical Framework:
----------------------
Acoplamento Harm√¥nico:
    H(x‚ÇÅ, x‚ÇÇ, ..., x‚Çô) = ‚àë·µ¢ w·µ¢¬∑x·µ¢ + K¬∑‚àë·µ¢‚±º sin(œÜ‚±º - œÜ·µ¢)

Sincroniza√ß√£o de Fase Global:
    r_global = |1/N ‚àë‚Çô e^{iœÜ‚Çô}|

Conserva√ß√£o de Energia Coletiva:
    ||H(x)||¬≤ ‚âà ‚àë·µ¢ ||x·µ¢||¬≤

Copyright (C) 2025 Klenio Araujo Padilha
Licensed under GNU GPLv3
"""

import torch
import torch.nn as nn
import numpy as np
import yaml
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass


def load_harmonic_config(config_path: Optional[str] = None, preset: str = 'standard') -> Dict:
    """
    Carrega configura√ß√£o de acoplamento harm√¥nico do arquivo YAML.

    Args:
        config_path: Caminho para arquivo de config (opcional)
        preset: Preset a usar ('standard', 'strong', 'weak', 'adaptive')

    Returns:
        Dict com configura√ß√£o completa
    """
    if config_path is None:
        # Usar caminho padr√£o
        project_root = Path(__file__).parent.parent.parent
        config_path = project_root / 'configs' / 'harmonic_coupling_config.yaml'

    with open(config_path, 'r', encoding='utf-8') as f:
        full_config = yaml.safe_load(f)

    # Pegar configura√ß√£o base
    config = full_config['harmonic_coupling'].copy()

    # Aplicar preset se especificado
    if preset and preset in full_config.get('presets', {}):
        preset_config = full_config['presets'][preset]
        # Merge recursivo
        def merge_dicts(base, override):
            result = base.copy()
            for key, value in override.items():
                if key in result and isinstance(result[key], dict) and isinstance(value, dict):
                    result[key] = merge_dicts(result[key], value)
                else:
                    result[key] = value
            return result

        config = merge_dicts(config, preset_config)

    return config


@dataclass
class LayerState:
    """Estado de uma camada no sistema acoplado"""
    output: torch.Tensor
    phase: torch.Tensor
    frequency: float
    energy: float
    name: str


class HarmonicLayerCoupling(nn.Module):
    """
    M√≥dulo de acoplamento harm√¥nico entre camadas Œ®QRH.
    Sincroniza fases e frequ√™ncias para processamento coerente.
    """

    def __init__(
        self,
        embed_dim: int = 256,
        n_layers: int = 4,
        config: Optional[Dict] = None,
        config_path: Optional[str] = None,
        preset: str = 'standard',
        device: str = 'cpu'
    ):
        super().__init__()

        # Carregar configura√ß√£o
        if config is None:
            config = load_harmonic_config(config_path, preset)

        self.config = config
        self.embed_dim = embed_dim
        self.n_layers = n_layers
        self.K = config['coupling_strength']
        self.omega_target = config['target_frequency']
        self.device = device

        # Pesos adaptativos para cada camada
        adaptive_weights = config['layer_weights']['adaptive']
        if adaptive_weights:
            self.layer_weights = nn.Parameter(torch.ones(n_layers) / n_layers)
        else:
            # Usar pesos fixos do config
            initial_weights = list(config['layer_weights']['initial_weights'].values())[:n_layers]
            self.layer_weights = nn.Parameter(torch.tensor(initial_weights), requires_grad=False)

        # Frequ√™ncias naturais de cada camada
        freq_range = config['natural_frequencies']['frequency_range']
        self.natural_frequencies = nn.Parameter(
            torch.linspace(freq_range[0], freq_range[1], n_layers)
        )

        # Hist√≥rico de sincroniza√ß√£o
        history_size = config['tracking']['history_size']
        self.register_buffer('sync_history', torch.zeros(history_size, device=device))
        self.history_idx = 0

        # Estado interno para tracking
        self.layer_states: List[LayerState] = []

    def extract_phase(self, x: torch.Tensor) -> torch.Tensor:
        """
        Extrai fase complexa de um tensor.

        Args:
            x: Tensor [batch, seq, features]

        Returns:
            phases: Fases [batch, features]
        """
        # Colapsar sequ√™ncia tomando a m√©dia
        x_collapsed = x.mean(dim=1)  # [batch, features]

        # Converter para complexo via FFT
        x_fft = torch.fft.fft(x_collapsed, dim=-1)

        # Extrair fase
        phases = torch.angle(x_fft)

        return phases

    def compute_global_synchronization(
        self,
        phases_list: List[torch.Tensor]
    ) -> torch.Tensor:
        """
        Computa ordem de sincroniza√ß√£o global entre todas as camadas.

        Args:
            phases_list: Lista de fases [batch, features] para cada camada

        Returns:
            r_global: Ordem de sincroniza√ß√£o [0, 1]
        """
        # Stack todas as fases
        all_phases = torch.stack(phases_list, dim=1)  # [batch, n_layers, features]

        # Converter para complexo
        complex_phases = torch.exp(1j * all_phases)

        # M√©dia sobre camadas e features
        mean_phase = complex_phases.mean(dim=(1, 2))  # [batch]

        # Magnitude = ordem de sincroniza√ß√£o
        r_global = torch.abs(mean_phase).mean()

        return r_global

    def apply_phase_coupling(
        self,
        outputs: List[torch.Tensor],
        phases: List[torch.Tensor]
    ) -> List[torch.Tensor]:
        """
        Aplica acoplamento de fase entre camadas via termo de Kuramoto.

        Args:
            outputs: Lista de outputs de cada camada
            phases: Lista de fases de cada camada

        Returns:
            coupled_outputs: Outputs acoplados harmonicamente
        """
        coupled_outputs = []

        for i, (output_i, phase_i) in enumerate(zip(outputs, phases)):
            # Termo de acoplamento: K¬∑‚àë‚±º sin(œÜ‚±º - œÜ·µ¢)
            coupling_term = torch.zeros_like(output_i)

            for j, phase_j in enumerate(phases):
                if i != j:
                    # Diferen√ßa de fase
                    phase_diff = phase_j - phase_i  # [batch, features]

                    # Termo de sincroniza√ß√£o
                    sync_term = torch.sin(phase_diff)  # [batch, features]

                    # Expandir para dimens√µes completas
                    sync_term_expanded = sync_term.unsqueeze(1).expand_as(output_i)

                    # Acumular acoplamento
                    coupling_term += self.K * sync_term_expanded / (self.n_layers - 1)

            # Output acoplado
            coupled_output = output_i + coupling_term
            coupled_outputs.append(coupled_output)

        return coupled_outputs

    def apply_frequency_alignment(
        self,
        outputs: List[torch.Tensor]
    ) -> List[torch.Tensor]:
        """
        Alinha frequ√™ncias naturais de cada camada √† frequ√™ncia alvo.

        Args:
            outputs: Lista de outputs de cada camada

        Returns:
            aligned_outputs: Outputs com frequ√™ncias alinhadas
        """
        aligned_outputs = []

        for i, output in enumerate(outputs):
            # Frequ√™ncia natural da camada
            omega_i = self.natural_frequencies[i]

            # Fator de ajuste para frequ√™ncia alvo
            freq_adjustment = self.omega_target / (omega_i + 1e-6)

            # Aplicar modula√ß√£o de frequ√™ncia
            # No dom√≠nio do tempo, isso equivale a dilatar/contrair temporalmente
            # Aqui, aproximamos multiplicando por fator
            aligned_output = output * freq_adjustment

            aligned_outputs.append(aligned_output)

        return aligned_outputs

    def weighted_combination(
        self,
        outputs: List[torch.Tensor],
        preserve_energy: bool = True
    ) -> torch.Tensor:
        """
        Combina outputs de todas as camadas com pesos adaptativos.

        Args:
            outputs: Lista de outputs de cada camada
            preserve_energy: Se True, normaliza para conservar energia

        Returns:
            combined: Output combinado
        """
        # Normalizar pesos
        weights = torch.softmax(self.layer_weights, dim=0)

        # Combinar com pesos
        combined = torch.zeros_like(outputs[0])
        for i, output in enumerate(outputs):
            combined += weights[i] * output

        # Conservar energia se solicitado
        if preserve_energy:
            # Calcular energia m√©dia das entradas
            input_energies = [torch.norm(out) for out in outputs]
            mean_input_energy = torch.stack(input_energies).mean()

            # Energia do output combinado
            output_energy = torch.norm(combined)

            # Normalizar para conservar energia
            if output_energy > 1e-8:
                energy_scale = mean_input_energy / output_energy
                combined = combined * energy_scale

        return combined

    def forward(
        self,
        layer_outputs: Dict[str, torch.Tensor],
        layer_names: Optional[List[str]] = None,
        input_reference: Optional[torch.Tensor] = None
    ) -> Tuple[torch.Tensor, Dict]:
        """
        Forward pass com acoplamento harm√¥nico.

        Args:
            layer_outputs: Dict com outputs de cada camada
                          {'attention': tensor, 'kuramoto': tensor, ...}
            layer_names: Lista ordenada de nomes das camadas
            input_reference: Tensor de entrada original para c√°lculo de energia

        Returns:
            harmonized_output: Output harmonizado
            metrics: M√©tricas de sincroniza√ß√£o
        """
        if layer_names is None:
            layer_names = list(layer_outputs.keys())

        # Coletar outputs na ordem especificada
        outputs = [layer_outputs[name] for name in layer_names]

        # Verificar que todos os outputs t√™m mesma shape
        ref_shape = outputs[0].shape
        for i, output in enumerate(outputs):
            if output.shape != ref_shape:
                # Ajustar shape se necess√°rio
                if output.size(-1) != ref_shape[-1]:
                    # Usar pooling ou padding adaptativo
                    if output.size(-1) > ref_shape[-1]:
                        outputs[i] = output[..., :ref_shape[-1]]
                    else:
                        pad_size = ref_shape[-1] - output.size(-1)
                        outputs[i] = torch.nn.functional.pad(output, (0, pad_size))

        # 1. Extrair fases de cada camada
        phases = [self.extract_phase(output) for output in outputs]

        # 2. Computar sincroniza√ß√£o global
        r_global = self.compute_global_synchronization(phases)

        # Atualizar hist√≥rico
        self.sync_history[self.history_idx % 100] = r_global
        self.history_idx += 1

        # 3. Aplicar acoplamento de fase
        coupled_outputs = self.apply_phase_coupling(outputs, phases)

        # 4. Alinhar frequ√™ncias
        aligned_outputs = self.apply_frequency_alignment(coupled_outputs)

        # 5. Combinar com pesos adaptativos
        harmonized_output = self.weighted_combination(aligned_outputs)

        # 6. Computar energias
        energies = [torch.norm(output).item() for output in outputs]
        total_energy_in = sum(energies)
        total_energy_out = torch.norm(harmonized_output).item()
        energy_ratio = total_energy_out / (total_energy_in + 1e-8)

        # 7. Aplicar normaliza√ß√£o de energia se necess√°rio
        if energy_ratio < 0.5 or energy_ratio > 2.0:
            scale = torch.sqrt(torch.tensor(total_energy_in / (total_energy_out + 1e-8)))
            harmonized_output = harmonized_output * scale
            total_energy_out = torch.norm(harmonized_output).item()
            energy_ratio = total_energy_out / (total_energy_in + 1e-8)

        # Salvar estados para an√°lise
        self.layer_states = [
            LayerState(
                output=outputs[i],
                phase=phases[i],
                frequency=self.natural_frequencies[i].item(),
                energy=energies[i],
                name=layer_names[i]
            )
            for i in range(len(outputs))
        ]

        # M√©tricas
        metrics = {
            'global_synchronization': r_global.item(),
            'layer_weights': self.layer_weights.detach().cpu().tolist(),
            'natural_frequencies': self.natural_frequencies.detach().cpu().tolist(),
            'energies': energies,
            'energy_ratio': energy_ratio,
            'is_synchronized': r_global.item() > 0.7,
            'sync_history': self.sync_history[:min(self.history_idx, 100)].cpu().tolist()
        }

        return harmonized_output, metrics


class AdaptiveHarmonicGate(nn.Module):
    """
    Gate adaptativo para controlar contribui√ß√£o de cada camada
    baseado em sincroniza√ß√£o harm√¥nica.
    """

    def __init__(self, n_layers: int = 4):
        super().__init__()
        self.n_layers = n_layers

        # Gates aprend√≠veis
        self.gates = nn.Parameter(torch.ones(n_layers))

    def forward(
        self,
        outputs: List[torch.Tensor],
        sync_order: float
    ) -> List[torch.Tensor]:
        """
        Aplica gating baseado em sincroniza√ß√£o.

        Args:
            outputs: Lista de outputs das camadas
            sync_order: Ordem de sincroniza√ß√£o r ‚àà [0, 1]

        Returns:
            gated_outputs: Outputs com gating aplicado
        """
        # Gate baseado em sincroniza√ß√£o
        # Se sincroniza√ß√£o alta ‚Üí gates abertos
        # Se sincroniza√ß√£o baixa ‚Üí gates mais fechados
        sync_factor = torch.sigmoid(torch.tensor(sync_order * 5 - 2.5))

        # Aplicar gates
        gates_normalized = torch.sigmoid(self.gates)
        gated_outputs = []

        for i, output in enumerate(outputs):
            gate_value = gates_normalized[i] * sync_factor
            gated_output = output * gate_value
            gated_outputs.append(gated_output)

        return gated_outputs


def create_harmonic_coupling(
    embed_dim: int = 256,
    n_layers: int = 4,
    config: Optional[Dict] = None,
    config_path: Optional[str] = None,
    preset: str = 'standard',
    device: str = 'cpu'
) -> HarmonicLayerCoupling:
    """Factory function para criar m√≥dulo de acoplamento harm√¥nico"""
    return HarmonicLayerCoupling(
        embed_dim=embed_dim,
        n_layers=n_layers,
        config=config,
        config_path=config_path,
        preset=preset,
        device=device
    )


# ============================================================================
# FUN√á√ïES AUXILIARES
# ============================================================================

def visualize_harmonic_coupling(
    coupling_module: HarmonicLayerCoupling,
    save_path: Optional[str] = None
):
    """
    Visualiza estado do acoplamento harm√¥nico entre camadas.

    Args:
        coupling_module: M√≥dulo de acoplamento
        save_path: Caminho para salvar visualiza√ß√£o
    """
    import matplotlib.pyplot as plt

    if not coupling_module.layer_states:
        print("‚ö†Ô∏è  Nenhum estado salvo para visualizar")
        return

    n_layers = len(coupling_module.layer_states)

    fig, axes = plt.subplots(2, 2, figsize=(14, 10))

    # 1. Frequ√™ncias naturais
    ax = axes[0, 0]
    freqs = [state.frequency for state in coupling_module.layer_states]
    names = [state.name for state in coupling_module.layer_states]
    ax.bar(names, freqs, color='steelblue', alpha=0.7)
    ax.axhline(y=coupling_module.omega_target, color='red', linestyle='--',
               label=f'Target: {coupling_module.omega_target:.2f}')
    ax.set_ylabel('Frequ√™ncia Natural')
    ax.set_title('Frequ√™ncias das Camadas')
    ax.legend()
    ax.grid(True, alpha=0.3)

    # 2. Energias
    ax = axes[0, 1]
    energies = [state.energy for state in coupling_module.layer_states]
    ax.bar(names, energies, color='coral', alpha=0.7)
    ax.set_ylabel('Energia (norma L2)')
    ax.set_title('Energias das Camadas')
    ax.grid(True, alpha=0.3)

    # 3. Hist√≥rico de sincroniza√ß√£o
    ax = axes[1, 0]
    history = coupling_module.sync_history[:coupling_module.history_idx].cpu().numpy()
    ax.plot(history, color='green', linewidth=2)
    ax.axhline(y=0.7, color='red', linestyle='--', label='Threshold: 0.7')
    ax.set_xlabel('Itera√ß√£o')
    ax.set_ylabel('Ordem de Sincroniza√ß√£o r')
    ax.set_title('Evolu√ß√£o da Sincroniza√ß√£o Global')
    ax.set_ylim([0, 1])
    ax.legend()
    ax.grid(True, alpha=0.3)

    # 4. Pesos das camadas
    ax = axes[1, 1]
    weights = torch.softmax(coupling_module.layer_weights, dim=0).detach().cpu().numpy()
    colors = plt.cm.viridis(np.linspace(0, 1, n_layers))
    ax.pie(weights, labels=names, autopct='%1.1f%%', colors=colors, startangle=90)
    ax.set_title('Contribui√ß√£o Relativa das Camadas')

    plt.tight_layout()

    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"üìä Visualiza√ß√£o salva em: {save_path}")
    else:
        plt.show()

    plt.close()
