"""
Efficient Quantum Decoder - Œ®QRH Architecture
==============================================

Implementa√ß√£o espec√≠fica para decodifica√ß√£o qu√¢ntica baseada na arquitetura real do Œ®QRH.
Resolve o problema de gibberish atrav√©s de invers√£o matem√°tica direta da transformada de Padilha.

Copyright (C) 2025 Klenio Araujo Padilha
Licensed under GNU GPLv3
"""

import torch
import torch.nn as nn
import math
from typing import Tuple, Optional, List
import numpy as np

class EfficientQuantumDecoder:
    """
    Decoder eficiente baseado na arquitetura Œ®QRH real.

    Implementa invers√£o matem√°tica direta da transformada qu√¢ntica,
    eliminando m√©tricas de similaridade complexas que causam gibberish.
    """

    def __init__(self, vocab_size=195, seq_length=64, embed_dim=64, device='cpu', verbose=True):
        """
        Inicializa decoder com par√¢metros do Œ®QRH.

        Args:
            vocab_size: Tamanho do vocabul√°rio (195 tokens do GPT-2 spectral)
            seq_length: Comprimento da sequ√™ncia (64)
            embed_dim: Dimens√£o do embedding (64)
            device: Dispositivo para processamento
            verbose: Se deve imprimir logs detalhados
        """
        self.vocab_size = vocab_size
        self.seq_length = seq_length
        self.embed_dim = embed_dim
        self.device = device
        self.verbose = verbose

        # Carregar vocabul√°rio espec√≠fico do Œ®QRH
        self.vocab = self._load_psiqrh_vocab()

        # Par√¢metros f√≠sicos baseados na equa√ß√£o de Padilha
        self.I0 = 1.0      # Amplitude m√°xima
        self.omega = 2.0 * math.pi  # Frequ√™ncia angular
        self.k = 2.0 * math.pi      # N√∫mero de onda

        # Camada de proje√ß√£o para mapear estado qu√¢ntico para vocabul√°rio
        self.projection = nn.Linear(embed_dim * 4, vocab_size, bias=False).to(device)

        # Conjunto pr√©-computado de tokens significativos para valida√ß√£o eficiente
        self.significant_tokens = set(range(3, 95))  # tokens 3-94 s√£o significativos

        self._log(f"üîß EfficientQuantumDecoder initialized: vocab_size={vocab_size}, seq_length={seq_length}, embed_dim={embed_dim}")

        # Para produ√ß√£o: inicializar pesos com matriz qu√¢ntica
        # decoder.set_projection_weights(quantum_matrix.quantum_matrix.reshape(195, -1))

    def _log(self, message: str):
        """Logging configur√°vel para produ√ß√£o"""
        if self.verbose:
            print(message)

    def initialize_with_quantum_matrix(self, quantum_matrix_instance):
        """Inicializa decoder com pesos da matriz qu√¢ntica real"""
        embedding_matrix = quantum_matrix_instance.quantum_matrix.reshape(self.vocab_size, -1)
        self.set_projection_weights(embedding_matrix)
        self._log("üîó Decoder weights initialized from quantum matrix")

    def set_projection_weights(self, embedding_matrix: torch.Tensor):
        """
        Alinha decoder com encoder usando pesos compartilhados (weight tying).
        embedding_matrix: [vocab_size, embed_dim*4]
        """
        with torch.no_grad():
            self.projection.weight.copy_(embedding_matrix.T)

    def _load_psiqrh_vocab(self) -> dict:
        """Carrega vocabul√°rio espec√≠fico do Œ®QRH (195 tokens do GPT-2 spectral)"""
        # Baseado no vocabul√°rio real do projeto Œ®QRH
        vocab = {}

        # Tokens especiais (0-2)
        vocab[0] = "<pad>"
        vocab[1] = "<unk>"
        vocab[2] = "<eos>"

        # Tokens de pontua√ß√£o e s√≠mbolos comuns (3-32)
        punctuation = [' ', '.', ',', '!', '?', ';', ':', '-', '(', ')', '[', ']', '{', '}', '"', "'",
                      '+', '=', '*', '/', '\\', '|', '@', '#', '$', '%', '^', '&', '<', '>']

        for i, char in enumerate(punctuation, 3):
            vocab[i] = char

        # N√∫meros (33-42)
        for i in range(10):
            vocab[33 + i] = str(i)

        # Letras mai√∫sculas (43-68)
        for i, char in enumerate('ABCDEFGHIJKLMNOPQRSTUVWXYZ', 43):
            vocab[i] = char

        # Letras min√∫sculas (69-94)
        for i, char in enumerate('abcdefghijklmnopqrstuvwxyz', 69):
            vocab[i] = char

        # Tokens especiais adicionais para completar 195
        for i in range(95, 195):
            vocab[i] = f"<special_{i}>"

        return vocab

    def inverse_decode(self, quantum_state: torch.Tensor) -> torch.Tensor:
        """
        Decodifica√ß√£o inversa baseada na f√≠sica do Œ®QRH.

        Args:
            quantum_state: torch.Size([1, 64, 64, 4]) - sa√≠da do optical_probe

        Returns:
            tokens: torch.Tensor - √≠ndices de tokens do vocabul√°rio
        """
        # Valida√ß√£o rigorosa de shape para produ√ß√£o
        expected_shape = (1, self.seq_length, self.embed_dim, 4)
        assert quantum_state.shape == expected_shape, \
            f"Expected shape {expected_shape}, got {quantum_state.shape}"

        self._log(f"üîÑ [EfficientQuantumDecoder] Starting inverse decode: shape={quantum_state.shape}")

        # 1. INVERSA DA SONDA √ìPTICA (Padilha Wave Equation)
        optical_inverse = self._inverse_optical_probe(quantum_state)

        # 2. INVERSA DA ROTA√á√ÉO SO(4)
        rotation_inverse = self._inverse_so4_rotation(optical_inverse)

        # 3. INVERSA DA FILTRAGEM ESPECTRAL
        spectral_inverse = self._inverse_spectral_filter(rotation_inverse)

        # 4. DECODIFICA√á√ÉO DIRETA PARA VOCABUL√ÅRIO GPT-2 (195 tokens)
        tokens = self._quantum_to_token_mapping(spectral_inverse)

        self._log(f"‚úÖ [EfficientQuantumDecoder] Inverse decode complete: {len(tokens)} tokens")
        return tokens

    def _inverse_optical_probe(self, quantum_state: torch.Tensor) -> torch.Tensor:
        """
        Inversa matem√°tica da sonda √≥ptica de Padilha.

        Original: f(Œª,t) = I‚ÇÄ sin(œât + Œ±Œª) e^(i(œât - kŒª + Œ≤Œª¬≤))
        Inversa: f‚Åª¬π(œà) = œà ¬∑ exp(-i(œât - kŒª + Œ≤Œª¬≤)) / I‚ÇÄ sin(œât + Œ±Œª)
        """
        self._log("üåä [EfficientQuantumDecoder] Applying inverse optical probe...")

        batch, seq, embed, quat = quantum_state.shape

        # Decompor estado qu√¢ntico em componentes
        real_part = quantum_state[..., 0]  # componente real
        imag_part = quantum_state[..., 1:] # componentes imagin√°rios quaterni√¥nicos

        # Calcular √¢ngulo e magnitude para invers√£o
        time_component = torch.angle(quantum_state.mean(dim=-1, keepdim=True))  # √¢ngulo m√©dio
        spatial_component = torch.abs(quantum_state).mean(dim=-1, keepdim=True)  # magnitude m√©dia

        # Par√¢metros da invers√£o (baseados nos par√¢metros do pipeline)
        alpha = 1.36  # valor calibrado
        beta = 0.725  # valor calibrado

        # Aplicar inversa da modula√ß√£o temporal: exp(-i(œât - kŒª + Œ≤Œª¬≤))
        # Simplifica√ß√£o: usar √¢ngulo do estado qu√¢ntico
        inverse_time = torch.exp(-1j * time_component * beta)

        # Aplicar inversa da modula√ß√£o espacial: 1 / (I‚ÇÄ sin(œât + Œ±Œª))
        # Usar suaviza√ß√£o est√°vel para evitar instabilidade num√©rica
        spatial_modulation = torch.sin(time_component + alpha * torch.arange(seq, device=self.device).unsqueeze(0).unsqueeze(-1).unsqueeze(-1))
        epsilon = 1e-3
        denominator = self.I0 * spatial_modulation
        inverse_spatial = denominator / (denominator**2 + epsilon**2)  # Vers√£o est√°vel

        # Aplicar invers√£o completa
        inverted_state = quantum_state * inverse_time * inverse_spatial

        self._log(f"   ‚úÖ Inverse optical probe applied: shape={inverted_state.shape}")
        return inverted_state

    def _inverse_so4_rotation(self, optical_inverse: torch.Tensor) -> torch.Tensor:
        """
        Inversa da rota√ß√£o SO(4) unit√°ria.

        Como as rota√ß√µes SO(4) s√£o unit√°rias, a inversa √© a transposta/conjugada.
        """
        self._log("üîÑ [EfficientQuantumDecoder] Applying inverse SO(4) rotation...")

        # Para rota√ß√µes unit√°rias, a inversa √© a transposta do conjugado
        # Simplifica√ß√£o: como estamos trabalhando com quaternions, aplicamos conjugado
        rotation_inverse = torch.conj(optical_inverse)

        self._log(f"   ‚úÖ Inverse SO(4) rotation applied: shape={rotation_inverse.shape}")
        return rotation_inverse

    def _inverse_spectral_filter(self, rotation_inverse: torch.Tensor) -> torch.Tensor:
        """
        Inversa da filtragem espectral F(k) = exp(i Œ± ¬∑ arctan(ln(|k| + Œµ)))
        Garante que a FFT foi aplicada na mesma dimens√£o e sinal est√° centrado.
        """
        self._log("üéº [EfficientQuantumDecoder] Applying inverse spectral filter...")

        # Aplicar transformada de Fourier inversa na dimens√£o correta (embed_dim)
        # Assumindo que a FFT original foi aplicada em dim=-2 (embed_dim)
        spectral_inverse = torch.fft.ifft(rotation_inverse, dim=-2)

        # Garantir centering correto (FFT assume periodicidade)
        # Shift para centralizar frequ√™ncias zero
        spectral_inverse = torch.fft.ifftshift(spectral_inverse, dim=-2)

        # Normalizar resultado
        spectral_inverse = spectral_inverse / (torch.abs(spectral_inverse).max() + 1e-8)

        self._log(f"   ‚úÖ Inverse spectral filter applied: shape={spectral_inverse.shape}")
        return spectral_inverse

    def _quantum_to_token_mapping(self, spectral_inverse: torch.Tensor) -> torch.Tensor:
        """
        Mapeamento direto estado qu√¢ntico -> tokens GPT-2 usando proje√ß√£o linear.
        spectral_inverse: [batch, seq_len, embed_dim, 4] (possivelmente complexo)
        """
        self._log("üéØ [EfficientQuantumDecoder] Mapping quantum state to tokens...")

        batch, seq_len, embed_dim, quat = spectral_inverse.shape

        # Tratar n√∫meros complexos: converter para real antes da proje√ß√£o
        if torch.is_complex(spectral_inverse):
            # Usar magnitude para representa√ß√£o real
            real_input = torch.abs(spectral_inverse)
        else:
            real_input = spectral_inverse

        # Achatar quaterni√µes
        flattened = real_input.reshape(batch, seq_len, embed_dim * quat)  # [1, 64, 256]

        # Projetar para vocabul√°rio
        logits = self.projection(flattened)  # [1, 64, 195]

        # Aplicar softmax para probabilidades
        probabilities = torch.softmax(logits, dim=-1)

        # Selecionar tokens
        tokens = torch.argmax(probabilities, dim=-1)  # [1, 64]

        self._log(f"   ‚úÖ Token mapping complete: {tokens.numel()} tokens generated")
        return tokens.squeeze(0)  # [64]


    def _apply_vocabulary_constraints(self, tokens: torch.Tensor) -> torch.Tensor:
        """
        Aplica constraints lingu√≠sticas do vocabul√°rio Œ®QRH.
        """
        # Garantir que tokens est√£o dentro do vocabul√°rio v√°lido
        valid_tokens = torch.clamp(tokens, 0, self.vocab_size - 1)

        # Adicionar token de fim de sequ√™ncia se necess√°rio
        if len(valid_tokens) < self.seq_length:
            eos_token = torch.tensor([2] * (self.seq_length - len(valid_tokens)), device=self.device)
            valid_tokens = torch.cat([valid_tokens, eos_token])

        return valid_tokens[:self.seq_length]

    def tokens_to_text(self, tokens: torch.Tensor) -> str:
        """
        Converte tokens de volta para texto usando vocabul√°rio Œ®QRH.
        """
        text_tokens = []
        for token_idx in tokens.tolist():
            if token_idx in self.vocab:
                token = self.vocab[token_idx]
                if token not in ['<pad>', '<unk>', '<eos>'] + [f'<special_{i}>' for i in range(95, 195)]:
                    text_tokens.append(token)
            else:
                text_tokens.append('?')  # Token desconhecido

        return ''.join(text_tokens)

    def validate_quantum_output(self, tokens: torch.Tensor, quantum_state: torch.Tensor, min_meaningful_tokens: int = 5) -> Tuple[str, bool]:
        """
        Valida√ß√£o espec√≠fica para sa√≠da qu√¢ntica do Œ®QRH.
        """
        # Converter tokens para texto
        text = self.tokens_to_text(tokens)

        # Verificar se h√° tokens significativos (n√£o apenas especiais)
        meaningful_count = sum(1 for t in tokens.tolist() if t in self.significant_tokens)

        if meaningful_count < min_meaningful_tokens:
            # Ativar fallback inteligente baseado no estado qu√¢ntico
            fallback_text = self._generate_quantum_fallback(quantum_state)
            return fallback_text, False

        return text, True

    def _generate_quantum_fallback(self, quantum_state: torch.Tensor) -> str:
        """ZERO FALLBACK POLICY: Sistema deve falhar claramente"""
        raise RuntimeError("Efficient quantum decoder failed - ZERO FALLBACK POLICY: No quantum fallback allowed")

    def _calculate_quantum_coherence(self, psi: torch.Tensor) -> float:
        """
        Calcula coer√™ncia qu√¢ntica do estado œà.
        """
        # Coer√™ncia baseada na magnitude da parte imagin√°ria
        imag_part = psi[..., 1::2] if psi.shape[-1] == 4 else psi.imag
        coherence = torch.mean(torch.abs(imag_part)).item()
        return coherence

    def run_regression_tests(self) -> dict:
        """
        Testes de regress√£o para validar funcionamento correto em produ√ß√£o.
        """
        import torch

        self._log("üß™ [EfficientQuantumDecoder] Running regression tests...")

        results = {
            'determinism_test': False,
            'token_quality_test': False,
            'shape_validation_test': False
        }

        try:
            # Teste 1: Determinismo - mesma entrada deve gerar mesma sa√≠da
            test_state = torch.randn(1, self.seq_length, self.embed_dim, 4, dtype=torch.complex64)

            tokens1 = self.inverse_decode(test_state.clone())
            tokens2 = self.inverse_decode(test_state.clone())

            results['determinism_test'] = torch.equal(tokens1, tokens2)
            self._log(f"   Determinism test: {'‚úÖ PASS' if results['determinism_test'] else '‚ùå FAIL'}")

            # Teste 2: Qualidade dos tokens - presen√ßa m√≠nima de tokens significativos
            text, is_valid = self.validate_quantum_output(tokens1, test_state, min_meaningful_tokens=3)
            results['token_quality_test'] = is_valid
            self._log(f"   Token quality test: {'‚úÖ PASS' if results['token_quality_test'] else '‚ùå FAIL'}")

            # Teste 3: Valida√ß√£o de shape - deve falhar com shape incorreta
            try:
                wrong_shape = torch.randn(2, 32, 32, 4)  # Shape incorreta
                self.inverse_decode(wrong_shape)
                results['shape_validation_test'] = False  # Deve ter falhado
                self._log("   Shape validation test: ‚ùå FAIL (should have raised AssertionError)")
            except AssertionError:
                results['shape_validation_test'] = True
                self._log("   Shape validation test: ‚úÖ PASS")

        except Exception as e:
            self._log(f"   Regression tests failed with error: {e}")

        all_passed = all(results.values())
        self._log(f"üß™ Regression tests: {'‚úÖ ALL PASSED' if all_passed else '‚ùå SOME FAILED'}")

        return results