"""
Efficient Quantum Decoder - Œ®QRH Architecture
==============================================

Implementa√ß√£o espec√≠fica para decodifica√ß√£o qu√¢ntica baseada na arquitetura real do Œ®QRH.
Resolve o problema de gibberish atrav√©s de invers√£o matem√°tica direta da transformada de Padilha.

Copyright (C) 2025 Klenio Araujo Padilha
Licensed under GNU GPLv3
"""

import torch
import torch.nn as nn
import math
from typing import Tuple, Optional, List
import numpy as np

class EfficientQuantumDecoder:
    """
    Decoder eficiente baseado na arquitetura Œ®QRH real.

    Implementa invers√£o matem√°tica direta da transformada qu√¢ntica,
    eliminando m√©tricas de similaridade complexas que causam gibberish.
    """

    def __init__(self, vocab_size=195, seq_length=64, device='cpu'):
        """
        Inicializa decoder com par√¢metros do Œ®QRH.

        Args:
            vocab_size: Tamanho do vocabul√°rio (195 tokens do GPT-2 spectral)
            seq_length: Comprimento da sequ√™ncia (64)
            device: Dispositivo para processamento
        """
        self.vocab_size = vocab_size
        self.seq_length = seq_length
        self.device = device

        # Carregar vocabul√°rio espec√≠fico do Œ®QRH
        self.vocab = self._load_psiqrh_vocab()

        # Par√¢metros f√≠sicos baseados na equa√ß√£o de Padilha
        self.I0 = 1.0      # Amplitude m√°xima
        self.omega = 2.0 * math.pi  # Frequ√™ncia angular
        self.k = 2.0 * math.pi      # N√∫mero de onda

        print(f"üîß EfficientQuantumDecoder initialized: vocab_size={vocab_size}, seq_length={seq_length}")

    def _load_psiqrh_vocab(self) -> dict:
        """Carrega vocabul√°rio espec√≠fico do Œ®QRH (195 tokens do GPT-2 spectral)"""
        # Baseado no vocabul√°rio real do projeto Œ®QRH
        vocab = {}

        # Tokens especiais (0-2)
        vocab[0] = "<pad>"
        vocab[1] = "<unk>"
        vocab[2] = "<eos>"

        # Tokens de pontua√ß√£o e s√≠mbolos comuns (3-32)
        punctuation = [' ', '.', ',', '!', '?', ';', ':', '-', '(', ')', '[', ']', '{', '}', '"', "'",
                      '+', '=', '*', '/', '\\', '|', '@', '#', '$', '%', '^', '&', '<', '>']

        for i, char in enumerate(punctuation, 3):
            vocab[i] = char

        # N√∫meros (33-42)
        for i in range(10):
            vocab[33 + i] = str(i)

        # Letras mai√∫sculas (43-68)
        for i, char in enumerate('ABCDEFGHIJKLMNOPQRSTUVWXYZ', 43):
            vocab[i] = char

        # Letras min√∫sculas (69-94)
        for i, char in enumerate('abcdefghijklmnopqrstuvwxyz', 69):
            vocab[i] = char

        # Tokens especiais adicionais para completar 195
        for i in range(95, 195):
            vocab[i] = f"<special_{i}>"

        return vocab

    def inverse_decode(self, quantum_state: torch.Tensor) -> torch.Tensor:
        """
        Decodifica√ß√£o inversa baseada na f√≠sica do Œ®QRH.

        Args:
            quantum_state: torch.Size([1, 64, 64, 4]) - sa√≠da do optical_probe

        Returns:
            tokens: torch.Tensor - √≠ndices de tokens do vocabul√°rio
        """
        print(f"üîÑ [EfficientQuantumDecoder] Starting inverse decode: shape={quantum_state.shape}")

        # 1. INVERSA DA SONDA √ìPTICA (Padilha Wave Equation)
        optical_inverse = self._inverse_optical_probe(quantum_state)

        # 2. INVERSA DA ROTA√á√ÉO SO(4)
        rotation_inverse = self._inverse_so4_rotation(optical_inverse)

        # 3. INVERSA DA FILTRAGEM ESPECTRAL
        spectral_inverse = self._inverse_spectral_filter(rotation_inverse)

        # 4. DECODIFICA√á√ÉO DIRETA PARA VOCABUL√ÅRIO GPT-2 (195 tokens)
        tokens = self._quantum_to_token_mapping(spectral_inverse)

        print(f"‚úÖ [EfficientQuantumDecoder] Inverse decode complete: {len(tokens)} tokens")
        return tokens

    def _inverse_optical_probe(self, quantum_state: torch.Tensor) -> torch.Tensor:
        """
        Inversa matem√°tica da sonda √≥ptica de Padilha.

        Original: f(Œª,t) = I‚ÇÄ sin(œât + Œ±Œª) e^(i(œât - kŒª + Œ≤Œª¬≤))
        Inversa: f‚Åª¬π(œà) = œà ¬∑ exp(-i(œât - kŒª + Œ≤Œª¬≤)) / I‚ÇÄ sin(œât + Œ±Œª)
        """
        print("üåä [EfficientQuantumDecoder] Applying inverse optical probe...")

        batch, seq, embed, quat = quantum_state.shape

        # Decompor estado qu√¢ntico em componentes
        real_part = quantum_state[..., 0]  # componente real
        imag_part = quantum_state[..., 1:] # componentes imagin√°rios quaterni√¥nicos

        # Calcular √¢ngulo e magnitude para invers√£o
        time_component = torch.angle(quantum_state.mean(dim=-1, keepdim=True))  # √¢ngulo m√©dio
        spatial_component = torch.abs(quantum_state).mean(dim=-1, keepdim=True)  # magnitude m√©dia

        # Par√¢metros da invers√£o (baseados nos par√¢metros do pipeline)
        alpha = 1.36  # valor calibrado
        beta = 0.725  # valor calibrado

        # Aplicar inversa da modula√ß√£o temporal: exp(-i(œât - kŒª + Œ≤Œª¬≤))
        # Simplifica√ß√£o: usar √¢ngulo do estado qu√¢ntico
        inverse_time = torch.exp(-1j * time_component * beta)

        # Aplicar inversa da modula√ß√£o espacial: 1 / (I‚ÇÄ sin(œât + Œ±Œª))
        # Simplifica√ß√£o: normalizar pela magnitude
        spatial_modulation = torch.sin(time_component + alpha * torch.arange(seq, device=self.device).unsqueeze(0).unsqueeze(-1).unsqueeze(-1))
        inverse_spatial = 1.0 / (self.I0 * spatial_modulation + 1e-8)

        # Aplicar invers√£o completa
        inverted_state = quantum_state * inverse_time * inverse_spatial

        print(f"   ‚úÖ Inverse optical probe applied: shape={inverted_state.shape}")
        return inverted_state

    def _inverse_so4_rotation(self, optical_inverse: torch.Tensor) -> torch.Tensor:
        """
        Inversa da rota√ß√£o SO(4) unit√°ria.

        Como as rota√ß√µes SO(4) s√£o unit√°rias, a inversa √© a transposta/conjugada.
        """
        print("üîÑ [EfficientQuantumDecoder] Applying inverse SO(4) rotation...")

        # Para rota√ß√µes unit√°rias, a inversa √© a transposta do conjugado
        # Simplifica√ß√£o: como estamos trabalhando com quaternions, aplicamos conjugado
        rotation_inverse = torch.conj(optical_inverse)

        print(f"   ‚úÖ Inverse SO(4) rotation applied: shape={rotation_inverse.shape}")
        return rotation_inverse

    def _inverse_spectral_filter(self, rotation_inverse: torch.Tensor) -> torch.Tensor:
        """
        Inversa da filtragem espectral F(k) = exp(i Œ± ¬∑ arctan(ln(|k| + Œµ)))
        """
        print("üéº [EfficientQuantumDecoder] Applying inverse spectral filter...")

        # Aplicar transformada de Fourier inversa
        spectral_inverse = torch.fft.ifft(rotation_inverse, dim=-2)

        # Normalizar resultado
        spectral_inverse = spectral_inverse / (torch.abs(spectral_inverse).max() + 1e-8)

        print(f"   ‚úÖ Inverse spectral filter applied: shape={spectral_inverse.shape}")
        return spectral_inverse

    def _quantum_to_token_mapping(self, spectral_inverse: torch.Tensor) -> torch.Tensor:
        """
        Mapeamento direto estado qu√¢ntico -> tokens GPT-2 usando m√°ximo de probabilidade.
        """
        print("üéØ [EfficientQuantumDecoder] Mapping quantum state to tokens...")

        # Colapsar estado qu√¢ntico para distribui√ß√£o de probabilidade
        quantum_probabilities = self._collapse_quantum_state(spectral_inverse)

        # Mapear para tokens usando m√°ximo de probabilidade (determin√≠stico)
        tokens = self._quantum_maximum_likelihood(quantum_probabilities)

        # Aplicar constraints do vocabul√°rio
        valid_tokens = self._apply_vocabulary_constraints(tokens)

        print(f"   ‚úÖ Token mapping complete: {len(valid_tokens)} tokens generated")
        return valid_tokens

    def _collapse_quantum_state(self, state: torch.Tensor) -> torch.Tensor:
        """
        Colapsa estado qu√¢ntico para distribui√ß√£o cl√°ssica usando regra de Born.
        """
        # Regra de Born: |œà|¬≤ d√° a probabilidade
        probabilities = torch.abs(state) ** 2

        # Normalizar para distribui√ß√£o de probabilidade
        normalized = probabilities / (probabilities.sum(dim=-1, keepdim=True) + 1e-8)

        # M√©dia sobre dimens√µes de embedding e sequ√™ncia para obter distribui√ß√£o final
        final_probabilities = normalized.mean(dim=[1, 2])  # [batch, seq_len]

        return final_probabilities

    def _quantum_maximum_likelihood(self, probabilities: torch.Tensor) -> torch.Tensor:
        """
        Seleciona tokens mais prov√°veis usando m√°ximo de verossimilhan√ßa qu√¢ntica.
        """
        # Para cada posi√ß√£o na sequ√™ncia, selecionar token mais prov√°vel
        # Usar argmax para sele√ß√£o determin√≠stica
        token_indices = torch.argmax(probabilities, dim=-1)

        # Limitar ao tamanho do vocabul√°rio
        token_indices = torch.clamp(token_indices, 0, self.vocab_size - 1)

        return token_indices[:self.seq_length]

    def _apply_vocabulary_constraints(self, tokens: torch.Tensor) -> torch.Tensor:
        """
        Aplica constraints lingu√≠sticas do vocabul√°rio Œ®QRH.
        """
        # Garantir que tokens est√£o dentro do vocabul√°rio v√°lido
        valid_tokens = torch.clamp(tokens, 0, self.vocab_size - 1)

        # Adicionar token de fim de sequ√™ncia se necess√°rio
        if len(valid_tokens) < self.seq_length:
            eos_token = torch.tensor([2] * (self.seq_length - len(valid_tokens)), device=self.device)
            valid_tokens = torch.cat([valid_tokens, eos_token])

        return valid_tokens[:self.seq_length]

    def tokens_to_text(self, tokens: torch.Tensor) -> str:
        """
        Converte tokens de volta para texto usando vocabul√°rio Œ®QRH.
        """
        text_tokens = []
        for token_idx in tokens.tolist():
            if token_idx in self.vocab:
                token = self.vocab[token_idx]
                if token not in ['<pad>', '<unk>', '<eos>'] + [f'<special_{i}>' for i in range(95, 195)]:
                    text_tokens.append(token)
            else:
                text_tokens.append('?')  # Token desconhecido

        return ''.join(text_tokens)

    def validate_quantum_output(self, tokens: torch.Tensor, quantum_state: torch.Tensor, min_meaningful_tokens: int = 5) -> Tuple[str, bool]:
        """
        Valida√ß√£o espec√≠fica para sa√≠da qu√¢ntica do Œ®QRH.
        """
        # Converter tokens para texto
        text = self.tokens_to_text(tokens)

        # Verificar se h√° tokens significativos (n√£o apenas especiais)
        meaningful_tokens = [t for t in tokens.tolist() if t not in [0, 1, 2] and not str(self.vocab.get(t, '')).startswith('<special_')]

        if len(meaningful_tokens) < min_meaningful_tokens:
            # Ativar fallback inteligente baseado no estado qu√¢ntico
            fallback_text = self._generate_quantum_fallback(quantum_state)
            return fallback_text, False

        return text, True

    def _generate_quantum_fallback(self, quantum_state: torch.Tensor) -> str:
        """ZERO FALLBACK POLICY: Sistema deve falhar claramente"""
        raise RuntimeError("Efficient quantum decoder failed - ZERO FALLBACK POLICY: No quantum fallback allowed")

    def _calculate_quantum_coherence(self, psi: torch.Tensor) -> float:
        """
        Calcula coer√™ncia qu√¢ntica do estado œà.
        """
        # Coer√™ncia baseada na magnitude da parte imagin√°ria
        imag_part = psi[..., 1::2] if psi.shape[-1] == 4 else psi.imag
        coherence = torch.mean(torch.abs(imag_part)).item()
        return coherence