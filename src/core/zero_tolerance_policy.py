#!/usr/bin/env python3
"""
Œ®QRH-PROMPT-ENGINE: {
  "context": "Sistema zero tolerance para valida√ß√£o matem√°tica obrigat√≥ria baseado no framework Œ®QRH",
  "analysis": "Implementa√ß√£o de pol√≠tica que for√ßa todas as respostas a serem derivadas matematicamente usando equa√ß√µes do doe.md",
  "solution": "Sistema anti-sarcasmo, anti-manipula√ß√£o com valida√ß√£o matem√°tica obrigat√≥ria usando f√≠sica, matem√°tica e √≥ptica avan√ßada",
  "implementation": [
    "Valida√ß√£o matem√°tica obrigat√≥ria usando equa√ß√µes Œ®QRH",
    "Sistema anti-sarcasmo baseado em an√°lise espectral",
    "Sistema anti-manipula√ß√£o usando quaternions",
    "Zero fallback policy - sem respostas n√£o-matem√°ticas",
    "Integra√ß√£o com camada de c√°lculo quaterni√¥nica"
  ],
  "validation": "Todas as respostas devem ser matematicamente derivadas da camada de c√°lculo do sistema"
}

Œ®QRH Zero Tolerance Mathematical Validation Policy
=================================================

Sistema de valida√ß√£o matem√°tica obrigat√≥ria baseado nos princ√≠pios do framework Œ®QRH.
Todas as respostas devem ser derivadas da camada de c√°lculo usando matem√°tica, f√≠sica e √≥ptica avan√ßada.

Implementa:
- Valida√ß√£o matem√°tica obrigat√≥ria usando equa√ß√µes do doe.md
- Sistema anti-sarcasmo e anti-manipula√ß√£o
- Zero fallback policy - sem respostas n√£o-matem√°ticas
- Integra√ß√£o com camada de c√°lculo quaterni√¥nica
"""

import torch
import torch.nn as nn
import numpy as np
from typing import Dict, Any, Tuple, Optional, List
import warnings
from dataclasses import dataclass
from enum import Enum
import ast
import re
import os
import sys
from pathlib import Path
import logging

logger = logging.getLogger("ZeroTolerancePolicy")

class ValidationLevel(Enum):
    """N√≠veis de valida√ß√£o matem√°tica"""
    STRICT = "strict"           # Apenas respostas matematicamente derivadas
    MODERATE = "moderate"       # Permite aproxima√ß√µes com justificativa matem√°tica
    EMERGENCY = "emergency"     # Para situa√ß√µes cr√≠ticas (ainda requer base matem√°tica)

@dataclass
class MathematicalBasis:
    """Estrutura para base matem√°tica obrigat√≥ria"""
    quaternion_derivation: bool = False
    spectral_analysis: bool = False
    fractal_dimension: bool = False
    padilha_wave_equation: bool = False
    leech_lattice_correction: bool = False

    def is_valid(self) -> bool:
        """Verifica se tem base matem√°tica suficiente"""
        return sum([
            self.quaternion_derivation,
            self.spectral_analysis,
            self.fractal_dimension,
            self.padilha_wave_equation,
            self.leech_lattice_correction
        ]) >= 2  # Pelo menos 2 bases matem√°ticas

class ZeroToleranceValidator:
    """
    Validador de Zero Tolerance para respostas baseadas em matem√°tica

    Baseado nas equa√ß√µes fundamentais do Œ®QRH framework:
    - Quaternion Operations: q‚ÇÅ * q‚ÇÇ = (w‚ÇÅw‚ÇÇ - x‚ÇÅx‚ÇÇ - y‚ÇÅy‚ÇÇ - z‚ÇÅz‚ÇÇ) + ...
    - Spectral Filter: F(k) = exp(iŒ±¬∑arctan(ln(|k| + Œµ)))
    - Padilha Wave: f(Œª,t) = I‚ÇÄsin(œât + Œ±Œª)e^(i(œât-kŒª+Œ≤Œª¬≤))
    - Fractal Dimension: D = -lim(Œµ‚Üí0) ln(N(Œµ))/ln(Œµ)
    """

    def __init__(self, validation_level: ValidationLevel = ValidationLevel.STRICT):
        self.validation_level = validation_level
        self.mathematical_constants = self._load_mathematical_constants()
        self.violation_count = 0
        self.total_validations = 0

    def _load_mathematical_constants(self) -> Dict[str, float]:
        """Carrega constantes matem√°ticas do framework Œ®QRH"""
        return {
            'alpha_min': 0.1,
            'alpha_max': 3.0,
            'epsilon_stability': 1e-10,
            'quaternion_tolerance': 1e-5,
            'energy_conservation_threshold': 0.05,
            'fractal_beta_1d': lambda D: 3 - 2*D,
            'fractal_beta_2d': lambda D: 5 - 2*D,
            'fractal_beta_3d': lambda D: 7 - 2*D,
        }

    def validate_response(self,
                         response_content: str,
                         mathematical_basis: MathematicalBasis,
                         calculation_trace: Optional[Dict] = None) -> Tuple[bool, str, float]:
        """
        Valida resposta usando zero tolerance policy

        Args:
            response_content: Conte√∫do da resposta
            mathematical_basis: Base matem√°tica da resposta
            calculation_trace: Trace dos c√°lculos realizados

        Returns:
            (is_valid, reason, confidence_score)
        """
        self.total_validations += 1

        # Valida√ß√£o 1: Base matem√°tica obrigat√≥ria
        if not mathematical_basis.is_valid():
            self.violation_count += 1
            return False, "REJECTED: Resposta sem base matem√°tica suficiente do framework Œ®QRH", 0.0

        # Valida√ß√£o 2: Anti-sarcasmo usando an√°lise espectral
        sarcasm_score = self._detect_sarcasm_spectral(response_content)
        if sarcasm_score > 0.3:
            self.violation_count += 1
            return False, f"REJECTED: Detectado sarcasmo (score: {sarcasm_score:.3f}) - viola√ß√£o da pol√≠tica", 0.0

        # Valida√ß√£o 3: Anti-manipula√ß√£o usando quaternions (threshold ajustado)
        manipulation_score = self._detect_manipulation_quaternion(response_content)
        if manipulation_score > 0.7:  # Aumentado de 0.4 para 0.7 para reduzir falsos positivos
            self.violation_count += 1
            return False, f"REJECTED: Detectada manipula√ß√£o (score: {manipulation_score:.3f})", 0.0

        # Valida√ß√£o 4: Trace de c√°lculo obrigat√≥rio
        if calculation_trace is None:
            if self.validation_level == ValidationLevel.STRICT:
                self.violation_count += 1
                return False, "REJECTED: Trace de c√°lculo matem√°tico n√£o fornecido", 0.0
        else:
            calc_validity = self._validate_calculation_trace(calculation_trace)
            if not calc_validity:
                self.violation_count += 1
                return False, "REJECTED: Trace de c√°lculo matematicamente inv√°lido", 0.0

        # Valida√ß√£o 5: Conformidade com equa√ß√µes Œ®QRH
        equation_compliance = self._validate_psi_qrh_compliance(mathematical_basis, calculation_trace)
        if equation_compliance < 0.7:
            self.violation_count += 1
            return False, f"REJECTED: Baixa conformidade Œ®QRH (score: {equation_compliance:.3f})", 0.0

        # Resposta aprovada
        confidence = self._calculate_confidence_score(mathematical_basis, calculation_trace)
        return True, "APPROVED: Resposta matematicamente validada", confidence

    def _detect_sarcasm_spectral(self, text: str) -> float:
        """
        Detecta sarcasmo usando an√°lise espectral de frequ√™ncia de palavras
        Baseado em F(k) = exp(iŒ±¬∑arctan(ln(|k| + Œµ)))
        """
        # Converte texto para frequ√™ncias de caracteres
        char_freq = np.array([ord(c) for c in text.lower() if c.isalnum()])
        if len(char_freq) == 0:
            return 0.0

        # Aplica filtro espectral Œ®QRH
        alpha = 1.5  # Par√¢metro de detec√ß√£o de sarcasmo
        epsilon = self.mathematical_constants['epsilon_stability']

        k_values = np.fft.fft(char_freq)
        spectral_filter = np.exp(1j * alpha * np.arctan(np.log(np.abs(k_values) + epsilon)))

        # Calcula score de sarcasmo baseado em distor√ß√£o espectral
        filtered_spectrum = k_values * spectral_filter
        distortion = np.mean(np.abs(filtered_spectrum - k_values))

        # Ajusta normaliza√ß√£o para evitar falsos positivos
        normalized_score = min(distortion / 10000.0, 1.0)  # Normaliza para [0,1] com threshold mais alto

        # Para queries matem√°ticas leg√≠timas, reduz score
        math_keywords = ['quaternion', 'fractal', 'spectral', 'calculate', 'analyze', 'dimension']
        if any(keyword in text.lower() for keyword in math_keywords):
            normalized_score = normalized_score * 0.1  # Reduz drasticamente para queries matem√°ticas

        return normalized_score

    def _detect_manipulation_quaternion(self, text: str) -> float:
        """
        Detecta manipula√ß√£o usando rota√ß√µes quaterni√¥nicas
        Baseado em Œ®' = q_left * Œ® * q_right‚Ä†
        """
        if len(text) < 4:
            return 0.0

        # Mapeia texto para quaternion
        text_nums = [ord(c) % 10 for c in text if c.isalnum()]
        if len(text_nums) < 4:
            return 0.0

        # Cria quaternion do texto
        q = np.array(text_nums[:4], dtype=float)
        if np.linalg.norm(q) == 0:
            return 0.0
        q = q / np.linalg.norm(q)  # Normaliza

        # Quaternion de refer√™ncia (n√£o-manipulativo)
        q_ref = np.array([1.0, 0.0, 0.0, 0.0])

        # Calcula "dist√¢ncia" quaterni√¥nica para detectar manipula√ß√£o
        # Hamilton product q1 * q2‚Ä†
        q_conj = np.array([q_ref[0], -q_ref[1], -q_ref[2], -q_ref[3]])

        # Produto Hamilton simplificado
        dot_product = np.dot(q, q_conj)
        manipulation_score = 1.0 - abs(dot_product)

        # Para queries matem√°ticas leg√≠timas, reduz score drasticamente
        math_keywords = ['quaternion', 'fractal', 'spectral', 'calculate', 'analyze', 'dimension', 'what', 'how']
        if any(keyword in text.lower() for keyword in math_keywords):
            manipulation_score = manipulation_score * 0.1  # Reduz score para queries matem√°ticas

        return min(manipulation_score, 1.0)

    def _validate_calculation_trace(self, trace: Dict) -> bool:
        """Valida trace de c√°lculo usando princ√≠pios Œ®QRH"""
        required_keys = ['method', 'input_values', 'calculations', 'result']

        if not all(key in trace for key in required_keys):
            return False

        # Verifica se m√©todo √© baseado em Œ®QRH
        valid_methods = [
            'quaternion_operations',
            'spectral_filtering',
            'fractal_analysis',
            'padilha_wave_equation',
            'leech_lattice_correction',
            'qrh_layer_computation',  # Novo m√©todo usando QRH Layer real
            'quaternion_spectral_analysis'  # M√©todo existente
        ]

        if trace['method'] not in valid_methods:
            return False

        # Verifica consist√™ncia num√©rica
        if isinstance(trace['input_values'], (list, np.ndarray)):
            if len(trace['input_values']) == 0:
                return False

        return True

    def _validate_psi_qrh_compliance(self, basis: MathematicalBasis, trace: Optional[Dict]) -> float:
        """Valida conformidade com equa√ß√µes Œ®QRH"""
        compliance_score = 0.0
        total_checks = 0

        # Check 1: Quaternion operations
        if basis.quaternion_derivation:
            compliance_score += 1.0
            total_checks += 1

        # Check 2: Spectral analysis
        if basis.spectral_analysis:
            compliance_score += 1.0
            total_checks += 1

        # Check 3: Fractal dimension
        if basis.fractal_dimension:
            compliance_score += 1.0
            total_checks += 1

        # Check 4: Padilha wave equation
        if basis.padilha_wave_equation:
            compliance_score += 1.0
            total_checks += 1

        # Check 5: Leech lattice correction
        if basis.leech_lattice_correction:
            compliance_score += 1.0
            total_checks += 1

        if total_checks == 0:
            return 0.0

        return compliance_score / total_checks

    def _calculate_confidence_score(self, basis: MathematicalBasis, trace: Optional[Dict]) -> float:
        """Calcula score de confian√ßa da resposta validada"""
        base_confidence = 0.5

        # Bonus por base matem√°tica s√≥lida
        if basis.is_valid():
            base_confidence += 0.3

        # Bonus por trace detalhado
        if trace is not None:
            base_confidence += 0.2

        return min(base_confidence, 1.0)

    def get_policy_stats(self) -> Dict[str, Any]:
        """Retorna estat√≠sticas da pol√≠tica zero tolerance"""
        if self.total_validations == 0:
            compliance_rate = 1.0
        else:
            compliance_rate = 1.0 - (self.violation_count / self.total_validations)

        return {
            'total_validations': self.total_validations,
            'violations': self.violation_count,
            'compliance_rate': compliance_rate,
            'validation_level': self.validation_level.value,
            'status': 'COMPLIANT' if compliance_rate > 0.95 else 'NON_COMPLIANT'
        }

class HardcodingDetector:
    """Detector de hardcoding baseado em an√°lise est√°tica e padr√µes (DEPRECATED - mantido para compatibilidade)"""

    def __init__(self):
        self.hardcoding_patterns = {
            "response_dictionaries": [
                r'responses\s*=\s*\{[^}]+\}',
                r'answers\s*=\s*\{[^}]+\}',
                r'RESPONSES\s*=\s*\{[^}]+\}'
            ],
            "template_strings": [
                r'return\s+"""[^"]+"""',
                r'return\s+f"[^"]+"',
                r'"""[^"""]+"""',
                r'\"\"\"[^\"\"\"]+\"\"\"'
            ],
            "simulation_patterns": [
                r'time\.sleep\s*\([^)]+\)',
                r'#\s*Simulate',
                r'#\s*Mock',
                r'#\s*Fake'
            ],
            "fallback_patterns": [
                r'fallback.*=.*"',
                r'default.*response',
                r'placeholder.*content'
            ],
            "hardcoded_values": [
                r'\d+\.\s*"[^"]+"',  # Respostas numeradas
                r'"[^"]{100,}"',      # Strings muito longas
                r'\{[^}]{200,}\}'      # Dicion√°rios grandes
            ]
        }

    def scan_file(self, file_path: str) -> Dict[str, Any]:
        """Escaneia arquivo em busca de padr√µes de hardcoding"""

        violations = {
            "file": file_path,
            "violations": [],
            "severity": "clean",
            "line_count": 0,
            "hardcoding_score": 0
        }

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')
                violations["line_count"] = len(lines)

            # Verificar padr√µes de regex
            for pattern_type, patterns in self.hardcoding_patterns.items():
                for pattern in patterns:
                    matches = re.finditer(pattern, content, re.MULTILINE | re.IGNORECASE)
                    for match in matches:
                        line_number = content[:match.start()].count('\n') + 1
                        violation = {
                            "type": pattern_type,
                            "pattern": pattern,
                            "match": match.group()[:200],  # Limitar tamanho
                            "line": line_number,
                            "severity": self._get_severity(pattern_type)
                        }
                        violations["violations"].append(violation)

            # An√°lise AST para detec√ß√£o mais profunda
            ast_violations = self._analyze_ast(content, file_path)
            violations["violations"].extend(ast_violations)

            # Calcular score de hardcoding
            violations["hardcoding_score"] = self._calculate_hardcoding_score(violations["violations"])
            violations["severity"] = self._determine_severity_level(violations["hardcoding_score"])

            return violations

        except Exception as e:
            logger.error(f"Erro ao escanear {file_path}: {e}")
            violations["error"] = str(e)
            return violations

    def _analyze_ast(self, content: str, file_path: str) -> List[Dict[str, Any]]:
        """An√°lise AST para detec√ß√£o de hardcoding estrutural"""

        violations = []

        try:
            tree = ast.parse(content)

            for node in ast.walk(tree):
                # Detectar dicion√°rios grandes (potenciais respostas hardcoded)
                if isinstance(node, ast.Dict):
                    if len(node.keys) > 5:  # Dicion√°rio com mais de 5 entradas
                        # Verificar se cont√©m strings longas (respostas)
                        string_values = []
                        for value in node.values:
                            if isinstance(value, ast.Str):
                                if len(value.s) > 50:  # Strings longas
                                    string_values.append(value.s)

                        if len(string_values) >= 3:  # M√∫ltiplas respostas longas
                            violations.append({
                                "type": "large_response_dict",
                                "pattern": "AST Dict Analysis",
                                "match": f"Dictionary with {len(node.keys)} keys and {len(string_values)} long responses",
                                "line": node.lineno if hasattr(node, 'lineno') else 0,
                                "severity": "high"
                            })

                # Detectar fun√ß√µes de simula√ß√£o
                if isinstance(node, ast.FunctionDef):
                    func_name = node.name.lower()
                    if any(keyword in func_name for keyword in ['simulate', 'mock', 'fake', 'dummy']):
                        violations.append({
                            "type": "simulation_function",
                            "pattern": "Function naming",
                            "match": f"Function '{node.name}' suggests simulation",
                            "line": node.lineno,
                            "severity": "medium"
                        })

                # Detectar imports de simula√ß√£o
                if isinstance(node, ast.Import) or isinstance(node, ast.ImportFrom):
                    for alias in (node.names if isinstance(node, ast.Import) else [node]):
                        module_name = (alias.name if isinstance(node, ast.Import) else node.module)
                        if module_name and any(keyword in module_name.lower() for keyword in ['mock', 'fake', 'dummy']):
                            violations.append({
                                "type": "simulation_import",
                                "pattern": "Module import",
                                "match": f"Import from simulation module: {module_name}",
                                "line": node.lineno,
                                "severity": "medium"
                            })

        except SyntaxError:
            # Arquivo pode n√£o ser Python v√°lido
            pass

        return violations

    def _get_severity(self, pattern_type: str) -> str:
        """Determinar severidade baseada no tipo de padr√£o"""
        severity_map = {
            "response_dictionaries": "critical",
            "template_strings": "high",
            "simulation_patterns": "medium",
            "fallback_patterns": "medium",
            "hardcoded_values": "low"
        }
        return severity_map.get(pattern_type, "low")

    def _calculate_hardcoding_score(self, violations: List[Dict]) -> float:
        """Calcular score de hardcoding baseado nas viola√ß√µes"""
        if not violations:
            return 0.0

        severity_weights = {"critical": 10, "high": 5, "medium": 3, "low": 1}
        total_score = sum(severity_weights.get(v["severity"], 1) for v in violations)

        return min(total_score / 10, 10.0)  # Normalizar para 0-10

    def _determine_severity_level(self, score: float) -> str:
        """Determinar n√≠vel de severidade baseado no score"""
        if score == 0:
            return "clean"
        elif score < 2:
            return "low"
        elif score < 5:
            return "medium"
        elif score < 8:
            return "high"
        else:
            return "critical"

class ZeroToleranceAuditor:
    """Auditor de toler√¢ncia zero para verifica√ß√£o cont√≠nua"""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.detector = HardcodingDetector()
        self.audit_results = {}

    def audit_project(self) -> Dict[str, Any]:
        """Realizar auditoria completa do projeto"""

        logger.info("üîç INICIANDO AUDITORIA DE TOLER√ÇNCIA ZERO")

        audit_result = {
            "timestamp": self._get_timestamp(),
            "project_root": str(self.project_root),
            "files_scanned": 0,
            "violations_found": 0,
            "critical_violations": 0,
            "files_with_violations": [],
            "overall_severity": "clean",
            "recommendations": []
        }

        # Escanear arquivos Python relevantes
        python_files = self._find_python_files()

        for file_path in python_files:
            file_result = self.detector.scan_file(file_path)
            self.audit_results[file_path] = file_result

            audit_result["files_scanned"] += 1

            if file_result["violations"]:
                audit_result["violations_found"] += len(file_result["violations"])
                audit_result["files_with_violations"].append({
                    "file": file_path,
                    "violations": len(file_result["violations"]),
                    "severity": file_result["severity"]
                })

                # Contar viola√ß√µes cr√≠ticas
                critical_count = sum(1 for v in file_result["violations"] if v["severity"] == "critical")
                audit_result["critical_violations"] += critical_count

        # Determinar severidade geral
        audit_result["overall_severity"] = self._determine_overall_severity(audit_result)

        # Gerar recomenda√ß√µes
        audit_result["recommendations"] = self._generate_recommendations(audit_result)

        logger.info(f"‚úÖ AUDITORIA CONCLU√çDA: {audit_result['files_scanned']} arquivos escaneados")
        logger.info(f"üìä VIOLA√á√ïES: {audit_result['violations_found']} total, {audit_result['critical_violations']} cr√≠ticas")

        return audit_result

    def _find_python_files(self) -> List[str]:
        """Encontrar todos os arquivos Python no projeto"""
        python_files = []

        for root, dirs, files in os.walk(self.project_root):
            # Ignorar diret√≥rios espec√≠ficos
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['__pycache__', 'node_modules']]

            for file in files:
                if file.endswith('.py') and not file.startswith('.'):
                    python_files.append(os.path.join(root, file))

        return python_files

    def _get_timestamp(self) -> str:
        """Obter timestamp formatado"""
        from datetime import datetime
        return datetime.now().isoformat()

    def _determine_overall_severity(self, audit_result: Dict) -> str:
        """Determinar severidade geral da auditoria"""
        if audit_result["critical_violations"] > 0:
            return "critical"
        elif audit_result["violations_found"] > 10:
            return "high"
        elif audit_result["violations_found"] > 5:
            return "medium"
        elif audit_result["violations_found"] > 0:
            return "low"
        else:
            return "clean"

    def _generate_recommendations(self, audit_result: Dict) -> List[str]:
        """Gerar recomenda√ß√µes baseadas nos resultados"""

        recommendations = []

        if audit_result["critical_violations"] > 0:
            recommendations.append("üö® CORRE√á√ÉO IMEDIATA REQUERIDA: Viola√ß√µes cr√≠ticas detectadas")
            recommendations.append("üîß Priorizar arquivos com viola√ß√µes cr√≠ticas")

        if audit_result["violations_found"] > 0:
            recommendations.append("üìã Revisar e corrigir viola√ß√µes identificadas")
            recommendations.append("üîç Implementar verifica√ß√µes cont√≠nuas no pipeline CI/CD")

        if audit_result["overall_severity"] == "clean":
            recommendations.append("‚úÖ Projeto est√° limpo - manter pol√≠ticas de preven√ß√£o")

        recommendations.append("üìö Documentar padr√µes anti-hardcoding para novos desenvolvedores")
        recommendations.append("üîÑ Estabelecer revis√µes de c√≥digo regulares focadas em hardcoding")

        return recommendations

    def generate_audit_report(self) -> str:
        """Gerar relat√≥rio detalhado da auditoria"""

        audit_result = self.audit_results

        report = f"""
üéØ RELAT√ìRIO DE AUDITORIA - POL√çTICA DE TOLER√ÇNCIA ZERO Œ®QRH

Œ®QRH-PROMPT-ENGINE: {{
  "context": "Auditoria completa do framework Œ®QRH para detec√ß√£o de hardcoding",
  "analysis": "Sistema escaneou {len(audit_result)} arquivos em busca de padr√µes de dados mockados",
  "solution": "Implementar verifica√ß√µes cont√≠nuas e corre√ß√µes preventivas",
  "implementation": [
    "‚úÖ {sum(1 for r in audit_result.values() if r['violations']) if audit_result else 0} arquivos com viola√ß√µes identificados",
    "‚úÖ {sum(len(r['violations']) for r in audit_result.values() if r['violations']) if audit_result else 0} viola√ß√µes totais detectadas",
    "‚úÖ Severidade geral: {self._determine_overall_severity({'violations_found': sum(len(r['violations']) for r in audit_result.values() if r['violations']), 'critical_violations': sum(1 for r in audit_result.values() for v in r.get('violations', []) if v.get('severity') == 'critical')}) if audit_result else 'clean'}"
  ],
  "validation": "Auditoria conclu√≠da com sucesso - sistema pronto para preven√ß√£o cont√≠nua"
}}

üìä RESUMO EXECUTIVO:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
"""

        if not audit_result:
            report += "‚ùå Nenhum resultado de auditoria dispon√≠vel\n"
            return report

        # Estat√≠sticas gerais
        total_files = len(audit_result)
        files_with_violations = sum(1 for r in audit_result.values() if r["violations"])
        total_violations = sum(len(r["violations"]) for r in audit_result.values())
        critical_violations = sum(1 for r in audit_result.values() for v in r["violations"] if v["severity"] == "critical")

        report += f"""
üìà ESTAT√çSTICAS GERAIS:
‚Ä¢ Arquivos escaneados: {total_files}
‚Ä¢ Arquivos com viola√ß√µes: {files_with_violations}
‚Ä¢ Viola√ß√µes totais: {total_violations}
‚Ä¢ Viola√ß√µes cr√≠ticas: {critical_violations}
‚Ä¢ Taxa de viola√ß√£o: {(files_with_violations/total_files*100) if total_files > 0 else 0:.1f}%

üîç ARQUIVOS COM VIOLA√á√ïES:
"""

        # Listar arquivos problem√°ticos
        problematic_files = [(f, r) for f, r in audit_result.items() if r["violations"]]
        problematic_files.sort(key=lambda x: len(x[1]["violations"]), reverse=True)

        for file_path, result in problematic_files[:10]:  # Top 10
            relative_path = Path(file_path).relative_to(self.project_root)
            report += f"\nüìÑ {relative_path}:"
            report += f"\n   ‚Ä¢ Viola√ß√µes: {len(result['violations'])}"
            report += f"\n   ‚Ä¢ Severidade: {result['severity']}"
            report += f"\n   ‚Ä¢ Score: {result['hardcoding_score']:.1f}/10"

        # Recomenda√ß√µes
        recommendations = self._generate_recommendations({
            "violations_found": total_violations,
            "critical_violations": critical_violations,
            "overall_severity": self._determine_overall_severity({
                "violations_found": total_violations,
                "critical_violations": critical_violations
            })
        })

        report += "\n\nüí° RECOMENDA√á√ïES:"
        for rec in recommendations:
            report += f"\n‚Ä¢ {rec}"

        report += "\n\nüéØ STATUS FINAL: "
        if critical_violations > 0:
            report += "üö® REQUER CORRE√á√ÉO IMEDIATA"
        elif total_violations > 0:
            report += "‚ö†Ô∏è REQUER ATEN√á√ÉO"
        else:
            report += "‚úÖ LIMPO - MANTENHA ASSIM!"

        return report

def main():
    """Fun√ß√£o principal para demonstra√ß√£o da auditoria"""

    logging.basicConfig(level=logging.INFO)

    print("üöÄ INICIANDO AUDITORIA DE TOLER√ÇNCIA ZERO Œ®QRH")
    print("=" * 60)

    # Auditoria do projeto atual
    project_root = Path(__file__).parent.parent
    auditor = ZeroToleranceAuditor(project_root)

    # Executar auditoria
    audit_result = auditor.audit_project()

    # Gerar relat√≥rio
    report = auditor.generate_audit_report()
    print(report)

    # Salvar relat√≥rio
    report_path = project_root / "zero_tolerance_audit_report.txt"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"\nüíæ Relat√≥rio salvo em: {report_path}")

    # Status final
    if audit_result.get("critical_violations", 0) > 0:
        print("\n‚ùå AUDITORIA FALHOU: Viola√ß√µes cr√≠ticas detectadas")
        return 1
    else:
        print("\n‚úÖ AUDITORIA APROVADA: Sistema dentro dos padr√µes de toler√¢ncia zero")
        return 0

if __name__ == "__main__":
    exit(main())