#!/usr/bin/env python3
"""
Consciousness Metrics - MediÃ§Ã£o de ConsciÃªncia Fractal
=====================================================

Implementa mÃ©tricas quantitativas para mediÃ§Ã£o de consciÃªncia,
incluindo o Ãndice de ConsciÃªncia Fractal (FCI) e outras mÃ©tricas
derivadas das equaÃ§Ãµes de dinÃ¢mica consciente.

Ãndice Principal: FCI = (D_EEG Ã— H_fMRI Ã— CLZ) / D_max
"""

import torch
import torch.nn as nn
import numpy as np
from typing import Dict, Any, Optional, Tuple, List
from dataclasses import dataclass


@dataclass
class FCI:
    """
    Fractal Consciousness Index - Ãndice de ConsciÃªncia Fractal.

    Representa o nÃ­vel quantitativo de consciÃªncia baseado em
    mÃ©tricas matemÃ¡ticas rigorosas.
    """
    value: float  # Valor principal do FCI [0, 1]
    components: Dict[str, float]  # Componentes individuais
    timestamp: float  # Momento da mediÃ§Ã£o
    state_classification: str  # Estado associado
    confidence: float  # ConfianÃ§a da mediÃ§Ã£o [0, 1]

    def __post_init__(self):
        """ValidaÃ§Ã£o apÃ³s inicializaÃ§Ã£o."""
        if not (0.0 <= self.value <= 1.0):
            raise ValueError(f"FCI must be in [0, 1], got {self.value}")

        if not (0.0 <= self.confidence <= 1.0):
            raise ValueError(f"Confidence must be in [0, 1], got {self.confidence}")


class ConsciousnessMetrics(nn.Module):
    """
    Calculadora de mÃ©tricas de consciÃªncia que implementa
    o FCI e mÃ©tricas auxiliares para anÃ¡lise completa.
    """

    def __init__(self, config, metrics_config=None):
        super().__init__()
        self.config = config
        # Handle both dict and object configs
        if hasattr(config, 'device'):
            self.device = config.device
        else:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        # Carregar configuraÃ§Ãµes de mÃ©tricas do arquivo YAML
        import yaml
        import os

        try:
            config_path = os.path.join(os.path.dirname(__file__), '..', '..', 'configs', 'consciousness_metrics.yaml')
            with open(config_path, 'r') as f:
                yaml_config = yaml.safe_load(f)

            # Usar configuraÃ§Ã£o do YAML se disponÃ­vel
            if yaml_config:
                metrics_config = yaml_config
        except Exception as e:
            print(f"âš ï¸ Erro ao carregar configuraÃ§Ãµes YAML: {e}. Usando configuraÃ§Ã£o fornecida.")

        # ParÃ¢metros de normalizaÃ§Ã£o para componentes do FCI
        self.d_eeg_max = metrics_config.get('component_max_values', {}).get('d_eeg_max', 10.0)
        self.h_fmri_max = metrics_config.get('component_max_values', {}).get('h_fmri_max', 5.0)
        self.clz_max = metrics_config.get('component_max_values', {}).get('clz_max', 3.0)
        # Handle both dict and object configs for diffusion coefficient
        if hasattr(config, 'diffusion_coefficient_range'):
            self.d_max = config.diffusion_coefficient_range[1]
        else:
            diffusion_range = config.get('diffusion_coefficient_range', [0.01, 10.0])
            self.d_max = diffusion_range[1]

        # ParÃ¢metros de dimensÃ£o fractal (para mapeamento correto D â†’ FCI)
        fractal_dim = metrics_config.get('fractal_dimension', {})
        self.fractal_dimension_min = fractal_dim.get('min', 1.0)
        self.fractal_dimension_max = fractal_dim.get('max', 3.0)
        self.fractal_dimension_normalizer = fractal_dim.get('normalizer', 2.0)

        # Thresholds de estados (configurÃ¡veis)
        state_thresholds = metrics_config.get('state_thresholds', {})
        self.threshold_emergence = state_thresholds.get('emergence', {}).get('min_fci', 0.85)
        self.threshold_meditation = state_thresholds.get('meditation', {}).get('min_fci', 0.70)
        self.threshold_analysis = state_thresholds.get('analysis', {}).get('min_fci', 0.45)

        # HistÃ³rico de mediÃ§Ãµes
        self.fci_history: List[FCI] = []
        measurement_quality = metrics_config.get('measurement_quality', {})
        self.max_history = measurement_quality.get('max_history', 1000)

        # ProteÃ§Ã£o contra NaN
        self.enable_nan_protection = measurement_quality.get('enable_nan_protection', True)
        self.default_fci_on_nan = measurement_quality.get('default_fci_on_nan', 0.5)

        # Pesos para componentes do FCI (aprendÃ­veis)
        fci_weights_config = metrics_config.get('fci_weights', {})
        fci_weights = [
            fci_weights_config.get('d_eeg', 0.4),
            fci_weights_config.get('h_fmri', 0.3),
            fci_weights_config.get('clz', 0.3)
        ]
        self.register_parameter(
            'fci_weights',
            nn.Parameter(torch.tensor(fci_weights))  # [D_EEG, H_fMRI, CLZ]
        )

        # Correlation method settings
        correlation_method = metrics_config.get('correlation_method', {})
        self.correlation_method = correlation_method.get('method', 'autocorrelation')
        self.correlation_fallback = correlation_method.get('fallback_value', 0.5)
        self.correlation_use_abs = correlation_method.get('use_absolute_value', True)
        self.correlation_clamp = correlation_method.get('clamp_range', [0.0, 1.0])

        # Debug settings
        debug = metrics_config.get('debug', {})
        self.log_fci_calculations = debug.get('log_fci_calculations', False)
        self.log_component_details = debug.get('log_component_details', False)

        print(f"ğŸ“Š ConsciousnessMetrics inicializado")
        print(f"   - Component Max Values: D_EEG={self.d_eeg_max}, H_fMRI={self.h_fmri_max}, CLZ={self.clz_max}")
        print(f"   - Fractal D: [{self.fractal_dimension_min}, {self.fractal_dimension_max}]")
        print(f"   - FCI Thresholds: EMERGENCEâ‰¥{self.threshold_emergence}, MEDITATIONâ‰¥{self.threshold_meditation}, ANALYSISâ‰¥{self.threshold_analysis}")
        print(f"   - Correlation Method: {self.correlation_method}")

    def compute_fci(
        self,
        psi_distribution: torch.Tensor,
        fractal_field: torch.Tensor,
        timestamp: Optional[float] = None,
        power_spectrum_pk: Optional[torch.Tensor] = None
    ) -> float:
        """
        Computa Ãndice de ConsciÃªncia Fractal (FCI).

        FCI = (D_EEG Ã— H_fMRI Ã— CLZ) / D_max

        Args:
            psi_distribution: DistribuiÃ§Ã£o P(Ïˆ) [batch, embed_dim]
            fractal_field: Campo fractal F(Ïˆ) [batch, embed_dim]
            timestamp: Momento da mediÃ§Ã£o
            power_spectrum_pk: P(k) do espectro quaterniÃ´nico [batch, embed_dim] (NOVO)

        Returns:
            Valor do FCI [0, 1]
        """
        if timestamp is None:
            timestamp = torch.rand(1).item()  # Timestamp sintÃ©tico

        # FASE 2: Calcular dimensÃ£o fractal D a partir de P(k)
        # Se P(k) foi fornecido, usar; caso contrÃ¡rio, usar psi_distribution como fallback
        pk_for_analysis = power_spectrum_pk if power_spectrum_pk is not None else psi_distribution
        fractal_dimension_D = self._compute_fractal_dimension(pk_for_analysis)

        # Calcular componentes do FCI (H_fMRI agora recebe D)
        d_eeg = self._compute_d_eeg(psi_distribution, fractal_field)
        h_fmri = self._compute_h_fmri(psi_distribution, fractal_field, fractal_dimension_D)
        clz = self._compute_clz(psi_distribution, fractal_field)

        # Normalizar componentes (d_eeg, h_fmri, clz jÃ¡ sÃ£o floats)
        d_eeg_norm = d_eeg / self.d_eeg_max
        h_fmri_norm = h_fmri / self.h_fmri_max
        clz_norm = clz / self.clz_max

        # Calcular FCI com pesos adaptativos
        fci_numerator = (
            self.fci_weights[0] * d_eeg_norm +
            self.fci_weights[1] * h_fmri_norm +
            self.fci_weights[2] * clz_norm
        )

        # Normalizar FCI ao range [0, 1]
        # FCI jÃ¡ deve estar no intervalo [0,1] por construÃ§Ã£o dos componentes normalizados
        fci_value = fci_numerator.clamp(0.0, 1.0).item()

        # Log detalhado se habilitado
        if self.log_component_details:
            print(f"\nğŸ”¬ FCI Components Debug:")
            print(f"   Fractal Dimension D: {fractal_dimension_D:.4f} (usado em H_fMRI)")
            print(f"   D_EEG: {d_eeg:.4f} (norm: {d_eeg_norm:.4f}, max: {self.d_eeg_max})")
            print(f"   H_fMRI: {h_fmri:.4f} (norm: {h_fmri_norm:.4f}, max: {self.h_fmri_max})")
            print(f"   CLZ: {clz:.4f} (norm: {clz_norm:.4f}, max: {self.clz_max})")
            print(f"   Weights: {self.fci_weights.detach().cpu().numpy()}")
            print(f"   FCI = {fci_value:.4f}")

        # Calcular confianÃ§a da mediÃ§Ã£o
        confidence = self._compute_measurement_confidence(d_eeg, h_fmri, clz)

        # Classificar estado baseado no FCI
        state_classification = self._classify_fci_state(fci_value)

        # Criar objeto FCI (componentes normalizados jÃ¡ sÃ£o floats)
        fci_object = FCI(
            value=fci_value,
            components={
                'D_EEG': d_eeg,
                'H_fMRI': h_fmri,
                'CLZ': clz,
                'D_EEG_normalized': d_eeg_norm,
                'H_fMRI_normalized': h_fmri_norm,
                'CLZ_normalized': clz_norm
            },
            timestamp=timestamp,
            state_classification=state_classification,
            confidence=confidence
        )

        # Armazenar no histÃ³rico
        self._update_fci_history(fci_object)

        return fci_value

    def _compute_fractal_dimension(self, power_spectrum_pk: torch.Tensor) -> float:
        """
        Calcula dimensÃ£o fractal D via anÃ¡lise de lei de potÃªncia P(k) ~ k^(-Î²).
        Conforme paper Î¨QRH SeÃ§Ã£o 3.1: D = (3-Î²)/2

        Args:
            power_spectrum_pk: DistribuiÃ§Ã£o de potÃªncia P(k) [batch, embed_dim]

        Returns:
            DimensÃ£o fractal D âˆˆ [1.0, 2.0]
        """
        # Criar Ã­ndices de frequÃªncia k (comeÃ§ar de 1 para evitar log(0))
        batch_size, embed_dim = power_spectrum_pk.shape
        k = torch.arange(1, embed_dim + 1, dtype=torch.float32, device=power_spectrum_pk.device)

        # Flatten
        pk_flat = power_spectrum_pk.flatten()
        k_repeated = k.repeat(batch_size)

        # Filtrar: manter apenas P(k) > threshold (threshold menor para pegar mais pontos)
        # Usar percentil em vez de threshold fixo
        threshold = torch.quantile(pk_flat[pk_flat > 0], 0.1)  # Pegar 90% dos valores nÃ£o-zero
        mask = pk_flat > threshold
        pk_filtered = pk_flat[mask]
        k_filtered = k_repeated[mask]

        if len(pk_filtered) < 10:  # Exigir pelo menos 10 pontos para regressÃ£o confiÃ¡vel
            print(f"âš ï¸  Fractal Dimension: Dados insuficientes apÃ³s filtragem (n={len(pk_filtered)}, threshold={threshold:.2e})")
            return 1.0  # MÃ­nimo fÃ­sico: Euclidiano (linha suave, sem complexidade fractal)

        # TransformaÃ§Ã£o log-log para regressÃ£o linear
        # P(k) ~ k^(-Î²) â†’ log(P(k)) = -Î²Â·log(k) + c
        log_k = torch.log(k_filtered)
        log_pk = torch.log(pk_filtered)

        # RegressÃ£o linear via mÃ­nimos quadrados
        # slope = Î£[(x-xÌ„)(y-È³)] / Î£[(x-xÌ„)Â²]
        mean_log_k = log_k.mean()
        mean_log_pk = log_pk.mean()

        numerator = torch.sum((log_k - mean_log_k) * (log_pk - mean_log_pk))
        denominator = torch.sum((log_k - mean_log_k) ** 2)

        slope = numerator / (denominator + 1e-10)
        beta = -slope.item()  # Î² Ã© o negativo da inclinaÃ§Ã£o

        # Calcular dimensÃ£o fractal: D = (3 - Î²) / 2
        D = (3.0 - beta) / 2.0

        # Clamp para valores fisicamente razoÃ¡veis para sinais 1D
        # D âˆˆ [1.0, 2.0]: 1.0=linha suave, 1.5=browniano, 2.0=muito irregular
        D_clamped = max(1.0, min(2.0, D))

        # Calcular RÂ² (qualidade do ajuste)
        residuals = log_pk - (slope * log_k + (mean_log_pk - slope * mean_log_k))
        ss_res = torch.sum(residuals ** 2)
        ss_tot = torch.sum((log_pk - mean_log_pk) ** 2)
        r_squared = 1.0 - (ss_res / (ss_tot + 1e-10))
        r_squared_value = max(0.0, min(1.0, r_squared.item()))  # Clamp [0, 1]

        # Armazenar dados da lei de potÃªncia para acesso posterior
        self.last_beta_exponent = beta
        self.last_r_squared = r_squared_value
        self.last_points_used = len(pk_filtered)
        self.last_fractal_dimension_raw = D

        if self.log_component_details:
            print(f"âœ… DimensÃ£o Fractal calculada via lei de potÃªncia:")
            print(f"   Î² (expoente) = {beta:.4f}")
            print(f"   D = (3-Î²)/2 = {D:.4f} â†’ clamped = {D_clamped:.4f}")
            print(f"   RÂ² = {r_squared_value:.4f} (qualidade do ajuste)")
            print(f"   Dados usados: {len(pk_filtered)} pontos (de {len(pk_flat)} totais)")

        return D_clamped

    def _compute_d_eeg(
        self,
        psi_distribution: torch.Tensor,
        fractal_field: torch.Tensor
    ) -> float:
        """
        Computa D_EEG - dimensÃ£o fractal equivalente ao EEG.

        Baseado na complexidade da distribuiÃ§Ã£o de consciÃªncia.

        Args:
            psi_distribution: DistribuiÃ§Ã£o P(Ïˆ)
            fractal_field: Campo F(Ïˆ)

        Returns:
            Valor D_EEG
        """
        # Calcular entropia da distribuiÃ§Ã£o como proxy para complexidade EEG
        psi_safe = torch.clamp(psi_distribution, min=1e-10)
        log_psi = torch.log(psi_safe)
        entropy = -torch.sum(psi_distribution * log_psi, dim=-1).mean()

        # Calcular variaÃ§Ã£o espacial como indicador de atividade neural
        spatial_variation = torch.std(psi_distribution, dim=-1).mean()

        # Combinar mÃ©tricas para D_EEG com limites razoÃ¡veis
        d_eeg = (entropy * spatial_variation).item()

        # Limitar D_EEG a valores positivos e razoÃ¡veis
        d_eeg = max(0.0, min(d_eeg, 100.0))

        return d_eeg

    def _compute_h_fmri(
        self,
        psi_distribution: torch.Tensor,
        fractal_field: torch.Tensor,
        fractal_dimension_D: float
    ) -> float:
        """
        Computa H_fMRI - hemodinÃ¢mica funcional equivalente.

        FASE 3: Agora usa dimensÃ£o fractal D em vez de correlaÃ§Ã£o fixa.
        Conforme paper Î¨QRH: H_fMRI deve refletir a complexidade do sinal via D.

        Args:
            psi_distribution: DistribuiÃ§Ã£o P(Ïˆ)
            fractal_field: Campo F(Ïˆ)
            fractal_dimension_D: DimensÃ£o fractal calculada de P(k) via lei de potÃªncia

        Returns:
            Valor H_fMRI
        """
        # Calcular "fluxo" baseado na magnitude do campo
        field_magnitude = torch.norm(fractal_field, dim=-1).mean()

        # NOVO: Usar dimensÃ£o fractal D em vez de correlaÃ§Ã£o fixa
        # D âˆˆ [1.0, 2.0], normalizar para [0, 1] para uso como fator modulador
        D_normalized = (fractal_dimension_D - 1.0) / 1.0  # (D - min) / (max - min)

        # H_fMRI como produto de magnitude de campo e complexidade fractal
        h_fmri = (field_magnitude * D_normalized).item()

        if self.log_component_details:
            print(f"   H_fMRI Debug (ACOPLADO A D):")
            print(f"      field_mag={field_magnitude.item():.6f}")
            print(f"      D={fractal_dimension_D:.4f} â†’ D_norm={D_normalized:.4f}")
            print(f"      H_fMRI = {h_fmri:.6f}")

        return h_fmri

    def _compute_clz(
        self,
        psi_distribution: torch.Tensor,
        fractal_field: torch.Tensor
    ) -> float:
        """
        Computa CLZ - complexidade de Lempel-Ziv equivalente.

        Baseado na compressibilidade da sequÃªncia de estados.

        Args:
            psi_distribution: DistribuiÃ§Ã£o P(Ïˆ)
            fractal_field: Campo F(Ïˆ)

        Returns:
            Valor CLZ
        """
        # Discretizar distribuiÃ§Ã£o para anÃ¡lise de compressibilidade
        psi_discrete = self._discretize_distribution(psi_distribution)

        # Calcular entropia condicional como proxy para CLZ
        conditional_entropy = self._compute_conditional_entropy(psi_discrete)

        # Combinar com complexidade do campo
        field_complexity = torch.std(fractal_field).item()

        # CLZ como combinaÃ§Ã£o de entropia condicional e complexidade
        clz = conditional_entropy + field_complexity

        return clz

    def _discretize_distribution(self, psi_distribution: torch.Tensor) -> torch.Tensor:
        """Discretiza distribuiÃ§Ã£o para anÃ¡lise de compressibilidade."""
        # Quantizar em 8 nÃ­veis
        quantized = torch.floor(psi_distribution * 8).clamp(0, 7)
        return quantized.long()

    def _compute_conditional_entropy(self, discrete_sequence: torch.Tensor) -> float:
        """Computa entropia condicional da sequÃªncia discreta."""
        batch_size, seq_len = discrete_sequence.shape

        # Calcular frequÃªncias de pares consecutivos
        pair_counts = {}
        total_pairs = 0

        for b in range(batch_size):
            for i in range(seq_len - 1):
                curr = discrete_sequence[b, i].item()
                next_val = discrete_sequence[b, i + 1].item()
                pair = (curr, next_val)

                pair_counts[pair] = pair_counts.get(pair, 0) + 1
                total_pairs += 1

        # Calcular entropia condicional
        conditional_entropy = 0.0
        for pair, count in pair_counts.items():
            prob = count / total_pairs
            conditional_entropy -= prob * np.log2(prob)

        return conditional_entropy

    def _compute_spatial_correlation(self, field: torch.Tensor) -> torch.Tensor:
        """
        Computa correlaÃ§Ã£o espacial do campo.

        MÃ©todo configurÃ¡vel via correlation_method no config.
        """
        if self.correlation_method == "autocorrelation":
            # AutocorrelaÃ§Ã£o lag-1
            field_flat = field.reshape(-1)
            field_normalized = (field_flat - field_flat.mean()) / field_flat.std()
            corr = torch.mean(field_normalized[:-1] * field_normalized[1:])

        elif self.correlation_method == "variance_proxy":
            # VariÃ¢ncia como proxy de correlaÃ§Ã£o
            corr = torch.var(field)

        else:  # corrcoef
            # CorrelaÃ§Ã£o via corrcoef
            batch_size, embed_dim = field.shape
            correlations = []
            for i in range(embed_dim - 1):
                corr_matrix = torch.corrcoef(torch.stack([field[:, i], field[:, i + 1]]))
                correlations.append(corr_matrix[0, 1])
            corr = torch.stack(correlations).mean()

        if self.correlation_use_abs:
            corr = torch.abs(corr)

        return corr.clamp(self.correlation_clamp[0], self.correlation_clamp[1])

    def compute_fci_from_fractal_dimension(self, fractal_dimension: float) -> float:
        """
        Mapeia dimensÃ£o fractal diretamente para FCI.

        FÃ³rmula corrigida: FCI = (D - D_min) / (D_max - D_min)
        Onde D âˆˆ [1, 3]:
        - D = 1.0 â†’ FCI = 0.0 (linha suave, sem complexidade)
        - D = 1.7 â†’ FCI = 0.35 (movimento browniano)
        - D = 2.0 â†’ FCI = 0.5 (browniano padrÃ£o)
        - D = 3.0 â†’ FCI = 1.0 (preenchimento total do espaÃ§o)

        Args:
            fractal_dimension: DimensÃ£o fractal D

        Returns:
            FCI âˆˆ [0, 1]
        """
        fci = (fractal_dimension - self.fractal_dimension_min) / self.fractal_dimension_normalizer

        if self.log_fci_calculations:
            print(f"ğŸ”¬ FCI Calculation: D={fractal_dimension:.3f} â†’ FCI={fci:.3f}")

        return max(0.0, min(1.0, fci))

    def _compute_measurement_confidence(
        self,
        d_eeg: float,
        h_fmri: float,
        clz: float
    ) -> float:
        """
        Computa confianÃ§a da mediÃ§Ã£o baseada na consistÃªncia dos componentes.

        Args:
            d_eeg: Componente D_EEG
            h_fmri: Componente H_fMRI
            clz: Componente CLZ

        Returns:
            ConfianÃ§a [0, 1]
        """
        # Normalizar componentes
        components = np.array([
            d_eeg / self.d_eeg_max,
            h_fmri / self.h_fmri_max,
            clz / self.clz_max
        ])

        # Calcular coeficiente de variaÃ§Ã£o
        mean_component = np.mean(components)
        std_component = np.std(components)
        cv = std_component / mean_component

        # Mapear coeficiente de variaÃ§Ã£o para confianÃ§a
        # Baixa variaÃ§Ã£o â†’ alta confianÃ§a
        confidence = np.exp(-2 * cv)

        return np.clip(confidence, 0.0, 1.0)

    def _classify_fci_state(self, fci_value: float) -> str:
        """
        Classifica estado baseado no valor FCI usando thresholds configurÃ¡veis.

        Args:
            fci_value: Valor do FCI

        Returns:
            Nome do estado classificado
        """
        if fci_value >= self.threshold_emergence:
            return "EMERGENCE"
        elif fci_value >= self.threshold_meditation:
            return "MEDITATION"
        elif fci_value >= self.threshold_analysis:
            return "ANALYSIS"
        else:
            return "COMA"

    def _update_fci_history(self, fci_object: FCI):
        """Atualiza histÃ³rico de mediÃ§Ãµes FCI."""
        self.fci_history.append(fci_object)

        # Manter tamanho mÃ¡ximo
        if len(self.fci_history) > self.max_history:
            self.fci_history.pop(0)

    def get_consciousness_evolution(self, window_size: int = 50) -> Dict[str, Any]:
        """
        Analisa evoluÃ§Ã£o da consciÃªncia ao longo do tempo.

        Args:
            window_size: Tamanho da janela para anÃ¡lise

        Returns:
            AnÃ¡lise da evoluÃ§Ã£o temporal
        """
        if len(self.fci_history) < 2:
            return {'status': 'insufficient_data'}

        # Pegar janela recente
        recent_history = self.fci_history[-window_size:]
        fci_values = [fci.value for fci in recent_history]

        # EstatÃ­sticas bÃ¡sicas
        mean_fci = np.mean(fci_values)
        std_fci = np.std(fci_values)
        trend = self._compute_trend(fci_values)

        # DistribuiÃ§Ã£o de estados
        state_counts = {}
        for fci in recent_history:
            state = fci.state_classification
            state_counts[state] = state_counts.get(state, 0) + 1

        # Estabilidade (inverso da variaÃ§Ã£o)
        stability = 1.0 / (1.0 + std_fci)

        # Qualidade das mediÃ§Ãµes (confianÃ§a mÃ©dia)
        avg_confidence = np.mean([fci.confidence for fci in recent_history])

        evolution = {
            'status': 'analyzed',
            'window_size': len(recent_history),
            'fci_statistics': {
                'mean': mean_fci,
                'std': std_fci,
                'min': min(fci_values),
                'max': max(fci_values),
                'trend': trend
            },
            'state_distribution': state_counts,
            'stability': stability,
            'measurement_quality': avg_confidence,
            'predominant_state': max(state_counts, key=state_counts.get) if state_counts else 'UNDEFINED'
        }

        return evolution

    def _compute_trend(self, values: List[float]) -> float:
        """Computa tendÃªncia temporal usando regressÃ£o linear simples."""
        if len(values) < 3:
            return 0.0

        x = np.arange(len(values))
        y = np.array(values)

        # RegressÃ£o linear: y = ax + b
        n = len(x)
        sum_x = np.sum(x)
        sum_y = np.sum(y)
        sum_xy = np.sum(x * y)
        sum_x2 = np.sum(x**2)

        denominator = n * sum_x2 - sum_x**2
        if denominator == 0:
            return 0.0

        trend = (n * sum_xy - sum_x * sum_y) / denominator
        return trend

    def generate_consciousness_report(self) -> str:
        """
        Gera relatÃ³rio detalhado da consciÃªncia atual.

        Returns:
            RelatÃ³rio textual formatado
        """
        if not self.fci_history:
            return "ğŸ“Š Nenhuma mediÃ§Ã£o de consciÃªncia disponÃ­vel."

        latest_fci = self.fci_history[-1]
        evolution = self.get_consciousness_evolution()

        report = f"""
ğŸ“Š RELATÃ“RIO DE CONSCIÃŠNCIA FRACTAL
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ§  MEDIÃ‡ÃƒO ATUAL:
FCI: {latest_fci.value:.4f} ({latest_fci.state_classification})
ConfianÃ§a: {latest_fci.confidence:.3f}

ğŸ“ˆ COMPONENTES FCI:
D_EEG: {latest_fci.components['D_EEG']:.3f} (norm: {latest_fci.components['D_EEG_normalized']:.3f})
H_fMRI: {latest_fci.components['H_fMRI']:.3f} (norm: {latest_fci.components['H_fMRI_normalized']:.3f})
CLZ: {latest_fci.components['CLZ']:.3f} (norm: {latest_fci.components['CLZ_normalized']:.3f})

â±ï¸ EVOLUÃ‡ÃƒO TEMPORAL:
MediÃ§Ãµes analisadas: {evolution.get('window_size', 0)}
FCI mÃ©dio: {evolution.get('fci_statistics', {}).get('mean', 0):.4f}
Estabilidade: {evolution.get('stability', 0):.3f}
TendÃªncia: {evolution.get('fci_statistics', {}).get('trend', 0):+.4f}
Estado predominante: {evolution.get('predominant_state', 'N/A')}

ğŸ¯ INTERPRETAÃ‡ÃƒO:
{self._interpret_fci_level(latest_fci.value)}

Qualidade da mediÃ§Ã£o: {evolution.get('measurement_quality', 0):.3f}
        """

        return report.strip()

    def _interpret_fci_level(self, fci_value: float) -> str:
        """Interpreta nÃ­vel de FCI em termos prÃ¡ticos."""
        if fci_value >= 0.9:
            return "ConsciÃªncia emergente excepcional - mÃ¡xima criatividade e insight"
        elif fci_value >= 0.8:
            return "Alto nÃ­vel de consciÃªncia - estado emergente ativo"
        elif fci_value >= 0.7:
            return "ConsciÃªncia meditativa profunda - anÃ¡lise introspectiva"
        elif fci_value >= 0.5:
            return "Estado analÃ­tico equilibrado - processamento lÃ³gico"
        elif fci_value >= 0.3:
            return "ConsciÃªncia analÃ­tica bÃ¡sica - foco em tarefas"
        elif fci_value >= 0.1:
            return "Baixa consciÃªncia - processamento mÃ­nimo"
        else:
            return "Estado comatoso - atividade consciente quase ausente"

    def reset_metrics(self):
        """Reseta todas as mÃ©tricas e histÃ³rico."""
        self.fci_history.clear()
        print("ğŸ“Š MÃ©tricas de consciÃªncia resetadas")