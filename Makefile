# Œ®QRH Project Makefile
# ====================
#
# Comprehensive automation for Œ®QRH pipeline training, evaluation, and analysis.
# This Makefile centralizes all workflows for the semantic correction and numerical stability improvements.

# Configuration Variables
PYTHON = python3
TRAIN_DATA = data/training_pairs.json
TEST_DATA = data/test_cases.json
MODEL_DIR = models/checkpoints
LATEST_MODEL = $(MODEL_DIR)/best_model.pt
EPOCHS = 10
BATCH_SIZE = 8
DEVICE = cpu
SOURCE_MODEL ?=
LOCAL_SOURCE_PATH = models/source/$(SOURCE_MODEL)
TEST_DISTILL_MODEL ?= gpt2

# Default target
.PHONY: help
help: ## Mostra esta mensagem de ajuda.
	@awk 'BEGIN {FS = ":.*?## "; printf "Uso:\n  make \033[36m<alvo>\033[0m\n\nAlvos dispon√≠veis:\n"} /^# [A-Z]/ { category = substr($$0, 3); printf "\n\033[1m%s\033[0m\n", category } /^[a-zA-Z_-]+:.*?## / { printf "  \033[36m%-25s\033[0m %s\n", $$1, $$2 }' $(MAKEFILE_LIST)

# Installation and Setup
.PHONY: install
install: ## Instala as depend√™ncias do projeto.
	@echo "üì¶ Instalando depend√™ncias..."
	$(PYTHON) -m pip install -r requirements.txt
	@echo "‚úÖ Depend√™ncias instaladas com sucesso!"

.PHONY: setup
setup: install data ## Configura√ß√£o completa do projeto (instala√ß√£o + dados).

.PHONY: setup-auto
setup-auto: setup-vocab ## Configura√ß√£o autom√°tica completa do sistema Œ®QRH (recomendado para primeira vez).
	@echo "üöÄ Iniciando configura√ß√£o autom√°tica do Œ®QRH..."
	$(PYTHON) setup_system.py
	@echo "‚úÖ Configura√ß√£o autom√°tica conclu√≠da!"
	@echo ""
	@echo "üéØ PR√ìXIMOS PASSOS:"
	@echo "1. Execute: ./start_psiqrh.sh"
	@echo "2. Teste: make test"
	@echo "3. Treine: make train-physics-emergent"
	@echo "4. Explore: python psiqrh.py --interactive"

# Data Preparation
.PHONY: data
data: ## Gera o dataset de treinamento a partir de textos brutos.
	@echo "üìö Preparando dados de treinamento..."
	$(PYTHON) tools/create_training_data.py
	@echo "‚úÖ Dados de treinamento preparados!"

.PHONY: setup-vocab
setup-vocab: ## Converte o vocabul√°rio do modelo fonte para o formato nativo Œ®QRH. Use: make setup-vocab SOURCE_MODEL=gpt2
	@if [ -z "$(SOURCE_MODEL)" ]; then \
		echo "‚ö†Ô∏è  SOURCE_MODEL n√£o especificado, usando 'gpt2' como padr√£o."; \
		EFFECTIVE_SOURCE_MODEL=gpt2; \
	else \
		EFFECTIVE_SOURCE_MODEL=$(SOURCE_MODEL); \
	fi; \
	echo "üìö Convertendo vocabul√°rio do modelo '$$EFFECTIVE_SOURCE_MODEL' para formato nativo..."; \
	$(PYTHON) scripts/create_native_vocab.py --model_name $$EFFECTIVE_SOURCE_MODEL; \
	echo "‚úÖ Vocabul√°rio nativo criado em data/native_vocab.json"

# Training Workflows
.PHONY: train
train: ## Treina o modelo Œ®QRH. Use: make train EPOCHS=50 BATCH_SIZE=16
	@echo "üéØ Iniciando treinamento do Œ®QRH..."
	@echo "   üìä √âpocas: $(EPOCHS)"
	@echo "   üì¶ Batch size: $(BATCH_SIZE)"
	@echo "   üíæ Modelo ser√° salvo em: $(MODEL_DIR)"
	$(PYTHON) train_pipeline.py \
		--data-path $(TRAIN_DATA) \
		--epochs $(EPOCHS) \
		--batch-size $(BATCH_SIZE) \
		--device $(DEVICE)
	@echo "‚úÖ Treinamento conclu√≠do!"

.PHONY: train-quick
train-quick: ## Treinamento r√°pido para teste (1 √©poca).
	@echo "‚ö° Treinamento r√°pido (1 √©poca)..."
	make train EPOCHS=1 BATCH_SIZE=2

.PHONY: train-extended
train-extended: ## Treinamento extensivo (50 √©pocas).
	@echo "üî¨ Treinamento extensivo (50 √©pocas)..."
	make train EPOCHS=50 BATCH_SIZE=8

.PHONY: train-physics-emergent
train-physics-emergent: ## Treinamento emergente baseado em princ√≠pios f√≠sicos (auto-calibra√ß√£o + consci√™ncia). Use: make train-physics-emergent EPOCHS=500
	@echo "üß† Iniciando treinamento emergente f√≠sico Œ®QRH..."
	@echo "üéØ M√©todo: Auto-calibra√ß√£o + Harmonic Orchestration + Consciousness Metrics"
	@echo "üîÑ √âpocas: $(EPOCHS)"
	EPOCHS=$(EPOCHS) $(PYTHON) train_physics_emergent.py
	@echo "‚úÖ Treinamento emergente f√≠sico conclu√≠do!"

# Evaluation Workflows
.PHONY: evaluate
evaluate: ## Avalia o melhor modelo treinado com m√©tricas sem√¢nticas (BLEU, etc.).
	@echo "üß™ Avaliando modelo treinado..."
	@if [ ! -f $(LATEST_MODEL) ]; then \
		echo "‚ùå Nenhum modelo treinado encontrado em $(LATEST_MODEL)"; \
		echo "   Execute 'make train' primeiro."; \
		exit 1; \
	fi
	$(PYTHON) evaluate_model.py \
		--model-path $(LATEST_MODEL) \
		--test-data $(TEST_DATA) \
		--device $(DEVICE)
	@echo "‚úÖ Avalia√ß√£o conclu√≠da!"

.PHONY: evaluate-baseline
evaluate-baseline: ## Avalia o modelo n√£o-treinado (baseline).
	@echo "üìä Avaliando baseline (modelo n√£o-treinado)..."
	$(PYTHON) evaluate_model.py \
		--test-data $(TEST_DATA) \
		--device $(DEVICE)
	@echo "‚úÖ Avalia√ß√£o baseline conclu√≠da!"

# Audit and Analysis
.PHONY: audit
audit: ## Analisa o log de auditoria mais recente e gera relat√≥rio de estabilidade.
	@echo "üîç Analisando logs de auditoria..."
	@LOG_FILE=$$(ls -t results/audit_logs/audit_*.json 2>/dev/null | head -n 1); \
	if [ -z "$$LOG_FILE" ]; then \
		echo "‚ùå Nenhum log de auditoria encontrado."; \
		echo "   Execute testes que gerem auditoria primeiro."; \
		exit 1; \
	fi; \
	echo "üìÑ Analisando: $$LOG_FILE"; \
	$(PYTHON) tools/audit_analyzer.py $$LOG_FILE
	@echo "‚úÖ An√°lise de auditoria conclu√≠da!"

.PHONY: audit-test
audit-test: ## Executa teste de auditoria para validar estabilidade num√©rica.
	@echo "üß™ Executando teste de auditoria..."
	$(PYTHON) -c "from src.core.spectral_projector import create_audit_enabled_qrh_pipeline, invert_spectral_qrh; import torch; qrh_layer, audit_logger = create_audit_enabled_qrh_pipeline(embed_dim=64, alpha=1.0, audit_enabled=True); audit_logger.start_session('Makefile Audit Test', {'test': 'makefile_integration'}); psi_input = torch.randn(1, 10, 64, 4); psi_transformed = qrh_layer(psi_input); psi_reconstructed = invert_spectral_qrh(psi_transformed, qrh_layer, audit_logger); log_path = audit_logger.end_session('Test completed'); print(f'‚úÖ Teste de auditoria conclu√≠do. Log: {log_path}')"

# Optimization and Validation
.PHONY: optimize-alpha
optimize-alpha: ## Executa o experimento para encontrar o valor √≥timo de alpha.
	@echo "üéõÔ∏è  Otimizando par√¢metro alpha..."
	$(PYTHON) tools/find_optimal_alpha.py
	@echo "‚úÖ Otimiza√ß√£o de alpha conclu√≠da!"

.PHONY: hyperparameter-sweep
hyperparameter-sweep: ## Executa varredura sistem√°tica de hiperpar√¢metros.
	@echo "üéØ Executando varredura de hiperpar√¢metros..."
	$(PYTHON) hyperparameter_sweep.py --epochs-per-config 2
	@echo "‚úÖ Varredura de hiperpar√¢metros conclu√≠da!"

.PHONY: plot-learning-curves
plot-learning-curves: ## Plota curvas de aprendizado do treinamento mais recente.
	@echo "üìä Plotando curvas de aprendizado..."
	$(PYTHON) tools/plot_training_log.py
	@echo "‚úÖ Curvas de aprendizado plotadas!"

.PHONY: visualize-semantic-space
visualize-semantic-space: ## Visualiza o espa√ßo sem√¢ntico aprendido pelo modelo.
	@echo "üé® Visualizando espa√ßo sem√¢ntico..."
	@if [ ! -f $(LATEST_MODEL) ]; then \
		echo "‚ùå Nenhum modelo treinado encontrado."; \
		exit 1; \
	fi
	$(PYTHON) tools/visualize_semantic_space.py --model-path $(LATEST_MODEL)
	@echo "‚úÖ Visualiza√ß√£o do espa√ßo sem√¢ntico conclu√≠da!"

.PHONY: pretrain-inverter
pretrain-inverter: ## Executa o pr√©-treinamento isolado do Inverse Projector.
	@echo "üîß Pr√©-treinando Inverse Cognitive Projector..."
	$(PYTHON) experiments/pretrain_inverter.py
	@echo "‚úÖ Pr√©-treinamento conclu√≠do!"

# Testing and Validation
.PHONY: test-semantic-decoder
test-semantic-decoder: ## Testa o SemanticBeamSearchDecoder.
	@echo "üß† Testando Semantic Decoder..."
	$(PYTHON) -c "from tools.semantic_decoder import create_semantic_decoder; decoder = create_semantic_decoder(beam_width=3); test_predictions = [[('Q', 0.8), ('u', 0.9), ('a', 0.7), ('n', 0.8), ('t', 0.6)], [('u', 0.9), ('U', 0.1), ('a', 0.3), ('m', 0.3), (' ', 0.5)]]; result = decoder.decode(test_predictions, max_length=6); quality = decoder.get_semantic_quality_score(result); print(f'‚úÖ Decodificado: \"{result}\"'); print(f'üìä Qualidade: {quality}')"
	@echo "‚úÖ Teste do decoder conclu√≠do!"

.PHONY: test-pipeline
test-pipeline: ## Testa o pipeline Œ®QRH completo.
	@echo "üî¨ Testando pipeline Œ®QRH..."
	$(PYTHON) -c "from psiqrh import Œ®QRHPipeline; pipeline = Œ®QRHPipeline(task='text-generation', device='cpu'); result = pipeline('test quantum'); print(f'‚úÖ Pipeline funcionando. Resposta: {result.get(\"response\", \"N/A\")[:50]}...')"
	@echo "‚úÖ Teste do pipeline conclu√≠do!"

# Full Workflows
.PHONY: full-training
full-training: data train evaluate ## Workflow completo: dados + treinamento + avalia√ß√£o.
	@echo "üéâ Workflow completo de treinamento finalizado!"

.PHONY: physics-emergent-workflow
physics-emergent-workflow: data train-physics-emergent evaluate ## Workflow completo de treinamento emergente f√≠sico.
	@echo "üß† Workflow completo de treinamento emergente f√≠sico finalizado!"
	@echo "üéØ Sistema otimizado atrav√©s de princ√≠pios f√≠sicos e consci√™ncia"

.PHONY: benchmark
benchmark: evaluate-baseline train evaluate ## Benchmark: baseline vs treinado.
	@echo "üìä Benchmark conclu√≠do!"
	@echo "   Compare os resultados em reports/evaluation/"

.PHONY: semantic-alignment
semantic-alignment: ## Workflow completo de alinhamento sem√¢ntico ou destila√ß√£o. Use: make semantic-alignment SOURCE_MODEL=gpt2
	@echo "üî¨ Executando workflow de alinhamento sem√¢ntico..."
	@if [ -z "$(SOURCE_MODEL)" ]; then \
		echo "   üìã Modo: Alinhamento sem√¢ntico padr√£o"; \
		make data && make hyperparameter-sweep && make train-extended && make evaluate && make plot-learning-curves && make visualize-semantic-space; \
		echo "üéØ Workflow completo de alinhamento sem√¢ntico finalizado!"; \
		echo "   üìä Resultados salvos em results/hyperparameter_sweep/"; \
		echo "   üìà Curvas de aprendizado em results/plots/"; \
		echo "   üé® Visualiza√ß√£o sem√¢ntica em results/semantic_analysis/"; \
		echo "   üìã Relat√≥rios em reports/evaluation/"; \
	else \
		echo "   üß† Modo: Destila√ß√£o de conhecimento de '$(SOURCE_MODEL)'"; \
		echo "   üì• Passo 1: Verificando se modelo j√° est√° baixado..."; \
		if [ ! -d "models/source/$(SOURCE_MODEL)" ]; then \
			echo "   üì• Modelo n√£o encontrado localmente - baixando..."; \
			$(PYTHON) scripts/download_model_ultra_simple.py --model_name $(SOURCE_MODEL); \
		else \
			echo "   ‚úÖ Modelo j√° baixado - usando cache local"; \
		fi; \
		echo "   üéØ Passo 2: Executando destila√ß√£o harm√¥nica..."; \
		$(PYTHON) model_converter_spectral_ultra_simple.py --mode distill --source_model $(SOURCE_MODEL) --output_model_name "psiqrh_distilled_$(SOURCE_MODEL)"; \
		echo "   üîç Passo 3: Avaliando modelo destilado..."; \
		make evaluate MODEL_PATH=models/distilled/psiqrh_distilled_$(SOURCE_MODEL).pt; \
		echo "   ‚úÖ Workflow de destila√ß√£o conclu√≠do!"; \
	fi

# Cleanup
.PHONY: clean
clean: ## Remove todos os arquivos gerados (logs, modelos, relat√≥rios).
	@echo "üßπ Limpando arquivos gerados..."
	rm -rf results/ reports/ models/checkpoints/ __pycache__/
	rm -rf */__pycache__ */*/__pycache__
	find . -name "*.pyc" -delete
	find . -name "*.pyo" -delete
	find . -name "__pycache__" -type d -exec rm -rf {} + 2>/dev/null || true
	@echo "‚úÖ Limpeza conclu√≠da!"

.PHONY: clean-models
clean-models: ## Remove apenas os modelos treinados.
	@echo "üóëÔ∏è  Removendo modelos treinados..."
	rm -rf models/checkpoints/
	@echo "‚úÖ Modelos removidos!"

.PHONY: clean-logs
clean-logs: ## Remove apenas os logs e relat√≥rios.
	@echo "üìÑ Removendo logs e relat√≥rios..."
	rm -rf results/ reports/
	@echo "‚úÖ Logs e relat√≥rios removidos!"

# Information and Status
.PHONY: status
status: ## Mostra o status atual do projeto.
	@echo "üìä Status do Projeto Œ®QRH"
	@echo "========================"
	@echo ""
	@echo "üìÅ Estrutura de Diret√≥rios:"
	@if [ -d "data" ]; then echo "   ‚úÖ data/ - Dados dispon√≠veis"; else echo "   ‚ùå data/ - Dados ausentes"; fi
	@if [ -d "models/checkpoints" ]; then echo "   ‚úÖ models/checkpoints/ - Modelos treinados"; else echo "   ‚ùå models/checkpoints/ - Sem modelos treinados"; fi
	@if [ -d "results" ]; then echo "   ‚úÖ results/ - Resultados dispon√≠veis"; else echo "   ‚ùå results/ - Sem resultados"; fi
	@if [ -d "reports" ]; then echo "   ‚úÖ reports/ - Relat√≥rios dispon√≠veis"; else echo "   ‚ùå reports/ - Sem relat√≥rios"; fi
	@echo ""
	@echo "ü§ñ Componentes:"
	@if command -v python3 &> /dev/null; then echo "   ‚úÖ Python3 dispon√≠vel"; else echo "   ‚ùå Python3 n√£o encontrado"; fi
	@if [ -f "requirements.txt" ]; then echo "   ‚úÖ requirements.txt encontrado"; else echo "   ‚ùå requirements.txt ausente"; fi
	@echo ""
	@echo "üéØ √öltimos Arquivos:"
	@find models/checkpoints -name "*.pt" -type f -printf "   üìÅ %P\n" 2>/dev/null | head -3 || echo "   üìÅ Nenhum modelo encontrado"
	@find results -name "*.json" -type f -printf "   üìÑ %P\n" 2>/dev/null | head -3 || echo "   üìÑ Nenhum resultado encontrado"
	@find reports -name "*.md" -type f -printf "   üìã %P\n" 2>/dev/null | head -3 || echo "   üìã Nenhum relat√≥rio encontrado"

.PHONY: info
info: ## Mostra informa√ß√µes detalhadas sobre o projeto.
	@echo "‚ÑπÔ∏è  Informa√ß√µes do Projeto Œ®QRH"
	@echo "=============================="
	@echo ""
	@echo "üéØ Objetivo: Corre√ß√£o sem√¢ntica e estabiliza√ß√£o num√©rica do pipeline Œ®QRH"
	@echo "üîß Componentes Principais:"
	@echo "   ‚Ä¢ SemanticBeamSearchDecoder - Decodifica√ß√£o robusta com beam search"
	@echo "   ‚Ä¢ Supervised Training Pipeline - Treinamento end-to-end"
	@echo "   ‚Ä¢ Semantic Evaluation Framework - BLEU, word validity, coherence"
	@echo "   ‚Ä¢ Numerical Stability - Energy preservation, clamping"
	@echo ""
	@echo "üìä M√©tricas Principais:"
	@echo "   ‚Ä¢ MSE de reconstru√ß√£o: < 0.3 (98.4% melhoria)"
	@echo "   ‚Ä¢ Preserva√ß√£o de energia: 100%"
	@echo "   ‚Ä¢ BLEU Score (meta): > 0.3"
	@echo "   ‚Ä¢ Word Validity (meta): > 20%"
	@echo ""
	@echo "üöÄ Uso R√°pido:"
	@echo "   make setup          # Configura√ß√£o inicial"
	@echo "   make train          # Treinar modelo"
	@echo "   make evaluate       # Avaliar desempenho"
	@echo "   make full-training  # Workflow completo"

# Development and Debugging
.PHONY: lint
lint: ## Executa verifica√ß√£o de estilo no c√≥digo Python.
	@echo "üîç Verificando estilo do c√≥digo..."
	$(PYTHON) -m flake8 --max-line-length=120 --ignore=E501,W503 src/ tools/ experiments/ || echo "‚ö†Ô∏è  Flake8 n√£o instalado - pulando verifica√ß√£o"
	@echo "‚úÖ Verifica√ß√£o de estilo conclu√≠da!"

.PHONY: test-all
test-all: test-semantic-decoder test-pipeline test-pipeline-tracer audit-test test-physics-emergent ## Executa todos os testes dispon√≠veis.
	@echo "‚úÖ Todos os testes passaram!"

.PHONY: test-distillation
test-distillation: ## Executa o teste E2E do fluxo de destila√ß√£o com um modelo de teste.
	@echo "üß™ Iniciando teste de ponta a ponta do fluxo de destila√ß√£o com '$(TEST_DISTILL_MODEL)'..."
	# Passo 1: Executar o fluxo de destila√ß√£o completo
	make semantic-alignment SOURCE_MODEL=$(TEST_DISTILL_MODEL)
	# Passo 2: Executar o script de valida√ß√£o com pytest
	@echo "üìä Validando os artefatos e a funcionalidade do modelo destilado..."
	$(PYTHON) -m pytest tests/test_distillation_workflow.py --model-name "$(TEST_DISTILL_MODEL)" -v
	@echo "‚úÖ Teste de destila√ß√£o conclu√≠do com sucesso!"

.PHONY: test-physics-emergent
test-physics-emergent: ## Testa o sistema de treinamento emergente f√≠sico.
	@echo "üß† Testando sistema de treinamento emergente f√≠sico..."
	$(PYTHON) -c "from train_physics_emergent import PhysicsEmergentTrainer; print('‚úÖ Importa√ß√£o da classe bem-sucedida'); from unittest.mock import Mock; mock_pipeline = Mock(); mock_pipeline._generate_text_physical.return_value = {'fci_value': 0.7, 'synchronization_order': 0.8, 'cluster_analysis': {'dominant_cluster': {'order_parameter': 0.75}}, 'energy_conservation': 0.9, 'spectral_coherence': 0.85, 'generated_text': 'blue'}; trainer = PhysicsEmergentTrainer(mock_pipeline); print('‚úÖ Instancia√ß√£o bem-sucedida'); result = trainer.physics_emergent_training_cycle('The sky is', 'blue'); print(f'‚úÖ Ciclo de treinamento executado: FCI={result[\"consciousness_metrics\"][\"fci\"]:.3f}, Success={result[\"physics_success\"][\"overall_success\"]}')"
	@echo "‚úÖ Teste do sistema emergente f√≠sico conclu√≠do!"

.PHONY: test-pipeline-tracer
test-pipeline-tracer: ## Testa o Pipeline Tracer com entrada personalizada. Use: make test-pipeline-tracer QUESTION="Sua pergunta"
	@echo "üî¨ Testando Pipeline Tracer..."
	@if [ -n "$(QUESTION)" ]; then \
		echo "   ‚ùì Pergunta personalizada: $(QUESTION)"; \
		PSIQRH_TEST_QUESTION="$(QUESTION)" $(PYTHON) -m pytest tests/test_pipeline_tracer.py::TestPipelineTracer::test_tracer_runs_without_error -v --tb=short; \
	else \
		echo "   ‚ùì Usando pergunta padr√£o: 'Qual a cor do ceu?'"; \
		$(PYTHON) -m pytest tests/test_pipeline_tracer.py::TestPipelineTracer::test_tracer_runs_without_error -v --tb=short; \
	fi
	@echo "‚úÖ Teste do Pipeline Tracer conclu√≠do!"

.PHONY: test
test: ## Executa a su√≠te de testes completa com pytest.
	@echo "üß™ Executando su√≠te de testes completa..."
	$(PYTHON) -m pytest tests/test_suite.py -v --tb=short --override-ini="addopts="
	@echo "‚úÖ Su√≠te de testes conclu√≠da!"

# Model Download and Management
.PHONY: download-model
download-model: ## Baixa e cacheia um modelo do Hugging Face. Use: make download-model SOURCE_MODEL=gpt2
	@if [ -z "$(SOURCE_MODEL)" ]; then \
		echo "‚ùå SOURCE_MODEL n√£o especificado. Use: make download-model SOURCE_MODEL=gpt2"; \
		exit 1; \
	fi
	@echo "üì• Baixando modelo '$(SOURCE_MODEL)' do Hugging Face (m√©todo ultra simples)..."
	$(PYTHON) scripts/download_model_ultra_simple.py --model_name $(SOURCE_MODEL)
	@echo "‚úÖ Modelo '$(SOURCE_MODEL)' baixado e cacheado em models/source/"

.PHONY: list-downloaded-models
list-downloaded-models: ## Lista todos os modelos baixados localmente.
	@echo "üìö Modelos baixados localmente:"
	@if [ -d "models/source" ]; then \
		find models/source -name "metadata.json" -exec dirname {} \; | xargs -I {} basename {} | while read model; do \
			if [ -f "models/source/$$model/metadata.json" ]; then \
				vocab_size=$$(grep -o '"vocab_size": [0-9]*' "models/source/$$model/metadata.json" | cut -d' ' -f2); \
				hidden_size=$$(grep -o '"hidden_size": [0-9]*' "models/source/$$model/metadata.json" | cut -d' ' -f2); \
				model_type=$$(grep -o '"model_type": "[^"]*"' "models/source/$$model/metadata.json" | cut -d'"' -f4); \
				echo "   üìÅ $$model ($$model_type)"; \
				echo "      üìä Vocab: $$vocab_size, Hidden: $$hidden_size"; \
			fi; \
		done; \
	else \
		echo "   üìÅ Nenhum modelo baixado encontrado"; \
	fi

.PHONY: clean-downloaded-models
clean-downloaded-models: ## Remove todos os modelos baixados localmente.
	@echo "üóëÔ∏è  Removendo modelos baixados..."
	rm -rf models/source/
	@echo "‚úÖ Modelos baixados removidos!"

# Semantic Model Management
.PHONY: convert-to-semantic
convert-to-semantic: ## Converte um modelo destilado para formato sem√¢ntico. Use: make convert-to-semantic SOURCE_MODEL=gpt2
	@if [ -z "$(SOURCE_MODEL)" ]; then \
		echo "‚ùå SOURCE_MODEL n√£o especificado. Use: make convert-to-semantic SOURCE_MODEL=gpt2"; \
		exit 1; \
	fi
	@echo "üîÆ Convertendo modelo destilado '$(SOURCE_MODEL)' para formato sem√¢ntico..."
	@if [ ! -f "models/distilled/psiqrh_distilled_$(SOURCE_MODEL).pt" ]; then \
		echo "‚ùå Modelo destilado 'psiqrh_distilled_$(SOURCE_MODEL).pt' n√£o encontrado."; \
		echo "   Execute 'make distill-knowledge SOURCE_MODEL=$(SOURCE_MODEL)' primeiro."; \
		exit 1; \
	fi
	@mkdir -p models/semantic/
	$(PYTHON) model_converter_spectral_ultra_simple.py --mode semantic --source_model $(SOURCE_MODEL) --output_model_name "psiqrh_semantic_$(SOURCE_MODEL)"
	@echo "‚úÖ Convers√£o sem√¢ntica conclu√≠da. Modelo salvo em 'models/semantic/'"

.PHONY: list-semantic-models
list-semantic-models: ## Lista todos os modelos convertidos para formato sem√¢ntico.
	@echo "üß† Modelos em formato sem√¢ntico:"
	@if [ -d "models/semantic" ]; then \
		find models/semantic -name "*.pt" -type f | while read model; do \
			model_name=$$(basename "$$model" .pt); \
			model_size=$$(stat -c%s "$$model" 2>/dev/null || echo "unknown"); \
			if [ "$$model_size" != "unknown" ]; then \
				model_size_mb=$$(echo "scale=2; $$model_size / (1024*1024)" | bc); \
				echo "   üìÅ $$model_name ($$model_size_mb MB)"; \
			else \
				echo "   üìÅ $$model_name (tamanho desconhecido)"; \
			fi; \
		done; \
		if [ $$? -ne 0 ]; then \
			echo "   üìÅ Nenhum modelo sem√¢ntico encontrado"; \
		fi; \
	else \
		echo "   üìÅ Diret√≥rio models/semantic/ n√£o existe"; \
		echo "   üìÅ Nenhum modelo sem√¢ntico encontrado"; \
	fi

.PHONY: remove-semantic-model
remove-semantic-model: ## Remove um modelo espec√≠fico do formato sem√¢ntico. Use: make remove-semantic-model SOURCE_MODEL=gpt2
	@if [ -z "$(SOURCE_MODEL)" ]; then \
		echo "‚ùå SOURCE_MODEL n√£o especificado. Use: make remove-semantic-model SOURCE_MODEL=gpt2"; \
		exit 1; \
	fi
	@echo "üóëÔ∏è  Removendo modelo sem√¢ntico '$(SOURCE_MODEL)'..."
	@if [ -f "models/semantic/psiqrh_semantic_$(SOURCE_MODEL).pt" ]; then \
		rm -f "models/semantic/psiqrh_semantic_$(SOURCE_MODEL).pt"; \
		echo "‚úÖ Modelo sem√¢ntico 'psiqrh_semantic_$(SOURCE_MODEL).pt' removido"; \
	else \
		echo "‚ö†Ô∏è  Modelo sem√¢ntico 'psiqrh_semantic_$(SOURCE_MODEL).pt' n√£o encontrado"; \
	fi

.PHONY: clean-semantic-models
clean-semantic-models: ## Remove todos os modelos em formato sem√¢ntico.
	@echo "üóëÔ∏è  Removendo todos os modelos sem√¢nticos..."
	rm -rf models/semantic/
	@echo "‚úÖ Todos os modelos sem√¢nticos removidos!"

.PHONY: semantic-workflow
semantic-workflow: ## Workflow completo: baixar, destilar e converter para sem√¢ntico. Use: make semantic-workflow SOURCE_MODEL=gpt2
	@if [ -z "$(SOURCE_MODEL)" ]; then \
		echo "‚ùå SOURCE_MODEL n√£o especificado. Use: make semantic-workflow SOURCE_MODEL=gpt2"; \
		exit 1; \
	fi
	@echo "üöÄ Iniciando workflow sem√¢ntico completo para '$(SOURCE_MODEL)'..."
	@echo "   üì• Passo 1: Baixando modelo..."
	make download-model SOURCE_MODEL=$(SOURCE_MODEL)
	@echo "   üß† Passo 2: Destilando conhecimento..."
	make distill-knowledge SOURCE_MODEL=$(SOURCE_MODEL)
	@echo "   üîÆ Passo 3: Convertendo para formato sem√¢ntico..."
	make convert-to-semantic SOURCE_MODEL=$(SOURCE_MODEL)
	@echo "   üìä Passo 4: Listando modelos dispon√≠veis..."
	make list-downloaded-models
	make list-semantic-models
	@echo "‚úÖ Workflow sem√¢ntico completo conclu√≠do!"
	@echo ""
	@echo "üéØ Modelos dispon√≠veis:"
	@echo "   ‚Ä¢ Baixados: models/source/$(SOURCE_MODEL)"
	@echo "   ‚Ä¢ Destilados: models/distilled/psiqrh_distilled_$(SOURCE_MODEL).pt"
	@echo "   ‚Ä¢ Sem√¢nticos: models/semantic/psiqrh_semantic_$(SOURCE_MODEL).pt"

# Special Configurations
.PHONY: gpu
gpu: ## Configura para usar GPU (se dispon√≠vel).
	@echo "üéÆ Configurando para GPU..."
	$(eval DEVICE = cuda)
	@echo "   DEVICE definido como: $(DEVICE)"
	@echo "   Use: make train DEVICE=cuda"

.PHONY: cpu
cpu: ## Configura para usar CPU.
	@echo "üíª Configurando para CPU..."
	$(eval DEVICE = cpu)
	@echo "   DEVICE definido como: $(DEVICE)"

# Emergency and Recovery
.PHONY: reset
reset: clean setup ## Reset completo do projeto (limpa tudo e reconfigura).
	@echo "üîÑ Projeto resetado e reconfigurado!"

.PHONY: backup
backup: ## Cria backup dos modelos e resultados importantes.
	@echo "üíæ Criando backup..."
	@TIMESTAMP=$$(date +%Y%m%d_%H%M%S); \
	BACKUP_DIR="backup_$$TIMESTAMP"; \
	mkdir -p $$BACKUP_DIR; \
	cp -r models/checkpoints $$BACKUP_DIR/ 2>/dev/null || true; \
	cp -r results $$BACKUP_DIR/ 2>/dev/null || true; \
	cp -r reports $$BACKUP_DIR/ 2>/dev/null || true; \
	echo "‚úÖ Backup criado em: $$BACKUP_DIR"

# Aliases for common operations
.PHONY: t
t: train ## Alias para train

.PHONY: e
e: evaluate ## Alias para evaluate

.PHONY: a
a: audit ## Alias para audit

.PHONY: distill-knowledge
distill-knowledge: ## Destila conhecimento de um LLM base para o espa√ßo Hilbert do Œ®QRH. Use: make distill-knowledge SOURCE_MODEL=gpt2
	@if [ -z "$(SOURCE_MODEL)" ]; then \
		echo "‚ùå SOURCE_MODEL n√£o especificado. Use: make distill-knowledge SOURCE_MODEL=gpt2"; \
		exit 1; \
	fi
	@echo "üîÆ Iniciando destila√ß√£o harm√¥nica de '$(SOURCE_MODEL)' para o formato Œ®QRH..."
	@echo "   üì• Verificando se modelo j√° est√° baixado..."
	@if [ ! -d "models/source/$(SOURCE_MODEL)" ]; then \
		echo "   üì• Modelo n√£o encontrado localmente - baixando..."; \
		$(PYTHON) scripts/download_model_ultra_simple.py --model_name $(SOURCE_MODEL); \
	else \
		echo "   ‚úÖ Modelo j√° baixado - usando cache local"; \
	fi
	$(PYTHON) model_converter_spectral_ultra_simple.py --mode distill --source_model $(SOURCE_MODEL) --output_model_name "psiqrh_distilled_$(SOURCE_MODEL)"
	@echo "‚úÖ Destila√ß√£o conclu√≠da. Modelo salvo em 'models/distilled/'"

.PHONY: vocab
vocab: ## Cria o vocabul√°rio nativo GPT-2 necess√°rio para o pipeline Œ®QRH.
	@echo "üî¨ Criando vocabul√°rio nativo GPT-2..."
	$(PYTHON) create_native_vocab.py
	@echo "‚úÖ Vocabul√°rio nativo criado em data/native_vocab.json"

.PHONY: h
h: help ## Alias para help

# Œ®QRH System Commands - UNIFIED SYSTEM
.PHONY: psiqrh-cli psiqrh-api psiqrh-interactive psiqrh-test psiqrh-benchmark psiqrh-enhanced

# Multi-Model Management Commands
.PHONY: list-models download-model convert-to-semantic distill-knowledge set-default-model semantic-workflow

psiqrh-cli: ## Executa CLI do Œ®QRH. Use: make psiqrh-cli TEXT="Ol√° mundo"
	@echo "üß† Executando Œ®QRH CLI..."
	@if [ -z "$(TEXT)" ]; then \
		echo "‚ùå TEXT n√£o especificado. Use: make psiqrh-cli TEXT=\"Ol√° mundo\""; \
		exit 1; \
	fi
	cd Œ®QRHSystem && $(PYTHON) -c "from interfaces.CLI import Œ®QRHCLI; cli = Œ®QRHCLI(); cli.process_text('$(TEXT)')"

psiqrh-enhanced: ## Executa Enhanced CLI do Œ®QRH Unificado. Use: make psiqrh-enhanced TEXT="Ol√° mundo"
	@echo "üöÄ Executando Œ®QRH Enhanced CLI (Sistema Unificado)..."
	@if [ -z "$(TEXT)" ]; then \
		echo "‚ùå TEXT n√£o especificado. Use: make psiqrh-enhanced TEXT=\"Ol√° mundo\""; \
		exit 1; \
	fi
	cd Œ®QRHSystem && $(PYTHON) -c "from interfaces.EnhancedCLI import EnhancedCLI; cli = EnhancedCLI(); cli.process_text('$(TEXT)')"
	@echo "‚úÖ Comando psiqrh-enhanced executado com sucesso!"

psiqrh-enhanced-interactive: ## Modo interativo aprimorado do Œ®QRH Unificado
	@echo "ü§ñ Iniciando modo interativo Œ®QRH Unificado..."
	cd Œ®QRHSystem && $(PYTHON) -c "from interfaces.EnhancedCLI import main; main()" --interactive

psiqrh-enhanced-batch: ## Processamento em lote com Enhanced CLI. Use: make psiqrh-enhanced-batch INPUT=input.txt OUTPUT=results.json
	@echo "üìÅ Executando processamento em lote Œ®QRH Unificado..."
	@if [ -z "$(INPUT)" ]; then \
		echo "‚ùå INPUT n√£o especificado. Use: make psiqrh-enhanced-batch INPUT=input.txt"; \
		exit 1; \
	fi
	cd Œ®QRHSystem && $(PYTHON) -c "from interfaces.EnhancedCLI import EnhancedCLI; cli = EnhancedCLI(); cli.run_batch_processing('$(INPUT)', '$(OUTPUT)')"

psiqrh-enhanced-spectral: ## Exporta an√°lise espectral completa. Use: make psiqrh-enhanced-spectral TEXT="teste" OUTPUT=analysis.json
	@echo "üî¨ Exportando an√°lise espectral Œ®QRH Unificado..."
	@if [ -z "$(TEXT)" ] || [ -z "$(OUTPUT)" ]; then \
		echo "‚ùå TEXT e OUTPUT s√£o obrigat√≥rios. Use: make psiqrh-enhanced-spectral TEXT=\"teste\" OUTPUT=analysis.json"; \
		exit 1; \
	fi
	cd Œ®QRHSystem && $(PYTHON) -c "from interfaces.EnhancedCLI import EnhancedCLI; cli = EnhancedCLI(); cli.export_spectral_analysis('$(TEXT)', '$(OUTPUT)')"

psiqrh-enhanced-benchmark: ## Benchmark aprimorado do Œ®QRH Unificado. Use: make psiqrh-enhanced-benchmark RUNS=100
	@echo "üìä Executando benchmark Œ®QRH Unificado..."
	@RUNS=$$(if [ -z "$(RUNS)" ]; then echo 100; else echo $(RUNS); fi); \
	cd Œ®QRHSystem && $(PYTHON) -c "from interfaces.EnhancedCLI import EnhancedCLI; cli = EnhancedCLI(); cli.benchmark_system($$RUNS)"

psiqrh-enhanced-status: ## Status completo do sistema Œ®QRH Unificado
	@echo "üî¨ Verificando status Œ®QRH Unificado..."
	cd Œ®QRHSystem && $(PYTHON) -c "from interfaces.EnhancedCLI import EnhancedCLI; cli = EnhancedCLI(); cli.show_system_status()"

psiqrh-enhanced-legacy-test: ## Testa compatibilidade com sistema legado
	@echo "üß™ Executando teste de compatibilidade legado Œ®QRH Unificado..."
	cd Œ®QRHSystem && $(PYTHON) -c "from interfaces.EnhancedCLI import EnhancedCLI; cli = EnhancedCLI(); cli.run_legacy_compatibility_test()"

psiqrh-interactive: ## Modo interativo do Œ®QRH (legacy)
	@echo "ü§ñ Iniciando modo interativo Œ®QRH (legacy)..."
	cd Œ®QRHSystem && $(PYTHON) -c "from interfaces.CLI import main; main()" --interactive

psiqrh-api: ## Inicia API REST do Œ®QRH
	@echo "üåê Iniciando API REST Œ®QRH..."
	cd Œ®QRHSystem && $(PYTHON) -c "from interfaces.API import main; main()" --host 0.0.0.0 --port 5000

psiqrh-test: ## Executa testes do sistema Œ®QRH
	@echo "üß™ Executando testes Œ®QRH..."
	cd Œ®QRHSystem && $(PYTHON) -m pytest tests/ -v --tb=short

psiqrh-benchmark: ## Benchmark de performance do Œ®QRH (legacy)
	@echo "üìä Executando benchmark Œ®QRH (legacy)..."
	cd Œ®QRHSystem && $(PYTHON) -c "from Œ®QRHSystem.core.PipelineManager import PipelineManager; from Œ®QRHSystem.config.SystemConfig import SystemConfig; import time; config = SystemConfig.default(); pipeline = PipelineManager(config); print('üî¨ Benchmark Œ®QRH - 100 execu√ß√µes...'); start_time = time.time(); [pipeline.process('Benchmark test') for i in range(100)]; end_time = time.time(); avg_time = (end_time - start_time) / 100; print(f'‚úÖ Benchmark conclu√≠do: {avg_time:.3f}s por execu√ß√£o')"
	@echo "‚úÖ Comando psiqrh-benchmark executado com sucesso!"

# Multi-Model Management Commands
list-models: ## Lista todos os modelos dispon√≠veis (fonte, destilados, sem√¢nticos)
	@echo "üìö Listando modelos dispon√≠veis..."
	cd Œ®QRHSystem && $(PYTHON) -c "from interfaces.ModelManagementCLI import ModelManagementCLI; cli = ModelManagementCLI(); cli.run(['list'])"
	@echo "‚úÖ Comando list-models executado com sucesso!"

download-model: ## Baixa um modelo do Hugging Face. Use: make download-model SOURCE_MODEL=gpt2
	@echo "üì• Baixando modelo..."
	@if [ -z "$(SOURCE_MODEL)" ]; then \
		echo "‚ùå SOURCE_MODEL n√£o especificado. Use: make download-model SOURCE_MODEL=gpt2"; \
		exit 1; \
	fi
	cd Œ®QRHSystem && $(PYTHON) -c "from interfaces.ModelManagementCLI import ModelManagementCLI; cli = ModelManagementCLI(); cli.run(['download', '$(SOURCE_MODEL)'])"

convert-to-semantic: ## Converte um modelo para formato sem√¢ntico. Use: make convert-to-semantic SOURCE_MODEL=gpt2
	@echo "üîÆ Convertendo modelo para formato sem√¢ntico..."
	@if [ -z "$(SOURCE_MODEL)" ]; then \
		echo "‚ùå SOURCE_MODEL n√£o especificado. Use: make convert-to-semantic SOURCE_MODEL=gpt2"; \
		exit 1; \
	fi
	cd Œ®QRHSystem && $(PYTHON) -c "from interfaces.ModelManagementCLI import ModelManagementCLI; cli = ModelManagementCLI(); cli.run(['convert', '$(SOURCE_MODEL)'])"

distill-knowledge: ## Destila conhecimento de um modelo. Use: make distill-knowledge SOURCE_MODEL=gpt2
	@echo "üß† Destilando conhecimento..."
	@if [ -z "$(SOURCE_MODEL)" ]; then \
		echo "‚ùå SOURCE_MODEL n√£o especificado. Use: make distill-knowledge SOURCE_MODEL=gpt2"; \
		exit 1; \
	fi
	cd Œ®QRHSystem && $(PYTHON) -c "from interfaces.ModelManagementCLI import ModelManagementCLI; cli = ModelManagementCLI(); cli.run(['distill', '$(SOURCE_MODEL)'])"

set-default-model: ## Define o modelo padr√£o do sistema. Use: make set-default-model MODEL=gpt2
	@echo "üéØ Definindo modelo padr√£o..."
	@if [ -z "$(MODEL)" ]; then \
		echo "‚ùå MODEL n√£o especificado. Use: make set-default-model MODEL=gpt2"; \
		exit 1; \
	fi
	cd Œ®QRHSystem && $(PYTHON) -c "from interfaces.ModelManagementCLI import ModelManagementCLI; cli = ModelManagementCLI(); cli.run(['set-default', '$(MODEL)'])"

semantic-workflow: ## Workflow completo: baixar, destilar e converter. Use: make semantic-workflow SOURCE_MODEL=gpt2
	@echo "üöÄ Executando workflow sem√¢ntico completo..."
	@if [ -z "$(SOURCE_MODEL)" ]; then \
		echo "‚ùå SOURCE_MODEL n√£o especificado. Use: make semantic-workflow SOURCE_MODEL=gpt2"; \
		exit 1; \
	fi
	@echo "   üì• Passo 1: Baixando modelo..."
	make download-model SOURCE_MODEL=$(SOURCE_MODEL)
	@echo "   üß† Passo 2: Destilando conhecimento..."
	make distill-knowledge SOURCE_MODEL=$(SOURCE_MODEL)
	@echo "   üîÆ Passo 3: Convertendo para formato sem√¢ntico..."
	make convert-to-semantic SOURCE_MODEL=$(SOURCE_MODEL)
	@echo "   üìä Passo 4: Verificando status..."
	make list-models
	@echo "‚úÖ Workflow sem√¢ntico completo conclu√≠do!"