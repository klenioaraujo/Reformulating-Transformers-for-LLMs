#!/usr/bin/env python3
"""
IntegraÃ§Ã£o da SaÃ­da SemÃ¢ntica no Pipeline Î¨QRH
==============================================

Integra a saÃ­da dos modelos semÃ¢nticos no pipeline de geraÃ§Ã£o de texto Î¨QRH,
combinando os parÃ¢metros espectrais extraÃ­dos com o sistema de geraÃ§Ã£o quÃ¢ntica.

PrincÃ­pios Integrados:
- EquaÃ§Ã£o de Padilha: f(Î»,t) = Iâ‚€ sin(Ï‰t + Î±Î») e^(i(Ï‰t - kÎ» + Î²Î»Â²))
- Filtragem Espectral: F(k) = exp(i Î± Â· arctan(ln(|k| + Îµ)))
- Sistema DCF: DinÃ¢mica de ConsciÃªncia Fractal
- Pipeline Î¨QRH: IntegraÃ§Ã£o completa com geraÃ§Ã£o de texto

Uso:
    from semantic_output_integration import SemanticOutputIntegrator
    integrator = SemanticOutputIntegrator()
    result = integrator.generate_with_semantic_model('gpt2', 'Hello world')
"""

import torch
import json
import os
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
import numpy as np

from spectral_parameters_integration import SpectralParametersIntegrator
from src.core.dynamic_quantum_matrix import DynamicQuantumCharacterMatrix
from advanced_physical_validation import AdvancedPhysicalValidator
from src.core.efficient_quantum_decoder import EfficientQuantumDecoder


class SemanticOutputIntegrator:
    """
    Integra a saÃ­da dos modelos semÃ¢nticos no pipeline Î¨QRH completo.
    """

    def __init__(self):
        self.spectral_integrator = SpectralParametersIntegrator()
        self.quantum_matrix = DynamicQuantumCharacterMatrix()
        self.validator = AdvancedPhysicalValidator()
        self.efficient_decoder = None  # Inicializado sob demanda
        self.current_model = None

        print("ğŸ”— Semantic Output Integrator inicializado")

    def generate_with_semantic_model(self, model_name: str, input_text: str,
                                   max_length: int = 50) -> Dict[str, Any]:
        """
        Gera texto usando modelo semÃ¢ntico integrado no pipeline Î¨QRH.

        Args:
            model_name: Nome do modelo semÃ¢ntico
            input_text: Texto de entrada
            max_length: Comprimento mÃ¡ximo da geraÃ§Ã£o

        Returns:
            Resultado da geraÃ§Ã£o com mÃ©tricas fÃ­sicas
        """
        print(f"ğŸ¯ Gerando com modelo semÃ¢ntico: {model_name}")
        print(f"ğŸ“ Entrada: '{input_text}'")

        # 1. Preparar modelo semÃ¢ntico
        if not self._prepare_semantic_model(model_name):
            return {
                'status': 'error',
                'error': f'Falha ao preparar modelo {model_name}'
            }

        # 2. Processar entrada com matriz quÃ¢ntica adaptada
        quantum_input = self._encode_input_text(input_text)

        # 3. Aplicar operaÃ§Ãµes quÃ¢nticas do pipeline Î¨QRH
        processed_output = self._apply_quantum_pipeline(quantum_input)

        # 4. Gerar sequÃªncia usando EquaÃ§Ã£o de Padilha
        generated_sequence = self._generate_with_padilha_equation(
            processed_output, max_length
        )

        # 5. Decodificar para texto usando sistema DCF
        final_text = self._decode_with_dcf_system(generated_sequence)

        # 6. Computar mÃ©tricas fÃ­sicas
        physical_metrics = self._compute_physical_metrics(
            quantum_input, processed_output, generated_sequence
        )

        # 7. Preparar resultado final
        result = {
            'status': 'success',
            'model_name': model_name,
            'input_text': input_text,
            'generated_text': final_text,
            'physical_metrics': physical_metrics,
            'spectral_parameters': self.quantum_matrix.get_current_parameters(),
            'generation_method': 'Semantic Î¨QRH Pipeline',
            'fcf_value': self._compute_fcf_metric(processed_output),
            'consciousness_state': self._determine_consciousness_state(physical_metrics),
            'synchronization_order': self._compute_synchronization_order(generated_sequence)
        }

        print("âœ… GeraÃ§Ã£o concluÃ­da com sucesso!")
        print(f"ğŸ“ Texto gerado: '{final_text[:100]}{'...' if len(final_text) > 100 else ''}'")

        return result

    def _prepare_semantic_model(self, model_name: str) -> bool:
        """
        Prepara o modelo semÃ¢ntico para uso.
        """
        try:
            # Adaptar matriz quÃ¢ntica aos parÃ¢metros do modelo
            success = self.quantum_matrix.adapt_to_model(model_name)
            if success:
                self.current_model = model_name
            return success
        except Exception as e:
            print(f"âŒ Erro preparando modelo {model_name}: {e}")
            return False

    def _encode_input_text(self, text: str) -> torch.Tensor:
        """
        Codifica texto de entrada usando matriz quÃ¢ntica adaptada.
        """
        return self.quantum_matrix.encode_text(text)

    def _apply_quantum_pipeline(self, quantum_input: torch.Tensor) -> torch.Tensor:
        """
        Aplica operaÃ§Ãµes quÃ¢nticas do pipeline Î¨QRH.
        """
        # Aplicar filtragem espectral
        filtered = self._apply_spectral_filtering(quantum_input)

        # Aplicar rotaÃ§Ãµes SO(4)
        rotated = self._apply_so4_rotations(filtered)

        # Aplicar processamento de consciÃªncia (simplificado)
        conscious = self._apply_consciousness_processing(rotated)

        return conscious

    def _apply_spectral_filtering(self, tensor: torch.Tensor) -> torch.Tensor:
        """
        Aplica filtragem espectral baseada nos parÃ¢metros do modelo usando camadas reais do Î¨QRH.
        """
        # Usar diretamente a camada de filtragem espectral do DynamicQuantumCharacterMatrix
        # Formatar tensor para [batch, seq, hidden] -> [batch, hidden, seq] para conv1d
        if tensor.dim() == 1:  # [hidden] - tensor unidimensional
            # Para tensor 1D, expandir para formato adequado [batch=1, channels=hidden_size, seq=1]
            x = tensor.unsqueeze(0).unsqueeze(-1)  # [1, hidden, 1]
        elif tensor.dim() == 2:  # [seq, hidden]
            x = tensor.unsqueeze(0).transpose(1, 2)  # [1, hidden, seq]
        else:
            x = tensor.transpose(0, 1).unsqueeze(0)  # [1, hidden, seq]

        # Aplicar filtro espectral real mantendo fase complexa
        filtered = self.quantum_matrix.adaptation_layers['spectral_filter'](x)

        # Reverter formato
        if tensor.dim() == 1:
            return filtered.squeeze(0).squeeze(-1)  # [hidden]
        else:
            return filtered.squeeze(0).transpose(0, 1)  # [seq, hidden]

    def _apply_so4_rotations(self, tensor: torch.Tensor) -> torch.Tensor:
        """
        Aplica rotaÃ§Ãµes SO(4) unitÃ¡rias usando camadas reais do Î¨QRH.
        """
        # Usar diretamente a camada de rotaÃ§Ã£o quaterniÃ³nica do DynamicQuantumCharacterMatrix
        # Formatar tensor para [batch, seq, hidden]
        if tensor.dim() == 1:  # [hidden] - tensor unidimensional
            x = tensor.unsqueeze(0).unsqueeze(0)  # [1, 1, hidden]
        elif tensor.dim() == 2:  # [seq, hidden]
            x = tensor.unsqueeze(0)  # [1, seq, hidden]
        else:
            x = tensor  # JÃ¡ no formato correto

        # Aplicar rotaÃ§Ãµes SO(4) verdadeiras
        rotated = self.quantum_matrix.adaptation_layers['quaternion_rotator'](x)

        # Reverter formato se necessÃ¡rio
        if tensor.dim() == 1:
            return rotated.squeeze(0).squeeze(0)  # [hidden]
        else:
            return rotated.squeeze(0) if tensor.dim() == 2 else rotated

    def _apply_consciousness_processing(self, tensor: torch.Tensor) -> torch.Tensor:
        """
        Aplica processamento de consciÃªncia (FCI computation).
        """
        # Processamento simplificado - normalizar baseado na energia
        energy = torch.norm(tensor)
        if energy > 0:
            normalized = tensor / energy
            # Aplicar transformaÃ§Ã£o nÃ£o-linear para simular processamento consciente
            # VersÃ£o complexa do tanh (aplicar separadamente Ã s partes)
            real_part = torch.tanh(normalized.real * 2.0)
            imag_part = torch.tanh(normalized.imag * 2.0)
            conscious = torch.complex(real_part, imag_part)
            return conscious

        return tensor

    def _generate_with_padilha_equation(self, quantum_state: torch.Tensor,
                                       max_length: int) -> torch.Tensor:
        """
        Gera sequÃªncia usando EquaÃ§Ã£o de Padilha com autoregressÃ£o quÃ¢ntica.
        """
        params = self.quantum_matrix.get_current_parameters()
        if not params:
            # Fallback para geraÃ§Ã£o simples
            return torch.randn(max_length, quantum_state.size(-1))

        alpha = params.get('alpha_final', 1.5)
        beta = params.get('beta_final', 0.8)

        # ParÃ¢metros da EquaÃ§Ã£o de Padilha
        I0 = 1.0
        omega = alpha
        k = beta

        # GeraÃ§Ã£o autoregressiva quÃ¢ntica
        sequence = []
        current_state = quantum_state.clone()  # Estado quÃ¢ntico inicial

        for t in range(max_length):
            lambda_val = t / max_length  # PosiÃ§Ã£o normalizada

            # f(Î»,t) = Iâ‚€ sin(Ï‰t + Î±Î») e^(i(Ï‰t - kÎ» + Î²Î»Â²))
            wave_function = I0 * torch.sin(torch.tensor(omega * t + alpha * lambda_val)) * \
                           torch.exp(1j * torch.tensor(omega * t - k * lambda_val + beta * lambda_val**2))

            # ModulaÃ§Ã£o quÃ¢ntica baseada no estado atual
            modulation = wave_function * current_state.mean(dim=0)

            # Aplicar pipeline Î¨QRH ao estado modulado
            processed_state = self._apply_quantum_pipeline(modulation.unsqueeze(0)).squeeze(0)

            # PrÃ³ximo estado Ã© baseado no estado processado
            next_state = processed_state * wave_function.conj()  # EvoluÃ§Ã£o unitÃ¡ria

            sequence.append(processed_state)
            current_state = next_state  # Atualizar estado para autoregressÃ£o

        return torch.stack(sequence)

    def _extract_original_model_name(self, semantic_model_name: str) -> str:
        """
        Extrai o nome do modelo original do nome do modelo semÃ¢ntico.

        Args:
            semantic_model_name: Nome do modelo semÃ¢ntico (ex: 'psiqrh_semantic_gpt2')

        Returns:
            Nome do modelo original para tokenizaÃ§Ã£o
        """
        if not semantic_model_name or not semantic_model_name.startswith('psiqrh_semantic_'):
            return 'gpt2'  # Fallback padrÃ£o

        # Remover prefixo 'psiqrh_semantic_'
        original_name = semantic_model_name.replace('psiqrh_semantic_', '')

        # Mapear nomes especiais se necessÃ¡rio
        name_mapping = {
            'gpt2': 'gpt2',
            # Adicionar outros mapeamentos conforme necessÃ¡rio
        }

        return name_mapping.get(original_name, original_name)

    def _decode_with_dcf_system(self, sequence: torch.Tensor) -> str:
        """
        Decodifica sequÃªncia usando sistema DCF (DinÃ¢mica de ConsciÃªncia Fractal).
        Usa o EfficientQuantumDecoder para decodificaÃ§Ã£o precisa.
        """
        if self.efficient_decoder is None:
            self.efficient_decoder = EfficientQuantumDecoder(verbose=False)  # Modo silencioso para produÃ§Ã£o
            self.efficient_decoder.initialize_with_quantum_matrix(self.quantum_matrix)

        tokens = self.efficient_decoder.inverse_decode(sequence.unsqueeze(0))
        return self.efficient_decoder.tokens_to_text(tokens)

    def _compute_physical_metrics(self, input_tensor: torch.Tensor,
                                processed_tensor: torch.Tensor,
                                generated_sequence: torch.Tensor) -> Dict[str, Any]:
        """
        Computa mÃ©tricas fÃ­sicas da geraÃ§Ã£o.
        """
        metrics = {}

        # ValidaÃ§Ã£o de conservaÃ§Ã£o de energia
        energy_validation = self.validator.validate_energy_conservation(
            input_tensor, processed_tensor
        )
        metrics['energy_conservation'] = energy_validation

        # ValidaÃ§Ã£o de estabilidade numÃ©rica
        stability_validation = self.validator.validate_numerical_stability(
            input_tensor, processed_tensor
        )
        metrics['numerical_stability'] = stability_validation

        # MÃ©tricas da sequÃªncia gerada
        metrics['sequence_metrics'] = {
            'length': generated_sequence.size(0),
            'mean_magnitude': generated_sequence.abs().mean().item(),
            'std_magnitude': generated_sequence.abs().std().item(),
            'complexity': self._compute_sequence_complexity(generated_sequence)
        }

        # ParÃ¢metros da EquaÃ§Ã£o de Padilha
        params = self.quantum_matrix.get_current_parameters() or {}
        metrics['padilha_parameters'] = {
            'I0': 1.0,
            'omega': params.get('alpha_final', 1.5),
            'k': params.get('beta_final', 0.8),
            'alpha': params.get('alpha_final', 1.5),
            'beta': params.get('beta_final', 0.8)
        }

        return metrics

    def _compute_fcf_metric(self, tensor: torch.Tensor) -> float:
        """
        Computa mÃ©trica FCF (Fractal Consciousness Factor).
        """
        # SimplificaÃ§Ã£o: baseado na complexidade espectral
        if tensor.numel() > 0:
            # Usar variÃ¢ncia como proxy de complexidade
            complexity = torch.var(tensor).item()
            # Normalizar para [0, 1]
            fcf = min(1.0, complexity / 10.0)
            return fcf
        return 0.5

    def _determine_consciousness_state(self, metrics: Dict) -> str:
        """
        Determina estado de consciÃªncia baseado nas mÃ©tricas.
        """
        # Extrair FCF real das mÃ©tricas ou computar do estado
        fcf = metrics.get('fcf_value', 0.5)  # ou compute de processed_tensor

        if fcf > 0.7:
            return "ENLIGHTENMENT"
        elif fcf > 0.5:
            return "MEDITATION"
        elif fcf > 0.3:
            return "FOCUS"
        else:
            return "CONFUSION"

    def _compute_synchronization_order(self, sequence: torch.Tensor) -> float:
        """
        Computa ordem de sincronizaÃ§Ã£o da sequÃªncia gerada.
        """
        if sequence.size(0) < 2:
            return 0.5

        # Usar correlaÃ§Ã£o entre passos consecutivos como proxy
        correlations = []
        for i in range(sequence.size(0) - 1):
            # Compute correlaÃ§Ã£o das magnitudes ou partes reais
            real_i = sequence[i].real
            real_ip1 = sequence[i+1].real
            corr = torch.corrcoef(torch.stack([real_i, real_ip1]))[0, 1].item()
            correlations.append(abs(corr))

        return np.mean(correlations) if correlations else 0.5

    def _compute_sequence_complexity(self, sequence: torch.Tensor) -> float:
        """
        Computa complexidade da sequÃªncia gerada.
        """
        if sequence.numel() == 0:
            return 0.0

        # Usar entropia como medida de complexidade
        flattened = sequence.flatten().abs()

        # Discretizar em bins
        bins = torch.histc(flattened, bins=10, min=0, max=flattened.max().item())

        # Computar entropia
        probs = bins / bins.sum()
        probs = probs[probs > 0]  # Remover zeros
        entropy = -torch.sum(probs * torch.log2(probs))

        return entropy.item()


# FunÃ§Ã£o de teste
def test_semantic_output_integration():
    """
    Testa a integraÃ§Ã£o da saÃ­da semÃ¢ntica.
    """
    print("ğŸ§ª Teste de IntegraÃ§Ã£o da SaÃ­da SemÃ¢ntica")
    print("=" * 50)

    integrator = SemanticOutputIntegrator()

    # Testar com modelo disponÃ­vel
    available_models = integrator.spectral_integrator.get_available_models()

    if available_models:
        test_model = available_models[0]
        test_text = "Hello quantum"

        print(f"ğŸ¯ Testando com modelo: {test_model}")
        print(f"ğŸ“ Texto de entrada: '{test_text}'")

        try:
            result = integrator.generate_with_semantic_model(
                test_model, test_text, max_length=20
            )

            if result['status'] == 'success':
                print("âœ… GeraÃ§Ã£o bem-sucedida!")
                print(f"ğŸ“ Texto gerado: '{result['generated_text']}'")
                print(f"ğŸ§  FCF: {result['fcf_value']:.3f}")
                print(f"ğŸ­ Estado: {result['consciousness_state']}")
                print(f"ğŸ”„ SincronizaÃ§Ã£o: {result['synchronization_order']:.3f}")

                # Verificar mÃ©tricas fÃ­sicas
                energy = result['physical_metrics']['energy_conservation']
                print(f"âš¡ ConservaÃ§Ã£o de energia: {energy['energy_conserved']}")

            else:
                print(f"âŒ Falha: {result.get('error', 'Erro desconhecido')}")

        except Exception as e:
            print(f"ğŸ’¥ Erro durante teste: {e}")
    else:
        print("âš ï¸  Nenhum modelo semÃ¢ntico disponÃ­vel para teste")


if __name__ == "__main__":
    test_semantic_output_integration()