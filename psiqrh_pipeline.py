#!/usr/bin/env python3
"""
Œ®QRH Pipeline Configurado e Robusto
====================================

Implementa√ß√£o final que utiliza a QuantumCharacterMatrix como motor central e exclusivo
para todo o processamento de texto, com todos os par√¢metros externalizados em configura√ß√£o.
"""

import torch
import torch.nn as nn
import numpy as np
import os
import sys
import argparse
from typing import List

# Adicionar diret√≥rio base ao path
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, BASE_DIR)

# Importar componentes essenciais do sistema Œ®QRH
from quantum_character_matrix import QuantumCharacterMatrix
from src.core.context_funnel import ContextFunnel

# Importar gerenciador de configura√ß√£o
try:
    from src.utils.config_manager import get_config_manager
except ImportError:
    # Fallback simples se o config manager n√£o estiver dispon√≠vel
    class SimpleConfigManager:
        def load_config(self, config_name):
            import yaml
            config_path = f"configs/{config_name}.yaml"
            if os.path.exists(config_path):
                with open(config_path, 'r') as f:
                    return yaml.safe_load(f)
            else:
                return {}

    def get_config_manager():
        return SimpleConfigManager()

class Œ®QRHPipeline:
    """
    Pipeline configurado que orquestra a QuantumCharacterMatrix para gerar respostas
    de forma algor√≠tmica, coesa e totalmente configur√°vel via arquivos.
    """

    def __init__(self):
        # Carregar configura√ß√£o
        config_mgr = get_config_manager()
        self.config = config_mgr.load_config('pipeline_config')

        # Par√¢metros do pipeline
        self.device = self.config.get('pipeline', {}).get('device', 'cpu')

        # Par√¢metros da QuantumCharacterMatrix
        qm_config = self.config.get('quantum_matrix', {})
        vocabulary = self.config.get('vocabulary')

        # Inicializar QuantumCharacterMatrix com par√¢metros do config
        self.qcm = QuantumCharacterMatrix(
            embed_dim=qm_config.get('embed_dim', 64),
            alpha=qm_config.get('alpha', 1.5),
            beta=qm_config.get('beta', 0.8),
            fractal_dim=qm_config.get('fractal_dim', 1.7),
            device=self.device,
            vocabulary=vocabulary
        )

        # Inicializar ContextFunnel com par√¢metros do config
        cf_config = self.config.get('context_funnel', {})
        self.context_funnel = ContextFunnel(
            embed_dim=self.qcm.embed_dim * 4,  # Opera sobre o quaterni√£o achatado
            num_heads=cf_config.get('num_heads', 8),
            max_history=cf_config.get('max_history', 50)
        ).to(self.device)

        print("‚úÖ Œ®QRH Pipeline Configurado inicializado com sucesso.")
        print(f"   üî© Usando QuantumCharacterMatrix como motor principal.")
        print(f"   üìö Vocabul√°rio: {len(self.qcm.vocabulary)} caracteres.")

    def process(self, input_text: str) -> str:
        """
        PIPELINE CORRIGIDO com decodifica√ß√£o posicional e preserva√ß√£o de contexto.
        """
        max_length = self.config.get('pipeline', {}).get('max_generation_length', 20)
        context_blend_ratio = 0.7  # Preserva 70% do contexto anterior

        print(f"\nüîÑ Processando: '{input_text}'")

        # --- Etapa 1: Codifica√ß√£o do Input via QuantumCharacterMatrix ---
        with torch.no_grad():
            input_states = [self.qcm.encode_character(char, position=i) for i, char in enumerate(input_text)]
            flattened_input_states = [s.flatten() for s in input_states]
            current_context = self.context_funnel(flattened_input_states)

        # --- Etapa 2: Loop de Gera√ß√£o Auto-Regressivo CORRIGIDO ---
        generated_chars = []
        current_position = len(input_text)  # Come√ßa ap√≥s o input

        for i in range(max_length):
            with torch.no_grad():
                context_to_decode = current_context.view(self.qcm.embed_dim, 4)

                # üî• DECODIFICA√á√ÉO COM POSI√á√ÉO CORRETA
                decoded_results = self.qcm.decode_quantum_state(
                    context_to_decode, top_k=1, position=current_position
                )

                if not decoded_results:
                    break

                next_char, confidence = decoded_results[0]

                # Crit√©rio de parada mais inteligente
                if next_char == '<UNK>' or confidence < 0.3:
                    break

                generated_chars.append(next_char)

                # üî• ATUALIZA√á√ÉO PONDERADA DO CONTEXTO
                new_char_state = self.qcm.encode_character(next_char, position=current_position)
                current_context = (
                    context_blend_ratio * current_context +
                    (1 - context_blend_ratio) * new_char_state.flatten()
                )

                current_position += 1

        generated_text = "".join(generated_chars)
        print(f"   üî¨ Resposta Gerada: '{generated_text}'")
        return generated_text

def main():
    """Fun√ß√£o principal para lidar com argumentos de linha de comando"""
    parser = argparse.ArgumentParser(
        description="Œ®QRH Pipeline Configurado - Gera√ß√£o de Texto com QuantumCharacterMatrix",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument(
        'text',
        nargs='?',
        default=None,
        help='Texto a ser processado pelo pipeline.'
    )
    parser.add_argument(
        '--seed',
        type=int,
        default=None,
        help='Semente de aleatoriedade para garantir resultados reproduz√≠veis.'
    )

    args = parser.parse_args()

    if args.seed is not None:
        print(f"üå± Usando semente de aleatoriedade: {args.seed}")
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
    else:
        print("üå± Executando em modo aleat√≥rio (sem semente).")

    # Se nenhum texto for passado, usa o default do config
    text_to_process = args.text
    if text_to_process is None:
        config_mgr = get_config_manager()
        try:
            app_config = config_mgr.load_config('pipeline_config')
            text_to_process = app_config.get('pipeline', {}).get('default_prompt', 'life is beautiful')
        except FileNotFoundError:
            text_to_process = 'life is beautiful'

    # Inicializa e executa o pipeline
    pipeline = Œ®QRHPipeline()
    result = pipeline.process(text_to_process)

    print(f"\nüéØ Input: {text_to_process}")
    print(f"üéØ Output: {result}")

if __name__ == "__main__":
    main()