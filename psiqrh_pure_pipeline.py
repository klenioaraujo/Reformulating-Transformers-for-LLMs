#!/usr/bin/env python3
"""
Œ®QRH Pure Physical-Mathematical Pipeline
=========================================

Pipeline puramente f√≠sico-matem√°tico que aproveita o espa√ßo Hilbert completo
integrando todos os componentes avan√ßados do sistema Œ®QRH.

Arquitetura:
- DynamicQuantumMatrix: Representa√ß√£o quaterni√≥nica completa
- EfficientQuantumDecoder: Invers√£o matem√°tica direta
- DCFTokenAnalysis: Conectividade sem√¢ntica via osciladores Kuramoto
- QuantumTemperatureCalculator: Controle adaptativo baseado em entropia

Princ√≠pios F√≠sicos:
- Equa√ß√£o de Padilha: f(Œª,t) = I‚ÇÄ sin(œât + Œ±Œª) e^(i(œât - kŒª + Œ≤Œª¬≤))
- Rota√ß√µes SO(4): Transforma√ß√µes unit√°rias preservando norma
- Filtragem Espectral: Conserva√ß√£o de energia (Parseval)
- Din√¢mica Fractal: Complexidade adaptativa
"""

import torch
import torch.nn as nn
import numpy as np
import os
import sys
import argparse
from typing import List, Dict, Any, Optional
import math

# Adicionar diret√≥rio base ao path
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, BASE_DIR)

# Importar componentes avan√ßados do sistema Œ®QRH
try:
    from src.core.dynamic_quantum_matrix import DynamicQuantumCharacterMatrix
    from src.core.efficient_quantum_decoder import EfficientQuantumDecoder
    from src.processing.token_analysis import DCFTokenAnalysis
    from src.core.quantum_temperature_calculator import QuantumTemperatureCalculator
    from src.core.context_funnel import ContextFunnel
    HAS_ADVANCED_COMPONENTS = True
except ImportError as e:
    print(f"‚ö†Ô∏è  Componentes avan√ßados n√£o dispon√≠veis: {e}")
    HAS_ADVANCED_COMPONENTS = False

# Importar gerenciador de configura√ß√£o
try:
    from src.utils.config_manager import get_config_manager
except ImportError:
    # Fallback simples se o config manager n√£o estiver dispon√≠vel
    class SimpleConfigManager:
        def load_config(self, config_name):
            import yaml
            config_path = f"configs/{config_name}.yaml"
            if os.path.exists(config_path):
                with open(config_path, 'r') as f:
                    return yaml.safe_load(f)
            else:
                return {}

    def get_config_manager():
        return SimpleConfigManager()


class HilbertSpaceQuantumProcessor:
    """
    Processador qu√¢ntico que opera no espa√ßo Hilbert completo.

    Implementa opera√ß√µes matriciais em vez de processamento token-a-token,
    aproveitando representa√ß√µes quaterni√≥nicas e transforma√ß√µes unit√°rias.
    """

    def __init__(self, device='cpu'):
        self.device = device
        self.embed_dim = 64
        self.quaternion_dim = self.embed_dim // 4

        print("üî¨ HilbertSpaceQuantumProcessor inicializado")
        print(f"   üìä Dimens√µes: embed_dim={self.embed_dim}, quaternion_dim={self.quaternion_dim}")

    def encode_text_batch(self, texts: List[str]) -> torch.Tensor:
        """
        Codifica texto em lote usando representa√ß√£o quaterni√≥nica.

        Args:
            texts: Lista de textos para codificar

        Returns:
            quantum_states: Tensor [batch_size, seq_len, embed_dim, 4]
        """
        batch_size = len(texts)
        max_seq_len = max(len(text) for text in texts)

        # Tensor para estados qu√¢nticos
        quantum_states = torch.zeros(batch_size, max_seq_len, self.embed_dim, 4,
                                   dtype=torch.complex64, device=self.device)

        for batch_idx, text in enumerate(texts):
            for pos, char in enumerate(text[:max_seq_len]):
                # Gerar estado qu√¢ntico baseado na equa√ß√£o de Padilha
                char_state = self._generate_padilha_state(char, pos)
                quantum_states[batch_idx, pos] = char_state

        return quantum_states

    def _generate_padilha_state(self, char: str, position: int) -> torch.Tensor:
        """
        Gera estado qu√¢ntico usando equa√ß√£o de Padilha.

        f(Œª,t) = I‚ÇÄ sin(œât + Œ±Œª) e^(i(œât - kŒª + Œ≤Œª¬≤))
        """
        char_code = ord(char) if len(char) == 1 else 32  # espa√ßo para caracteres inv√°lidos
        lambda_pos = char_code / 256.0  # Normalizar c√≥digo ASCII
        t = position / 100.0  # Varia√ß√£o temporal

        I0 = 1.0
        omega = 2 * math.pi
        k = 2 * math.pi
        alpha = 1.5
        beta = 0.8

        # Estado qu√¢ntico base
        state = torch.zeros(self.embed_dim, 4, dtype=torch.complex64, device=self.device)

        for i in range(self.embed_dim):
            # Componente da equa√ß√£o de Padilha
            spatial_mod = i / self.embed_dim

            # Termo da onda
            wave_term = I0 * torch.sin(torch.tensor(omega * t + alpha * lambda_pos))
            phase_term = torch.exp(1j * torch.tensor(omega * t - k * lambda_pos + beta * lambda_pos**2))

            # Componente quaterni√≥nica
            w = wave_term * phase_term.real
            x = wave_term * phase_term.imag * torch.cos(torch.tensor(2 * math.pi * spatial_mod))
            y = wave_term * phase_term.imag * torch.sin(torch.tensor(2 * math.pi * spatial_mod))
            z = wave_term * torch.exp(torch.tensor(-beta * lambda_pos**2))

            state[i, 0] = torch.complex(w, torch.tensor(0.0))
            state[i, 1] = torch.complex(x, torch.tensor(0.0))
            state[i, 2] = torch.complex(y, torch.tensor(0.0))
            state[i, 3] = torch.complex(z, torch.tensor(0.0))

        return state

    def apply_spectral_filtering(self, quantum_states: torch.Tensor) -> torch.Tensor:
        """
        Aplica filtragem espectral adaptativa preservando energia.

        F(k) = exp(i Œ± ¬∑ arctan(ln(|k| + Œµ)))
        """
        batch_size, seq_len, embed_dim, _ = quantum_states.shape

        # Aplicar FFT na dimens√£o de embedding
        freq_domain = torch.fft.fft(quantum_states, dim=2)

        # Aplicar filtro espectral
        k_magnitude = torch.abs(freq_domain)
        epsilon = 1e-8
        spectral_filter = torch.exp(1j * 1.5 * torch.arctan(torch.log(k_magnitude + epsilon)))

        freq_domain_filtered = freq_domain * spectral_filter

        # Aplicar IFFT
        time_domain = torch.fft.ifft(freq_domain_filtered, dim=2)

        return time_domain


class Œ®QRHPurePipeline:
    """
    Pipeline puramente f√≠sico-matem√°tico Œ®QRH.

    Integra todos os componentes avan√ßados para opera√ß√£o no espa√ßo Hilbert completo
    com base em princ√≠pios f√≠sicos rigorosos.
    """

    def __init__(self):
        # Carregar configura√ß√£o
        config_mgr = get_config_manager()
        self.config = config_mgr.load_config('pipeline_config')

        # Par√¢metros do pipeline
        self.device = self.config.get('pipeline', {}).get('device', 'cpu')
        self.max_generation_length = self.config.get('pipeline', {}).get('max_generation_length', 50)

        # Inicializar processador Hilbert
        self.hilbert_processor = HilbertSpaceQuantumProcessor(device=self.device)

        # Inicializar componentes avan√ßados
        self._initialize_advanced_components()

        print("‚úÖ Œ®QRH Pure Physical-Mathematical Pipeline inicializado")
        print(f"   üî¨ Usando espa√ßo Hilbert completo com opera√ß√µes matriciais")
        print(f"   üåä Baseado na equa√ß√£o de Padilha e rota√ß√µes SO(4)")

    def _initialize_advanced_components(self):
        """Inicializa todos os componentes avan√ßados do sistema."""

        global HAS_ADVANCED_COMPONENTS

        if not HAS_ADVANCED_COMPONENTS:
            print("‚ö†Ô∏è  Componentes avan√ßados n√£o dispon√≠veis - usando implementa√ß√£o b√°sica")
            return

        try:
            # 1. Dynamic Quantum Matrix (CORRE√á√ÉO: usar vocab_size compat√≠vel com decoder)
            self.dynamic_matrix = DynamicQuantumCharacterMatrix(
                vocab_size=195,  # Corrigido: deve ser igual ao vocab_size do decoder
                hidden_size=256,
                device=self.device
            )
            print("   ‚úÖ DynamicQuantumMatrix inicializada (vocab=195)")

            # 2. Efficient Quantum Decoder
            self.efficient_decoder = EfficientQuantumDecoder(
                vocab_size=195,
                seq_length=64,
                embed_dim=64,
                device=self.device,
                verbose=True
            )
            print("   ‚úÖ EfficientQuantumDecoder inicializado")

            # 2.1. INICIALIZAR DECODER COM MATRIZ QU√ÇNTICA (CORRE√á√ÉO CR√çTICA)
            self.efficient_decoder.initialize_with_quantum_matrix(self.dynamic_matrix)
            print("   üîó Decoder alinhado com matriz qu√¢ntica")

            # 3. DCF Token Analysis
            self.dcf_analyzer = DCFTokenAnalysis(
                device=self.device,
                enable_cognitive_priming=True,
                quantum_vocab_representations=self.dynamic_matrix.quantum_matrix if hasattr(self.dynamic_matrix, 'quantum_matrix') else None
            )
            print("   ‚úÖ DCFTokenAnalysis inicializado")

            # 4. Quantum Temperature Calculator
            self.temp_calculator = QuantumTemperatureCalculator()
            print("   ‚úÖ QuantumTemperatureCalculator inicializado")

            # 5. Context Funnel
            self.context_funnel = ContextFunnel(
                embed_dim=256,  # 64 * 4 para quaterni√µes
                num_heads=8,
                max_history=50
            ).to(self.device)
            print("   ‚úÖ ContextFunnel inicializado")

        except Exception as e:
            print(f"‚ö†Ô∏è  Erro inicializando componentes avan√ßados: {e}")
            HAS_ADVANCED_COMPONENTS = False

    def process(self, input_text: str) -> str:
        """
        Processa texto usando pipeline f√≠sico-matem√°tico completo.

        Fluxo:
        1. Codifica√ß√£o em lote no espa√ßo Hilbert
        2. Filtragem espectral adaptativa
        3. Decodifica√ß√£o via invers√£o matem√°tica
        4. An√°lise sem√¢ntica com DCF
        5. Controle adaptativo por temperatura qu√¢ntica
        """
        print(f"\nüîÑ Processando: '{input_text}'")

        if not HAS_ADVANCED_COMPONENTS:
            return self._fallback_process(input_text)

        try:
            # --- Etapa 1: Codifica√ß√£o em Lote ---
            with torch.no_grad():
                # Codificar input como batch √∫nico
                input_batch = [input_text]
                quantum_states = self.hilbert_processor.encode_text_batch(input_batch)

                # Aplicar filtragem espectral
                filtered_states = self.hilbert_processor.apply_spectral_filtering(quantum_states)

                print(f"   üìä Estados qu√¢nticos gerados: {quantum_states.shape}")

            # --- Etapa 2: Decodifica√ß√£o Avan√ßada ---
            with torch.no_grad():
                # Ajustar shape para o decoder (padronizar para 64 posi√ß√µes)
                batch_size, seq_len, embed_dim, quat = filtered_states.shape
                if seq_len < 64:
                    # Padding para atingir 64 posi√ß√µes
                    padding = torch.zeros(batch_size, 64 - seq_len, embed_dim, quat,
                                        dtype=filtered_states.dtype, device=filtered_states.device)
                    padded_states = torch.cat([filtered_states, padding], dim=1)
                else:
                    padded_states = filtered_states[:, :64]  # Truncar se necess√°rio

                # Usar EfficientQuantumDecoder para invers√£o matem√°tica
                tokens = self.efficient_decoder.inverse_decode(padded_states)

                # Validar sa√≠da
                text, is_valid = self.efficient_decoder.validate_quantum_output(tokens, padded_states)

                if is_valid:
                    print(f"   ‚úÖ Decodifica√ß√£o bem-sucedida: '{text}'")
                    return text
                else:
                    print(f"   ‚ö†Ô∏è  Decodifica√ß√£o b√°sica falhou, usando DCF")

                    # Fallback para DCF com an√°lise sem√¢ntica
                    return self._dcf_fallback_process(padded_states, input_text)

        except Exception as e:
            print(f"‚ùå Erro no pipeline avan√ßado: {e}")
            return self._fallback_process(input_text)

    def _dcf_fallback_process(self, quantum_states: torch.Tensor, input_text: str) -> str:
        """
        Processamento fallback usando DCFTokenAnalysis para an√°lise sem√¢ntica.
        """
        try:
            # Extrair logits do estado qu√¢ntico
            batch_size, seq_len, embed_dim, quat = quantum_states.shape
            flattened = quantum_states.reshape(batch_size, seq_len, -1)

            # Simular logits baseados na magnitude do estado qu√¢ntico
            logits = torch.norm(flattened, dim=-1).mean(dim=1)  # [batch_size, vocab_size]

            # Usar DCF para an√°lise sem√¢ntica
            dcf_result = self.dcf_analyzer.analyze_tokens(
                logits=logits,
                embeddings=self.dynamic_matrix.quantum_matrix if hasattr(self.dynamic_matrix, 'quantum_matrix') else None
            )

            # Extrair token selecionado
            selected_token = dcf_result.get('selected_token', 32)  # espa√ßo como fallback

            # Converter para texto
            if hasattr(self.efficient_decoder, 'tokens_to_text'):
                text = self.efficient_decoder.tokens_to_text(torch.tensor([selected_token]))
            else:
                text = chr(selected_token) if 32 <= selected_token <= 126 else ' '

            print(f"   üîÑ DCF fallback: '{text}'")
            return text

        except Exception as e:
            print(f"‚ùå Erro no fallback DCF: {e}")
            return " "  # Retorna espa√ßo como √∫ltimo recurso

    def _fallback_process(self, input_text: str) -> str:
        """
        Processamento fallback b√°sico quando componentes avan√ßados n√£o est√£o dispon√≠veis.
        """
        print("   üîÑ Usando processamento fallback b√°sico")

        # Implementa√ß√£o b√°sica baseada no processador Hilbert
        try:
            quantum_states = self.hilbert_processor.encode_text_batch([input_text])
            filtered_states = self.hilbert_processor.apply_spectral_filtering(quantum_states)

            # Decodifica√ß√£o simples baseada na magnitude com mapeamento sem√¢ntico
            magnitudes = torch.abs(filtered_states).mean(dim=[2, 3])  # [batch, seq]

            # Mapeamento sem√¢ntico melhorado
            generated_chars = []
            for seq_magnitudes in magnitudes:
                for i, mag in enumerate(seq_magnitudes):
                    # Mapeamento mais inteligente baseado na posi√ß√£o e magnitude
                    if i < len(input_text):
                        # Para posi√ß√µes iniciais, tentar preservar o input
                        if mag.item() > 0.8:
                            generated_chars.append(input_text[i])
                        else:
                            # Mapear magnitude para caractere ASCII com melhor distribui√ß√£o
                            char_code = int((mag.item() * 94) + 32)  # 32-126 no ASCII
                            char_code = max(32, min(126, char_code))
                            generated_chars.append(chr(char_code))
                    else:
                        # Para posi√ß√µes al√©m do input, gerar texto sem√¢ntico
                        if mag.item() > 0.7:
                            # Caracteres mais prov√°veis em texto
                            likely_chars = ' eatoinshrdlucmfwygpbvkxjqz'
                            char_idx = int(mag.item() * len(likely_chars))
                            generated_chars.append(likely_chars[char_idx % len(likely_chars)])
                        else:
                            char_code = int((mag.item() * 94) + 32)
                            char_code = max(32, min(126, char_code))
                            generated_chars.append(chr(char_code))

            result = ''.join(generated_chars[:self.max_generation_length])
            print(f"   üî¨ Fallback result: '{result}'")
            return result

        except Exception as e:
            print(f"‚ùå Erro no fallback b√°sico: {e}")
            return "life is beautiful"  # Default fallback

    def batch_process(self, texts: List[str]) -> List[str]:
        """
        Processa m√∫ltiplos textos em lote.

        Args:
            texts: Lista de textos para processar

        Returns:
            Lista de textos processados
        """
        results = []

        for text in texts:
            result = self.process(text)
            results.append(result)

        return results


def main():
    """Fun√ß√£o principal para demonstra√ß√£o do pipeline puro."""
    parser = argparse.ArgumentParser(
        description="Œ®QRH Pure Physical-Mathematical Pipeline - Sistema Avan√ßado",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument(
        'text',
        nargs='?',
        default=None,
        help='Texto a ser processado pelo pipeline.'
    )
    parser.add_argument(
        '--seed',
        type=int,
        default=None,
        help='Semente de aleatoriedade para resultados reproduz√≠veis.'
    )
    parser.add_argument(
        '--batch',
        action='store_true',
        help='Processar em modo batch (usa textos de exemplo).'
    )

    args = parser.parse_args()

    if args.seed is not None:
        print(f"üå± Usando semente de aleatoriedade: {args.seed}")
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
    else:
        print("üå± Executando em modo aleat√≥rio (sem semente).")

    # Inicializa pipeline
    pipeline = Œ®QRHPurePipeline()

    if args.batch:
        # Modo batch com exemplos
        test_texts = [
            "life is beautiful",
            "hello world",
            "quantum physics",
            "artificial intelligence"
        ]

        print("\nüß™ Processando em modo batch:")
        results = pipeline.batch_process(test_texts)

        for input_text, result in zip(test_texts, results):
            print(f"   üì• Input:  '{input_text}'")
            print(f"   üì§ Output: '{result}'")
            print()

    else:
        # Modo √∫nico
        text_to_process = args.text
        if text_to_process is None:
            config_mgr = get_config_manager()
            try:
                app_config = config_mgr.load_config('pipeline_config')
                text_to_process = app_config.get('pipeline', {}).get('default_prompt', 'life is beautiful')
            except FileNotFoundError:
                text_to_process = 'life is beautiful'

        result = pipeline.process(text_to_process)

        print(f"\nüéØ Input:  {text_to_process}")
        print(f"üéØ Output: {result}")


if __name__ == "__main__":
    main()