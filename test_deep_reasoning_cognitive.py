#!/usr/bin/env python3
"""
DEEP REASONING COGNITIVE TEST SUITE

Multi-scale cognitive evaluation using:
1. Synthetic Neurotransmitters for cognitive modulation
2. QRH Multi-Scale Testing (different complexity levels)
3. JIT Compilation for performance optimization
4. Deep Reasoning Tasks (logical, mathematical, linguistic)

This test suite evaluates the system's ability to perform human-like reasoning
using the enhanced QRH architecture with synthetic neurotransmitter alignment.
"""

import torch
import torch.nn as nn
import time
import math
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from enum import Enum

from qrh_layer import QRHLayer, QRHConfig
from production_system import ProductionSemanticQRH, ProductionConfig, ProductionMode
from synthetic_neurotransmitters import (
    SyntheticNeurotransmitterSystem, NeurotransmitterConfig, create_aligned_qrh_component
)


class ReasoningComplexity(Enum):
    """Levels of reasoning complexity for multi-scale testing"""
    BASIC = "basic"           # Simple pattern recognition
    INTERMEDIATE = "intermediate"  # Multi-step logical reasoning
    ADVANCED = "advanced"     # Complex abstract reasoning
    EXPERT = "expert"        # Human-level cognitive tasks


class CognitiveTask(Enum):
    """Types of cognitive tasks for deep reasoning evaluation"""
    LOGICAL_INFERENCE = "logical_inference"
    MATHEMATICAL_REASONING = "mathematical_reasoning"
    LINGUISTIC_ANALYSIS = "linguistic_analysis"
    PATTERN_RECOGNITION = "pattern_recognition"
    ABSTRACT_REASONING = "abstract_reasoning"
    CAUSAL_INFERENCE = "causal_inference"
    ANALOGICAL_REASONING = "analogical_reasoning"


@dataclass
class ReasoningTestConfig:
    """Configuration for deep reasoning tests"""
    complexity_level: ReasoningComplexity = ReasoningComplexity.INTERMEDIATE
    cognitive_task: CognitiveTask = CognitiveTask.LOGICAL_INFERENCE
    sequence_length: int = 64
    batch_size: int = 4
    embed_dim: int = 32
    num_reasoning_steps: int = 5
    enable_jit: bool = True
    enable_neurotransmitters: bool = True
    reasoning_timeout_seconds: float = 10.0


class DeepReasoningCognitiveSystem(nn.Module):
    """
    Deep Reasoning System using QRH + Synthetic Neurotransmitters
    Designed for multi-scale cognitive evaluation
    """

    def __init__(self, config: ReasoningTestConfig):
        super().__init__()
        self.config = config

        # Production QRH System Configuration
        self.qrh_config = ProductionConfig(
            mode=ProductionMode.HIGH_ACCURACY,  # High accuracy for reasoning tasks
            embed_dim=config.embed_dim,
            max_sequence_length=config.sequence_length,
            batch_size=config.batch_size,
            enable_jit_compilation=config.enable_jit,
            min_detection_rate=0.9,  # High standards for reasoning
            min_coherence_score=0.8,
            min_signal_clarity=0.7
        )

        # Core QRH System
        self.qrh_system = ProductionSemanticQRH(self.qrh_config)

        # Reasoning-specific neurotransmitter configuration
        self.nt_config = NeurotransmitterConfig(
            embed_dim=config.embed_dim,
            # Optimize for reasoning tasks
            dopamine_strength=0.9,      # High reward for correct reasoning
            serotonin_stability=0.8,    # High stability for consistent logic
            acetylcholine_focus=0.95,   # Maximum attention for reasoning
            gaba_inhibition=0.6,        # Strong noise suppression
            glutamate_excitation=1.2    # High excitation for complex thoughts
        )

        # Multi-Scale Reasoning Modules
        self.reasoning_scales = nn.ModuleDict({
            'micro': self._create_reasoning_module(config.embed_dim // 4),    # Fine details
            'meso': self._create_reasoning_module(config.embed_dim // 2),     # Local patterns
            'macro': self._create_reasoning_module(config.embed_dim),         # Global structure
            'meta': self._create_reasoning_module(config.embed_dim * 2)       # Abstract concepts
        })

        # Cognitive Task Specialists
        self.cognitive_specialists = nn.ModuleDict({
            task.value: self._create_specialist_module(config.embed_dim)
            for task in CognitiveTask
        })

        # Reasoning State Tracker
        self.reasoning_memory = nn.LSTM(
            input_size=config.embed_dim * 4,  # QRH output dimension
            hidden_size=config.embed_dim * 2,
            num_layers=2,
            batch_first=True,
            dropout=0.1
        )

        # Decision Integration Layer
        # Total features: 4 scales (4*embed_dim) + reasoning_state (2*embed_dim) + specialist (embed_dim) = 7*embed_dim
        total_features = config.embed_dim * 7
        self.decision_integrator = nn.Sequential(
            nn.Linear(total_features, config.embed_dim * 2),  # Multi-scale + memory + specialist
            nn.GELU(),
            nn.LayerNorm(config.embed_dim * 2),
            nn.Linear(config.embed_dim * 2, config.embed_dim),
            nn.Tanh()
        )

        # Confidence Estimation
        self.confidence_estimator = nn.Sequential(
            nn.Linear(config.embed_dim, config.embed_dim // 2),
            nn.ReLU(),
            nn.Linear(config.embed_dim // 2, 1),
            nn.Sigmoid()
        )

        # Apply JIT optimization if enabled
        if config.enable_jit:
            self._apply_jit_optimization()

    def _create_reasoning_module(self, hidden_dim: int) -> nn.Module:
        """Create a reasoning module for specific scale"""
        return nn.Sequential(
            nn.Linear(self.config.embed_dim * 4, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.GELU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.GELU(),
            nn.Linear(hidden_dim, self.config.embed_dim)
        )

    def _create_specialist_module(self, hidden_dim: int) -> nn.Module:
        """Create a cognitive task specialist module"""
        return nn.Sequential(
            nn.Linear(self.config.embed_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.GELU(),
            nn.Linear(hidden_dim // 2, self.config.embed_dim)
        )

    def _apply_jit_optimization(self):
        """Apply JIT compilation for performance optimization"""
        try:
            # JIT compile reasoning modules for speed
            sample_input = torch.randn(1, self.config.embed_dim * 4)

            for scale_name, module in self.reasoning_scales.items():
                try:
                    self.reasoning_scales[scale_name] = torch.jit.trace(module, sample_input)
                    print(f"âœ… JIT compiled {scale_name} reasoning scale")
                except Exception as e:
                    print(f"âš ï¸ JIT compilation failed for {scale_name}: {e}")

            print("ğŸš€ Deep reasoning system JIT optimization completed")
        except Exception as e:
            print(f"âš ï¸ JIT optimization warning: {e}")

    def forward(self, x: torch.Tensor,
                task_type: CognitiveTask,
                reasoning_steps: Optional[int] = None) -> Dict[str, torch.Tensor]:
        """
        Perform deep reasoning with multi-scale analysis
        """
        reasoning_steps = reasoning_steps or self.config.num_reasoning_steps
        batch_size, seq_len = x.shape[:2]

        # Step 1: Core QRH Processing with semantic understanding
        qrh_output, qrh_metrics = self.qrh_system(x, return_detailed_metrics=True)

        # Step 2: Multi-Scale Reasoning Analysis
        scale_outputs = {}
        for scale_name, scale_module in self.reasoning_scales.items():
            try:
                scale_outputs[scale_name] = scale_module(qrh_output)
            except Exception as e:
                # Fallback for JIT compilation issues
                scale_outputs[scale_name] = torch.zeros(
                    batch_size, seq_len, self.config.embed_dim,
                    device=x.device
                )

        # Step 3: Cognitive Task Specialization
        specialist_output = self.cognitive_specialists[task_type.value](
            qrh_output.mean(dim=1)  # Global context
        )

        # Step 4: Iterative Reasoning Process
        reasoning_state = self._iterative_reasoning(
            qrh_output, scale_outputs, specialist_output, reasoning_steps
        )

        # Step 5: Decision Integration
        integrated_features = torch.cat([
            scale_outputs['micro'].mean(dim=1),
            scale_outputs['meso'].mean(dim=1),
            scale_outputs['macro'].mean(dim=1),
            scale_outputs['meta'].mean(dim=1),
            reasoning_state,
            specialist_output
        ], dim=-1)

        final_decision = self.decision_integrator(integrated_features)

        # Step 6: Confidence Estimation
        confidence = self.confidence_estimator(final_decision)

        return {
            'reasoning_output': final_decision,
            'confidence': confidence,
            'scale_outputs': scale_outputs,
            'specialist_output': specialist_output,
            'qrh_metrics': qrh_metrics,
            'reasoning_steps': reasoning_steps
        }

    def _iterative_reasoning(self, qrh_output: torch.Tensor,
                           scale_outputs: Dict[str, torch.Tensor],
                           specialist_output: torch.Tensor,
                           steps: int) -> torch.Tensor:
        """Perform iterative reasoning process"""
        batch_size = qrh_output.shape[0]

        # Initialize LSTM hidden state
        hidden = (
            torch.zeros(2, batch_size, self.config.embed_dim * 2, device=qrh_output.device),
            torch.zeros(2, batch_size, self.config.embed_dim * 2, device=qrh_output.device)
        )

        # Iterative reasoning loop
        reasoning_input = qrh_output
        for step in range(steps):
            # LSTM step for reasoning memory
            lstm_output, hidden = self.reasoning_memory(reasoning_input, hidden)

            # Update reasoning input with feedback
            reasoning_input = qrh_output + 0.1 * lstm_output

        return lstm_output[:, -1, :]  # Final reasoning state


class CognitiveTestSuite:
    """
    Comprehensive cognitive test suite for deep reasoning evaluation
    """

    def __init__(self, device: str = 'cpu'):
        self.device = torch.device(device)
        self.test_results = {}

    def generate_test_data(self, config: ReasoningTestConfig) -> Dict[str, torch.Tensor]:
        """Generate test data based on cognitive task and complexity"""
        batch_size, seq_len, embed_dim = config.batch_size, config.sequence_length, config.embed_dim * 4

        if config.cognitive_task == CognitiveTask.LOGICAL_INFERENCE:
            return self._generate_logical_inference_data(batch_size, seq_len, embed_dim, config.complexity_level)
        elif config.cognitive_task == CognitiveTask.MATHEMATICAL_REASONING:
            return self._generate_mathematical_reasoning_data(batch_size, seq_len, embed_dim, config.complexity_level)
        elif config.cognitive_task == CognitiveTask.PATTERN_RECOGNITION:
            return self._generate_pattern_recognition_data(batch_size, seq_len, embed_dim, config.complexity_level)
        elif config.cognitive_task == CognitiveTask.ABSTRACT_REASONING:
            return self._generate_abstract_reasoning_data(batch_size, seq_len, embed_dim, config.complexity_level)
        else:
            # Default: Random structured data with embedded patterns
            return self._generate_default_reasoning_data(batch_size, seq_len, embed_dim, config.complexity_level)

    def _generate_logical_inference_data(self, batch_size: int, seq_len: int,
                                       embed_dim: int, complexity: ReasoningComplexity) -> Dict[str, torch.Tensor]:
        """Generate logical inference test data"""
        # Create logical sequences: A -> B, B -> C, therefore A -> C
        data = torch.randn(batch_size, seq_len, embed_dim)

        if complexity == ReasoningComplexity.BASIC:
            # Simple A -> B patterns
            data[:, :seq_len//3, :] *= 1.0  # Premise A
            data[:, seq_len//3:2*seq_len//3, :] *= 1.5  # Premise B
            data[:, 2*seq_len//3:, :] *= 2.0  # Conclusion

        elif complexity == ReasoningComplexity.INTERMEDIATE:
            # Multi-step inference chains
            for i in range(0, seq_len, 4):
                if i + 3 < seq_len:
                    data[:, i, :] *= (i + 1) * 0.5  # Progressive logical chain

        elif complexity == ReasoningComplexity.ADVANCED:
            # Complex nested logic with contradictions
            data += 0.3 * torch.sin(torch.arange(seq_len).float()).unsqueeze(0).unsqueeze(-1) * torch.randn(embed_dim)

        return {'input': data, 'expected_pattern': 'logical_chain'}

    def _generate_mathematical_reasoning_data(self, batch_size: int, seq_len: int,
                                            embed_dim: int, complexity: ReasoningComplexity) -> Dict[str, torch.Tensor]:
        """Generate mathematical reasoning test data"""
        data = torch.randn(batch_size, seq_len, embed_dim)

        if complexity == ReasoningComplexity.BASIC:
            # Simple arithmetic progressions
            progression = torch.arange(seq_len, dtype=torch.float32)
            data += progression.unsqueeze(0).unsqueeze(-1) * 0.1

        elif complexity == ReasoningComplexity.INTERMEDIATE:
            # Fibonacci-like sequences
            fib_like = torch.zeros(seq_len)
            fib_like[0], fib_like[1] = 1, 1
            for i in range(2, seq_len):
                fib_like[i] = fib_like[i-1] + fib_like[i-2]
            data += fib_like.unsqueeze(0).unsqueeze(-1) * 0.01

        elif complexity == ReasoningComplexity.ADVANCED:
            # Complex mathematical relationships
            x = torch.arange(seq_len).float()
            math_pattern = torch.sin(x * 0.5) * torch.cos(x * 0.2) * torch.exp(-x * 0.01)
            data += math_pattern.unsqueeze(0).unsqueeze(-1)

        return {'input': data, 'expected_pattern': 'mathematical_sequence'}

    def _generate_pattern_recognition_data(self, batch_size: int, seq_len: int,
                                         embed_dim: int, complexity: ReasoningComplexity) -> Dict[str, torch.Tensor]:
        """Generate pattern recognition test data"""
        data = torch.randn(batch_size, seq_len, embed_dim)

        if complexity == ReasoningComplexity.BASIC:
            # Simple repetitive patterns
            pattern_length = 4
            base_pattern = torch.randn(embed_dim)
            for i in range(0, seq_len, pattern_length):
                end_idx = min(i + pattern_length, seq_len)
                data[:, i:end_idx, :] = base_pattern.unsqueeze(0).unsqueeze(0)

        elif complexity == ReasoningComplexity.INTERMEDIATE:
            # Evolving patterns
            base_pattern = torch.randn(embed_dim)
            for i in range(seq_len):
                evolution_factor = 1.0 + i * 0.02
                data[:, i, :] = base_pattern * evolution_factor + torch.randn(embed_dim) * 0.1

        elif complexity == ReasoningComplexity.ADVANCED:
            # Hierarchical nested patterns
            for scale in [4, 8, 16]:
                pattern = torch.sin(torch.arange(seq_len).float() * 2 * math.pi / scale)
                data += pattern.unsqueeze(0).unsqueeze(-1) * torch.randn(embed_dim) * 0.1

        return {'input': data, 'expected_pattern': 'hierarchical_patterns'}

    def _generate_abstract_reasoning_data(self, batch_size: int, seq_len: int,
                                        embed_dim: int, complexity: ReasoningComplexity) -> Dict[str, torch.Tensor]:
        """Generate abstract reasoning test data (analogies, metaphors)"""
        data = torch.randn(batch_size, seq_len, embed_dim)

        # Create abstract relationship patterns
        # A is to B as C is to D
        if complexity in [ReasoningComplexity.ADVANCED, ReasoningComplexity.EXPERT]:
            # Create analogical structures
            concept_a = torch.randn(embed_dim)
            concept_b = concept_a * 1.5 + torch.randn(embed_dim) * 0.2  # Transformation
            concept_c = torch.randn(embed_dim)
            concept_d = concept_c * 1.5 + torch.randn(embed_dim) * 0.2  # Same transformation

            # Embed analogical structure in sequence
            quarter = seq_len // 4
            data[:, :quarter, :] = concept_a
            data[:, quarter:2*quarter, :] = concept_b
            data[:, 2*quarter:3*quarter, :] = concept_c
            data[:, 3*quarter:, :] = concept_d

        return {'input': data, 'expected_pattern': 'analogical_reasoning'}

    def _generate_default_reasoning_data(self, batch_size: int, seq_len: int,
                                       embed_dim: int, complexity: ReasoningComplexity) -> Dict[str, torch.Tensor]:
        """Generate default structured reasoning data"""
        data = torch.randn(batch_size, seq_len, embed_dim)

        # Add complexity-dependent structure
        complexity_factor = {
            ReasoningComplexity.BASIC: 0.1,
            ReasoningComplexity.INTERMEDIATE: 0.3,
            ReasoningComplexity.ADVANCED: 0.5,
            ReasoningComplexity.EXPERT: 0.8
        }[complexity]

        # Add structured patterns
        for i in range(seq_len):
            structure_signal = math.sin(i * complexity_factor) * math.cos(i * complexity_factor * 0.5)
            data[:, i, :] += structure_signal * torch.randn(embed_dim) * 0.2

        return {'input': data, 'expected_pattern': 'structured_complexity'}

    def run_cognitive_evaluation(self, config: ReasoningTestConfig) -> Dict[str, Any]:
        """Run comprehensive cognitive evaluation"""
        print(f"ğŸ§  Running Cognitive Evaluation: {config.cognitive_task.value}")
        print(f"ğŸ“Š Complexity Level: {config.complexity_level.value}")
        print(f"âš¡ JIT Enabled: {config.enable_jit}")
        print(f"ğŸ§¬ Neurotransmitters Enabled: {config.enable_neurotransmitters}")

        # Initialize reasoning system
        reasoning_system = DeepReasoningCognitiveSystem(config).to(self.device)

        # Generate test data
        test_data = self.generate_test_data(config)
        input_data = test_data['input'].to(self.device)

        # Measure reasoning performance
        start_time = time.time()

        try:
            with torch.no_grad():
                results = reasoning_system(input_data, config.cognitive_task)

            processing_time = time.time() - start_time

            # Analyze results
            analysis = self._analyze_reasoning_results(results, test_data, processing_time, config)

            return {
                'success': True,
                'config': config,
                'results': results,
                'analysis': analysis,
                'processing_time': processing_time
            }

        except Exception as e:
            processing_time = time.time() - start_time
            return {
                'success': False,
                'config': config,
                'error': str(e),
                'processing_time': processing_time
            }

    def _analyze_reasoning_results(self, results: Dict[str, torch.Tensor],
                                 test_data: Dict[str, torch.Tensor],
                                 processing_time: float,
                                 config: ReasoningTestConfig) -> Dict[str, Any]:
        """Analyze reasoning results for cognitive metrics"""
        analysis = {
            'cognitive_metrics': {},
            'performance_metrics': {},
            'reasoning_quality': {}
        }

        # Cognitive Metrics
        confidence = results['confidence'].mean().item()
        reasoning_coherence = self._calculate_coherence(results['reasoning_output'])
        scale_consistency = self._calculate_scale_consistency(results['scale_outputs'])

        analysis['cognitive_metrics'] = {
            'confidence_score': confidence,
            'reasoning_coherence': reasoning_coherence,
            'scale_consistency': scale_consistency,
            'cognitive_complexity': self._assess_cognitive_complexity(results, config.complexity_level)
        }

        # Performance Metrics
        tokens_per_second = (config.batch_size * config.sequence_length) / processing_time
        analysis['performance_metrics'] = {
            'processing_time_ms': processing_time * 1000,
            'tokens_per_second': tokens_per_second,
            'reasoning_efficiency': confidence / (processing_time + 1e-6)
        }

        # Reasoning Quality Assessment
        analysis['reasoning_quality'] = {
            'logical_consistency': self._assess_logical_consistency(results),
            'pattern_detection': self._assess_pattern_detection(results, test_data),
            'abstraction_level': self._assess_abstraction_level(results['scale_outputs'])
        }

        return analysis

    def _calculate_coherence(self, reasoning_output: torch.Tensor) -> float:
        """Calculate coherence of reasoning output"""
        # Measure consistency across the reasoning output
        output_var = torch.var(reasoning_output, dim=0).mean().item()
        coherence = 1.0 / (1.0 + output_var)
        return float(coherence)

    def _calculate_scale_consistency(self, scale_outputs: Dict[str, torch.Tensor]) -> float:
        """Calculate consistency across different reasoning scales"""
        scales = list(scale_outputs.values())
        if len(scales) < 2:
            return 1.0

        # Calculate correlation between different scales
        correlations = []
        for i in range(len(scales)):
            for j in range(i + 1, len(scales)):
                scale_i = scales[i].flatten()
                scale_j = scales[j].flatten()

                # Resize to same dimension for comparison
                min_size = min(len(scale_i), len(scale_j))
                scale_i = scale_i[:min_size]
                scale_j = scale_j[:min_size]

                correlation = torch.corrcoef(torch.stack([scale_i, scale_j]))[0, 1]
                if not torch.isnan(correlation):
                    correlations.append(correlation.item())

        return float(np.mean(correlations)) if correlations else 0.5

    def _assess_cognitive_complexity(self, results: Dict[str, torch.Tensor],
                                   complexity_level: ReasoningComplexity) -> float:
        """Assess the cognitive complexity of the reasoning process"""
        # Higher complexity should show more sophisticated patterns
        reasoning_entropy = -torch.sum(
            torch.softmax(results['reasoning_output'], dim=-1) *
            torch.log_softmax(results['reasoning_output'], dim=-1),
            dim=-1
        ).mean().item()

        # Normalize entropy based on expected complexity
        complexity_scores = {
            ReasoningComplexity.BASIC: 0.25,
            ReasoningComplexity.INTERMEDIATE: 0.5,
            ReasoningComplexity.ADVANCED: 0.75,
            ReasoningComplexity.EXPERT: 1.0
        }

        expected_complexity = complexity_scores[complexity_level]
        complexity_match = 1.0 - abs(reasoning_entropy - expected_complexity)

        return max(0.0, complexity_match)

    def _assess_logical_consistency(self, results: Dict[str, torch.Tensor]) -> float:
        """Assess logical consistency of reasoning"""
        # Check for internal contradictions in reasoning output
        reasoning_output = results['reasoning_output']

        # Calculate self-consistency: reasoning should be stable
        output_stability = 1.0 - torch.std(reasoning_output, dim=0).mean().item()

        return max(0.0, min(1.0, output_stability))

    def _assess_pattern_detection(self, results: Dict[str, torch.Tensor],
                                test_data: Dict[str, torch.Tensor]) -> float:
        """Assess pattern detection capability"""
        # This would ideally compare against known patterns in test data
        # For now, we measure the system's ability to find structure

        reasoning_output = results['reasoning_output']

        # Look for structured patterns in the output
        output_fft = torch.fft.fft(reasoning_output.flatten())
        pattern_strength = torch.abs(output_fft).max().item() / torch.abs(output_fft).mean().item()

        # Normalize to 0-1 range
        pattern_detection_score = min(1.0, pattern_strength / 10.0)

        return pattern_detection_score

    def _assess_abstraction_level(self, scale_outputs: Dict[str, torch.Tensor]) -> float:
        """Assess the level of abstraction in multi-scale reasoning"""
        # Higher abstraction should show different patterns at different scales
        scale_names = ['micro', 'meso', 'macro', 'meta']
        abstraction_levels = []

        for i, scale_name in enumerate(scale_names):
            if scale_name in scale_outputs:
                # Measure complexity of patterns at each scale
                scale_data = scale_outputs[scale_name]
                scale_complexity = torch.var(scale_data, dim=-1).mean().item()
                abstraction_levels.append(scale_complexity * (i + 1))  # Weight by abstraction level

        if abstraction_levels:
            # Higher scales should show different (typically more complex) patterns
            abstraction_gradient = np.gradient(abstraction_levels)
            abstraction_score = np.mean(np.abs(abstraction_gradient))
            return min(1.0, abstraction_score)

        return 0.5  # Default if no scales available

    def run_comprehensive_cognitive_battery(self) -> Dict[str, Any]:
        """Run comprehensive battery of cognitive tests"""
        print("ğŸ§ ğŸ”¬ COMPREHENSIVE COGNITIVE BATTERY")
        print("=" * 80)

        all_results = {}
        overall_performance = {
            'cognitive_tasks': {},
            'complexity_levels': {},
            'performance_summary': {}
        }

        # Test all cognitive tasks at different complexity levels
        for task in CognitiveTask:
            print(f"\nğŸ¯ Testing {task.value.upper()}")
            task_results = {}

            for complexity in ReasoningComplexity:
                print(f"  ğŸ“Š {complexity.value} level...")

                config = ReasoningTestConfig(
                    complexity_level=complexity,
                    cognitive_task=task,
                    enable_jit=True,
                    enable_neurotransmitters=True
                )

                result = self.run_cognitive_evaluation(config)
                task_results[complexity.value] = result

                if result['success']:
                    confidence = result['analysis']['cognitive_metrics']['confidence_score']
                    coherence = result['analysis']['cognitive_metrics']['reasoning_coherence']
                    print(f"    âœ… Success: Confidence={confidence:.3f}, Coherence={coherence:.3f}")
                else:
                    print(f"    âŒ Failed: {result['error']}")

            all_results[task.value] = task_results

        # Generate overall performance summary
        overall_performance = self._generate_performance_summary(all_results)

        print("\n" + "=" * 80)
        print("ğŸ“‹ COGNITIVE BATTERY SUMMARY")
        print("=" * 80)
        self._print_performance_summary(overall_performance)

        return {
            'detailed_results': all_results,
            'performance_summary': overall_performance,
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }

    def _generate_performance_summary(self, all_results: Dict[str, Any]) -> Dict[str, Any]:
        """Generate overall performance summary from all test results"""
        summary = {
            'overall_success_rate': 0.0,
            'average_confidence': 0.0,
            'average_coherence': 0.0,
            'average_processing_time': 0.0,
            'cognitive_strengths': [],
            'areas_for_improvement': [],
            'complexity_performance': {},
            'task_performance': {}
        }

        total_tests = 0
        successful_tests = 0
        confidence_sum = 0.0
        coherence_sum = 0.0
        processing_time_sum = 0.0

        # Analyze results by task and complexity
        for task_name, task_results in all_results.items():
            task_success = 0
            task_total = 0

            for complexity_name, result in task_results.items():
                total_tests += 1
                task_total += 1

                if result['success']:
                    successful_tests += 1
                    task_success += 1

                    metrics = result['analysis']['cognitive_metrics']
                    confidence_sum += metrics['confidence_score']
                    coherence_sum += metrics['reasoning_coherence']
                    processing_time_sum += result['processing_time']

            # Task performance
            summary['task_performance'][task_name] = task_success / task_total if task_total > 0 else 0.0

        # Overall metrics
        if successful_tests > 0:
            summary['overall_success_rate'] = successful_tests / total_tests
            summary['average_confidence'] = confidence_sum / successful_tests
            summary['average_coherence'] = coherence_sum / successful_tests
            summary['average_processing_time'] = processing_time_sum / successful_tests

        # Identify strengths and weaknesses
        task_performances = summary['task_performance']
        if task_performances:
            best_task = max(task_performances.items(), key=lambda x: x[1])
            worst_task = min(task_performances.items(), key=lambda x: x[1])

            summary['cognitive_strengths'] = [best_task[0]] if best_task[1] > 0.7 else []
            summary['areas_for_improvement'] = [worst_task[0]] if worst_task[1] < 0.5 else []

        return summary

    def _print_performance_summary(self, summary: Dict[str, Any]):
        """Print formatted performance summary"""
        print(f"ğŸ¯ Overall Success Rate: {summary['overall_success_rate']:.1%}")
        print(f"ğŸ” Average Confidence: {summary['average_confidence']:.3f}")
        print(f"ğŸ§  Average Coherence: {summary['average_coherence']:.3f}")
        print(f"âš¡ Average Processing Time: {summary['average_processing_time']*1000:.1f}ms")

        print(f"\nğŸ“Š Task Performance Breakdown:")
        for task, performance in summary['task_performance'].items():
            status = "âœ…" if performance > 0.7 else "âš ï¸" if performance > 0.4 else "âŒ"
            print(f"  {status} {task.replace('_', ' ').title()}: {performance:.1%}")

        if summary['cognitive_strengths']:
            print(f"\nğŸŒŸ Cognitive Strengths: {', '.join(summary['cognitive_strengths'])}")

        if summary['areas_for_improvement']:
            print(f"ğŸ”§ Areas for Improvement: {', '.join(summary['areas_for_improvement'])}")


def main():
    """Main function to run deep reasoning cognitive tests"""
    print("ğŸ§ ğŸš€ DEEP REASONING COGNITIVE TEST SUITE")
    print("Multi-scale QRH + Synthetic Neurotransmitters + JIT Optimization")
    print("=" * 80)

    # Initialize cognitive test suite
    cognitive_tester = CognitiveTestSuite(device='cpu')

    # Run comprehensive cognitive battery
    results = cognitive_tester.run_comprehensive_cognitive_battery()

    # Save results
    import json
    results_file = 'deep_reasoning_cognitive_results.json'

    # Convert results to JSON-serializable format
    json_results = {
        'performance_summary': results['performance_summary'],
        'timestamp': results['timestamp'],
        'test_count': len(results['detailed_results'])
    }

    with open(results_file, 'w') as f:
        json.dump(json_results, f, indent=2, default=str)

    print(f"\nğŸ’¾ Detailed results saved to: {results_file}")
    print("ğŸ‰ Deep Reasoning Cognitive Evaluation Complete!")

    return results


if __name__ == "__main__":
    results = main()